(function(global, context){
	var fileData=[]
var cacheData=[]

	fileData.push(function(){return {
	"stat": {
		"mtime": "2019-05-18T07:17:58.534Z",
		"mtimeMs": 1558163878534.45,
		"atime": "2019-05-18T07:17:58.530Z",
		"atimeMs": 1558163878530.4497,
		"isdirectory": true
	},
	"filename": ""
}})
	fileData.push(function(){ var item= cacheData[1]; if(!item){ item= cacheData[1]= {
	"stat": {
		"mtime": "2017-04-30T20:19:13.000Z",
		"mtimeMs": 1493583553000,
		"atime": "2019-05-18T07:17:58.537Z",
		"atimeMs": 1558163878537,
		"isfile": true
	},
	"filename": "cli.js",
	"content": "#!/usr/bin/env node\n\nvar extract = require('./')\n\nvar args = process.argv.slice(2)\nvar source = args[0]\nvar dest = args[1] || process.cwd()\nif (!source) {\n  console.error('Usage: extract-zip foo.zip <targetDirectory>')\n  process.exit(1)\n}\n\nextract(source, {dir: dest}, function (err, results) {\n  if (err) {\n    console.error('error!', err)\n    process.exit(1)\n  } else {\n    process.exit(0)\n  }\n})\n",
	"transpiled": true
}; item.content= context.Buffer.from(item.content,'binary'); } return item; })
	fileData.push(function(){ var item= cacheData[2]; if(!item){ item= cacheData[2]= {
	"stat": {
		"mtime": "2017-05-01T05:05:35.000Z",
		"mtimeMs": 1493615135000,
		"atime": "2019-05-18T07:17:58.537Z",
		"atimeMs": 1558163878537,
		"isfile": true
	},
	"filename": "index.js",
	"content": "var fs = require('fs')\nvar path = require('path')\nvar yauzl = require('yauzl')\nvar mkdirp = require('mkdirp')\nvar concat = require('concat-stream')\nvar debug = require('debug')('extract-zip')\n\nmodule.exports = function (zipPath, opts, cb) {\n  debug('creating target directory', opts.dir)\n\n  if (path.isAbsolute(opts.dir) === false) {\n    return cb(new Error('Target directory is expected to be absolute'))\n  }\n\n  mkdirp(opts.dir, function (err) {\n    if (err) return cb(err)\n\n    fs.realpath(opts.dir, function (err, canonicalDir) {\n      if (err) return cb(err)\n\n      opts.dir = canonicalDir\n\n      openZip(opts)\n    })\n  })\n\n  function openZip () {\n    debug('opening', zipPath, 'with opts', opts)\n\n    yauzl.open(zipPath, {lazyEntries: true}, function (err, zipfile) {\n      if (err) return cb(err)\n\n      var cancelled = false\n\n      zipfile.readEntry()\n\n      zipfile.on('close', function () {\n        if (!cancelled) {\n          debug('zip extraction complete')\n          cb()\n        }\n      })\n\n      zipfile.on('entry', function (entry) {\n        if (cancelled) {\n          debug('skipping entry', entry.fileName, {cancelled: cancelled})\n          return\n        }\n\n        debug('zipfile entry', entry.fileName)\n\n        if (/^__MACOSX\\//.test(entry.fileName)) {\n          // dir name starts with __MACOSX/\n          zipfile.readEntry()\n          return\n        }\n\n        var destDir = path.dirname(path.join(opts.dir, entry.fileName))\n\n        mkdirp(destDir, function (err) {\n          if (err) {\n            cancelled = true\n            zipfile.close()\n            return cb(err)\n          }\n\n          fs.realpath(destDir, function (err, canonicalDestDir) {\n            if (err) {\n              cancelled = true\n              zipfile.close()\n              return cb(err)\n            }\n\n            var relativeDestDir = path.relative(opts.dir, canonicalDestDir)\n\n            if (relativeDestDir.split(path.sep).indexOf('..') !== -1) {\n              cancelled = true\n              zipfile.close()\n              return cb(new Error('Out of bound path \"' + canonicalDestDir + '\" found while processing file ' + entry.fileName))\n            }\n\n            extractEntry(entry, function (err) {\n              // if any extraction fails then abort everything\n              if (err) {\n                cancelled = true\n                zipfile.close()\n                return cb(err)\n              }\n              debug('finished processing', entry.fileName)\n              zipfile.readEntry()\n            })\n          })\n        })\n      })\n\n      function extractEntry (entry, done) {\n        if (cancelled) {\n          debug('skipping entry extraction', entry.fileName, {cancelled: cancelled})\n          return setImmediate(done)\n        }\n\n        if (opts.onEntry) {\n          opts.onEntry(entry, zipfile)\n        }\n\n        var dest = path.join(opts.dir, entry.fileName)\n\n        // convert external file attr int into a fs stat mode int\n        var mode = (entry.externalFileAttributes >> 16) & 0xFFFF\n        // check if it's a symlink or dir (using stat mode constants)\n        var IFMT = 61440\n        var IFDIR = 16384\n        var IFLNK = 40960\n        var symlink = (mode & IFMT) === IFLNK\n        var isDir = (mode & IFMT) === IFDIR\n\n        // Failsafe, borrowed from jsZip\n        if (!isDir && entry.fileName.slice(-1) === '/') {\n          isDir = true\n        }\n\n        // check for windows weird way of specifying a directory\n        // https://github.com/maxogden/extract-zip/issues/13#issuecomment-154494566\n        var madeBy = entry.versionMadeBy >> 8\n        if (!isDir) isDir = (madeBy === 0 && entry.externalFileAttributes === 16)\n\n        // if no mode then default to default modes\n        if (mode === 0) {\n          if (isDir) {\n            if (opts.defaultDirMode) mode = parseInt(opts.defaultDirMode, 10)\n            if (!mode) mode = 493 // Default to 0755\n          } else {\n            if (opts.defaultFileMode) mode = parseInt(opts.defaultFileMode, 10)\n            if (!mode) mode = 420 // Default to 0644\n          }\n        }\n\n        debug('extracting entry', { filename: entry.fileName, isDir: isDir, isSymlink: symlink })\n\n        // reverse umask first (~)\n        var umask = ~process.umask()\n        // & with processes umask to override invalid perms\n        var procMode = mode & umask\n\n        // always ensure folders are created\n        var destDir = dest\n        if (!isDir) destDir = path.dirname(dest)\n\n        debug('mkdirp', {dir: destDir})\n        mkdirp(destDir, function (err) {\n          if (err) {\n            debug('mkdirp error', destDir, {error: err})\n            cancelled = true\n            return done(err)\n          }\n\n          if (isDir) return done()\n\n          debug('opening read stream', dest)\n          zipfile.openReadStream(entry, function (err, readStream) {\n            if (err) {\n              debug('openReadStream error', err)\n              cancelled = true\n              return done(err)\n            }\n\n            readStream.on('error', function (err) {\n              console.log('read err', err)\n            })\n\n            if (symlink) writeSymlink()\n            else writeStream()\n\n            function writeStream () {\n              var writeStream = fs.createWriteStream(dest, {mode: procMode})\n              readStream.pipe(writeStream)\n\n              writeStream.on('finish', function () {\n                done()\n              })\n\n              writeStream.on('error', function (err) {\n                debug('write error', {error: err})\n                cancelled = true\n                return done(err)\n              })\n            }\n\n            // AFAICT the content of the symlink file itself is the symlink target filename string\n            function writeSymlink () {\n              readStream.pipe(concat(function (data) {\n                var link = data.toString()\n                debug('creating symlink', link, dest)\n                fs.symlink(link, dest, function (err) {\n                  if (err) cancelled = true\n                  done(err)\n                })\n              }))\n            }\n          })\n        })\n      }\n    })\n  }\n}\n",
	"transpiled": true
}; item.content= context.Buffer.from(item.content,'binary'); } return item; })
	fileData.push(function(){return {
	"stat": {
		"mtime": "2019-05-18T07:17:58.978Z",
		"mtimeMs": 1558163878978.4575,
		"atime": "2019-05-18T07:17:58.534Z",
		"atimeMs": 1558163878534.45,
		"isdirectory": true
	},
	"filename": "node_modules"
}})
	fileData.push(function(){return {
	"stat": {
		"mtime": "2019-05-18T07:17:58.590Z",
		"mtimeMs": 1558163878590.451,
		"atime": "2019-05-18T07:17:58.590Z",
		"atimeMs": 1558163878590.451,
		"isdirectory": true
	},
	"filename": "node_modules/buffer-from"
}})
	fileData.push(function(){ var item= cacheData[5]; if(!item){ item= cacheData[5]= {
	"stat": {
		"mtime": "1985-10-26T08:15:00.000Z",
		"mtimeMs": 499162500000,
		"atime": "2019-05-18T07:17:58.595Z",
		"atimeMs": 1558163878595,
		"isfile": true
	},
	"filename": "node_modules/buffer-from/index.js",
	"content": "var toString = Object.prototype.toString\n\nvar isModern = (\n  typeof Buffer.alloc === 'function' &&\n  typeof Buffer.allocUnsafe === 'function' &&\n  typeof Buffer.from === 'function'\n)\n\nfunction isArrayBuffer (input) {\n  return toString.call(input).slice(8, -1) === 'ArrayBuffer'\n}\n\nfunction fromArrayBuffer (obj, byteOffset, length) {\n  byteOffset >>>= 0\n\n  var maxLength = obj.byteLength - byteOffset\n\n  if (maxLength < 0) {\n    throw new RangeError(\"'offset' is out of bounds\")\n  }\n\n  if (length === undefined) {\n    length = maxLength\n  } else {\n    length >>>= 0\n\n    if (length > maxLength) {\n      throw new RangeError(\"'length' is out of bounds\")\n    }\n  }\n\n  return isModern\n    ? Buffer.from(obj.slice(byteOffset, byteOffset + length))\n    : new Buffer(new Uint8Array(obj.slice(byteOffset, byteOffset + length)))\n}\n\nfunction fromString (string, encoding) {\n  if (typeof encoding !== 'string' || encoding === '') {\n    encoding = 'utf8'\n  }\n\n  if (!Buffer.isEncoding(encoding)) {\n    throw new TypeError('\"encoding\" must be a valid string encoding')\n  }\n\n  return isModern\n    ? Buffer.from(string, encoding)\n    : new Buffer(string, encoding)\n}\n\nfunction bufferFrom (value, encodingOrOffset, length) {\n  if (typeof value === 'number') {\n    throw new TypeError('\"value\" argument must not be a number')\n  }\n\n  if (isArrayBuffer(value)) {\n    return fromArrayBuffer(value, encodingOrOffset, length)\n  }\n\n  if (typeof value === 'string') {\n    return fromString(value, encodingOrOffset)\n  }\n\n  return isModern\n    ? Buffer.from(value)\n    : new Buffer(value)\n}\n\nmodule.exports = bufferFrom\n",
	"transpiled": true
}; item.content= context.Buffer.from(item.content,'binary'); } return item; })
	fileData.push(function(){ var item= cacheData[6]; if(!item){ item= cacheData[6]= {
	"stat": {
		"mtime": "1985-10-26T08:15:00.000Z",
		"mtimeMs": 499162500000,
		"atime": "2019-05-18T07:17:58.590Z",
		"atimeMs": 1558163878590.451,
		"isfile": true
	},
	"filename": "node_modules/buffer-from/package.json",
	"content": "{\n  \"name\": \"buffer-from\",\n  \"version\": \"1.1.1\",\n  \"license\": \"MIT\",\n  \"repository\": \"LinusU/buffer-from\",\n  \"files\": [\n    \"index.js\"\n  ],\n  \"scripts\": {\n    \"test\": \"standard && node test\"\n  },\n  \"devDependencies\": {\n    \"standard\": \"^7.1.2\"\n  },\n  \"keywords\": [\n    \"buffer\",\n    \"buffer from\"\n  ]\n}\n",
	"transpiled": true
}; item.content= context.Buffer.from(item.content,'binary'); } return item; })
	fileData.push(function(){return {
	"stat": {
		"mtime": "2019-05-18T07:17:58.538Z",
		"mtimeMs": 1558163878538.45,
		"atime": "2019-05-18T07:17:58.538Z",
		"atimeMs": 1558163878538.45,
		"isdirectory": true
	},
	"filename": "node_modules/concat-stream"
}})
	fileData.push(function(){ var item= cacheData[8]; if(!item){ item= cacheData[8]= {
	"stat": {
		"mtime": "2018-03-21T15:17:02.000Z",
		"mtimeMs": 1521645422000,
		"atime": "2019-05-18T07:17:58.544Z",
		"atimeMs": 1558163878544,
		"isfile": true
	},
	"filename": "node_modules/concat-stream/index.js",
	"content": "var Writable = require('readable-stream').Writable\nvar inherits = require('inherits')\nvar bufferFrom = require('buffer-from')\n\nif (typeof Uint8Array === 'undefined') {\n  var U8 = require('typedarray').Uint8Array\n} else {\n  var U8 = Uint8Array\n}\n\nfunction ConcatStream(opts, cb) {\n  if (!(this instanceof ConcatStream)) return new ConcatStream(opts, cb)\n\n  if (typeof opts === 'function') {\n    cb = opts\n    opts = {}\n  }\n  if (!opts) opts = {}\n\n  var encoding = opts.encoding\n  var shouldInferEncoding = false\n\n  if (!encoding) {\n    shouldInferEncoding = true\n  } else {\n    encoding =  String(encoding).toLowerCase()\n    if (encoding === 'u8' || encoding === 'uint8') {\n      encoding = 'uint8array'\n    }\n  }\n\n  Writable.call(this, { objectMode: true })\n\n  this.encoding = encoding\n  this.shouldInferEncoding = shouldInferEncoding\n\n  if (cb) this.on('finish', function () { cb(this.getBody()) })\n  this.body = []\n}\n\nmodule.exports = ConcatStream\ninherits(ConcatStream, Writable)\n\nConcatStream.prototype._write = function(chunk, enc, next) {\n  this.body.push(chunk)\n  next()\n}\n\nConcatStream.prototype.inferEncoding = function (buff) {\n  var firstBuffer = buff === undefined ? this.body[0] : buff;\n  if (Buffer.isBuffer(firstBuffer)) return 'buffer'\n  if (typeof Uint8Array !== 'undefined' && firstBuffer instanceof Uint8Array) return 'uint8array'\n  if (Array.isArray(firstBuffer)) return 'array'\n  if (typeof firstBuffer === 'string') return 'string'\n  if (Object.prototype.toString.call(firstBuffer) === \"[object Object]\") return 'object'\n  return 'buffer'\n}\n\nConcatStream.prototype.getBody = function () {\n  if (!this.encoding && this.body.length === 0) return []\n  if (this.shouldInferEncoding) this.encoding = this.inferEncoding()\n  if (this.encoding === 'array') return arrayConcat(this.body)\n  if (this.encoding === 'string') return stringConcat(this.body)\n  if (this.encoding === 'buffer') return bufferConcat(this.body)\n  if (this.encoding === 'uint8array') return u8Concat(this.body)\n  return this.body\n}\n\nvar isArray = Array.isArray || function (arr) {\n  return Object.prototype.toString.call(arr) == '[object Array]'\n}\n\nfunction isArrayish (arr) {\n  return /Array\\]$/.test(Object.prototype.toString.call(arr))\n}\n\nfunction isBufferish (p) {\n  return typeof p === 'string' || isArrayish(p) || (p && typeof p.subarray === 'function')\n}\n\nfunction stringConcat (parts) {\n  var strings = []\n  var needsToString = false\n  for (var i = 0; i < parts.length; i++) {\n    var p = parts[i]\n    if (typeof p === 'string') {\n      strings.push(p)\n    } else if (Buffer.isBuffer(p)) {\n      strings.push(p)\n    } else if (isBufferish(p)) {\n      strings.push(bufferFrom(p))\n    } else {\n      strings.push(bufferFrom(String(p)))\n    }\n  }\n  if (Buffer.isBuffer(parts[0])) {\n    strings = Buffer.concat(strings)\n    strings = strings.toString('utf8')\n  } else {\n    strings = strings.join('')\n  }\n  return strings\n}\n\nfunction bufferConcat (parts) {\n  var bufs = []\n  for (var i = 0; i < parts.length; i++) {\n    var p = parts[i]\n    if (Buffer.isBuffer(p)) {\n      bufs.push(p)\n    } else if (isBufferish(p)) {\n      bufs.push(bufferFrom(p))\n    } else {\n      bufs.push(bufferFrom(String(p)))\n    }\n  }\n  return Buffer.concat(bufs)\n}\n\nfunction arrayConcat (parts) {\n  var res = []\n  for (var i = 0; i < parts.length; i++) {\n    res.push.apply(res, parts[i])\n  }\n  return res\n}\n\nfunction u8Concat (parts) {\n  var len = 0\n  for (var i = 0; i < parts.length; i++) {\n    if (typeof parts[i] === 'string') {\n      parts[i] = bufferFrom(parts[i])\n    }\n    len += parts[i].length\n  }\n  var u8 = new U8(len)\n  for (var i = 0, offset = 0; i < parts.length; i++) {\n    var part = parts[i]\n    for (var j = 0; j < part.length; j++) {\n      u8[offset++] = part[j]\n    }\n  }\n  return u8\n}\n",
	"transpiled": true
}; item.content= context.Buffer.from(item.content,'binary'); } return item; })
	fileData.push(function(){ var item= cacheData[9]; if(!item){ item= cacheData[9]= {
	"stat": {
		"mtime": "2018-03-21T15:17:09.000Z",
		"mtimeMs": 1521645429000,
		"atime": "2019-05-18T07:17:58.542Z",
		"atimeMs": 1558163878542.45,
		"isfile": true
	},
	"filename": "node_modules/concat-stream/package.json",
	"content": "{\n  \"name\": \"concat-stream\",\n  \"version\": \"1.6.2\",\n  \"description\": \"writable stream that concatenates strings or binary data and calls a callback with the result\",\n  \"tags\": [\n    \"stream\",\n    \"simple\",\n    \"util\",\n    \"utility\"\n  ],\n  \"author\": \"Max Ogden <max@maxogden.com>\",\n  \"repository\": {\n    \"type\": \"git\",\n    \"url\": \"http://github.com/maxogden/concat-stream.git\"\n  },\n  \"bugs\": {\n    \"url\": \"http://github.com/maxogden/concat-stream/issues\"\n  },\n  \"engines\": [\n    \"node >= 0.8\"\n  ],\n  \"main\": \"index.js\",\n  \"files\": [\n    \"index.js\"\n  ],\n  \"scripts\": {\n    \"test\": \"tape test/*.js test/server/*.js\"\n  },\n  \"license\": \"MIT\",\n  \"dependencies\": {\n    \"buffer-from\": \"^1.0.0\",\n    \"inherits\": \"^2.0.3\",\n    \"readable-stream\": \"^2.2.2\",\n    \"typedarray\": \"^0.0.6\"\n  },\n  \"devDependencies\": {\n    \"tape\": \"^4.6.3\"\n  },\n  \"testling\": {\n    \"files\": \"test/*.js\",\n    \"browsers\": [\n      \"ie/8..latest\",\n      \"firefox/17..latest\",\n      \"firefox/nightly\",\n      \"chrome/22..latest\",\n      \"chrome/canary\",\n      \"opera/12..latest\",\n      \"opera/next\",\n      \"safari/5.1..latest\",\n      \"ipad/6.0..latest\",\n      \"iphone/6.0..latest\",\n      \"android-browser/4.2..latest\"\n    ]\n  }\n}\n",
	"transpiled": true
}; item.content= context.Buffer.from(item.content,'binary'); } return item; })
	fileData.push(function(){return {
	"stat": {
		"mtime": "2019-05-18T07:17:58.690Z",
		"mtimeMs": 1558163878690.4526,
		"atime": "2019-05-18T07:17:58.690Z",
		"atimeMs": 1558163878690.4526,
		"isdirectory": true
	},
	"filename": "node_modules/core-util-is"
}})
	fileData.push(function(){ var item= cacheData[11]; if(!item){ item= cacheData[11]= {
	"stat": {
		"mtime": "2015-11-20T00:23:19.000Z",
		"mtimeMs": 1447978999000,
		"atime": "2019-05-18T07:17:58.696Z",
		"atimeMs": 1558163878696,
		"isfile": true
	},
	"filename": "node_modules/core-util-is/float.patch",
	"content": "diff --git a/lib/util.js b/lib/util.js\nindex a03e874..9074e8e 100644\n--- a/lib/util.js\n+++ b/lib/util.js\n@@ -19,430 +19,6 @@\n // OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE\n // USE OR OTHER DEALINGS IN THE SOFTWARE.\n\n-var formatRegExp = /%[sdj%]/g;\n-exports.format = function(f) {\n-  if (!isString(f)) {\n-    var objects = [];\n-    for (var i = 0; i < arguments.length; i++) {\n-      objects.push(inspect(arguments[i]));\n-    }\n-    return objects.join(' ');\n-  }\n-\n-  var i = 1;\n-  var args = arguments;\n-  var len = args.length;\n-  var str = String(f).replace(formatRegExp, function(x) {\n-    if (x === '%%') return '%';\n-    if (i >= len) return x;\n-    switch (x) {\n-      case '%s': return String(args[i++]);\n-      case '%d': return Number(args[i++]);\n-      case '%j':\n-        try {\n-          return JSON.stringify(args[i++]);\n-        } catch (_) {\n-          return '[Circular]';\n-        }\n-      default:\n-        return x;\n-    }\n-  });\n-  for (var x = args[i]; i < len; x = args[++i]) {\n-    if (isNull(x) || !isObject(x)) {\n-      str += ' ' + x;\n-    } else {\n-      str += ' ' + inspect(x);\n-    }\n-  }\n-  return str;\n-};\n-\n-\n-// Mark that a method should not be used.\n-// Returns a modified function which warns once by default.\n-// If --no-deprecation is set, then it is a no-op.\n-exports.deprecate = function(fn, msg) {\n-  // Allow for deprecating things in the process of starting up.\n-  if (isUndefined(global.process)) {\n-    return function() {\n-      return exports.deprecate(fn, msg).apply(this, arguments);\n-    };\n-  }\n-\n-  if (process.noDeprecation === true) {\n-    return fn;\n-  }\n-\n-  var warned = false;\n-  function deprecated() {\n-    if (!warned) {\n-      if (process.throwDeprecation) {\n-        throw new Error(msg);\n-      } else if (process.traceDeprecation) {\n-        console.trace(msg);\n-      } else {\n-        console.error(msg);\n-      }\n-      warned = true;\n-    }\n-    return fn.apply(this, arguments);\n-  }\n-\n-  return deprecated;\n-};\n-\n-\n-var debugs = {};\n-var debugEnviron;\n-exports.debuglog = function(set) {\n-  if (isUndefined(debugEnviron))\n-    debugEnviron = process.env.NODE_DEBUG || '';\n-  set = set.toUpperCase();\n-  if (!debugs[set]) {\n-    if (new RegExp('\\\\b' + set + '\\\\b', 'i').test(debugEnviron)) {\n-      var pid = process.pid;\n-      debugs[set] = function() {\n-        var msg = exports.format.apply(exports, arguments);\n-        console.error('%s %d: %s', set, pid, msg);\n-      };\n-    } else {\n-      debugs[set] = function() {};\n-    }\n-  }\n-  return debugs[set];\n-};\n-\n-\n-/**\n- * Echos the value of a value. Trys to print the value out\n- * in the best way possible given the different types.\n- *\n- * @param {Object} obj The object to print out.\n- * @param {Object} opts Optional options object that alters the output.\n- */\n-/* legacy: obj, showHidden, depth, colors*/\n-function inspect(obj, opts) {\n-  // default options\n-  var ctx = {\n-    seen: [],\n-    stylize: stylizeNoColor\n-  };\n-  // legacy...\n-  if (arguments.length >= 3) ctx.depth = arguments[2];\n-  if (arguments.length >= 4) ctx.colors = arguments[3];\n-  if (isBoolean(opts)) {\n-    // legacy...\n-    ctx.showHidden = opts;\n-  } else if (opts) {\n-    // got an \"options\" object\n-    exports._extend(ctx, opts);\n-  }\n-  // set default options\n-  if (isUndefined(ctx.showHidden)) ctx.showHidden = false;\n-  if (isUndefined(ctx.depth)) ctx.depth = 2;\n-  if (isUndefined(ctx.colors)) ctx.colors = false;\n-  if (isUndefined(ctx.customInspect)) ctx.customInspect = true;\n-  if (ctx.colors) ctx.stylize = stylizeWithColor;\n-  return formatValue(ctx, obj, ctx.depth);\n-}\n-exports.inspect = inspect;\n-\n-\n-// http://en.wikipedia.org/wiki/ANSI_escape_code#graphics\n-inspect.colors = {\n-  'bold' : [1, 22],\n-  'italic' : [3, 23],\n-  'underline' : [4, 24],\n-  'inverse' : [7, 27],\n-  'white' : [37, 39],\n-  'grey' : [90, 39],\n-  'black' : [30, 39],\n-  'blue' : [34, 39],\n-  'cyan' : [36, 39],\n-  'green' : [32, 39],\n-  'magenta' : [35, 39],\n-  'red' : [31, 39],\n-  'yellow' : [33, 39]\n-};\n-\n-// Don't use 'blue' not visible on cmd.exe\n-inspect.styles = {\n-  'special': 'cyan',\n-  'number': 'yellow',\n-  'boolean': 'yellow',\n-  'undefined': 'grey',\n-  'null': 'bold',\n-  'string': 'green',\n-  'date': 'magenta',\n-  // \"name\": intentionally not styling\n-  'regexp': 'red'\n-};\n-\n-\n-function stylizeWithColor(str, styleType) {\n-  var style = inspect.styles[styleType];\n-\n-  if (style) {\n-    return '\\u001b[' + inspect.colors[style][0] + 'm' + str +\n-           '\\u001b[' + inspect.colors[style][1] + 'm';\n-  } else {\n-    return str;\n-  }\n-}\n-\n-\n-function stylizeNoColor(str, styleType) {\n-  return str;\n-}\n-\n-\n-function arrayToHash(array) {\n-  var hash = {};\n-\n-  array.forEach(function(val, idx) {\n-    hash[val] = true;\n-  });\n-\n-  return hash;\n-}\n-\n-\n-function formatValue(ctx, value, recurseTimes) {\n-  // Provide a hook for user-specified inspect functions.\n-  // Check that value is an object with an inspect function on it\n-  if (ctx.customInspect &&\n-      value &&\n-      isFunction(value.inspect) &&\n-      // Filter out the util module, it's inspect function is special\n-      value.inspect !== exports.inspect &&\n-      // Also filter out any prototype objects using the circular check.\n-      !(value.constructor && value.constructor.prototype === value)) {\n-    var ret = value.inspect(recurseTimes, ctx);\n-    if (!isString(ret)) {\n-      ret = formatValue(ctx, ret, recurseTimes);\n-    }\n-    return ret;\n-  }\n-\n-  // Primitive types cannot have properties\n-  var primitive = formatPrimitive(ctx, value);\n-  if (primitive) {\n-    return primitive;\n-  }\n-\n-  // Look up the keys of the object.\n-  var keys = Object.keys(value);\n-  var visibleKeys = arrayToHash(keys);\n-\n-  if (ctx.showHidden) {\n-    keys = Object.getOwnPropertyNames(value);\n-  }\n-\n-  // Some type of object without properties can be shortcutted.\n-  if (keys.length === 0) {\n-    if (isFunction(value)) {\n-      var name = value.name ? ': ' + value.name : '';\n-      return ctx.stylize('[Function' + name + ']', 'special');\n-    }\n-    if (isRegExp(value)) {\n-      return ctx.stylize(RegExp.prototype.toString.call(value), 'regexp');\n-    }\n-    if (isDate(value)) {\n-      return ctx.stylize(Date.prototype.toString.call(value), 'date');\n-    }\n-    if (isError(value)) {\n-      return formatError(value);\n-    }\n-  }\n-\n-  var base = '', array = false, braces = ['{', '}'];\n-\n-  // Make Array say that they are Array\n-  if (isArray(value)) {\n-    array = true;\n-    braces = ['[', ']'];\n-  }\n-\n-  // Make functions say that they are functions\n-  if (isFunction(value)) {\n-    var n = value.name ? ': ' + value.name : '';\n-    base = ' [Function' + n + ']';\n-  }\n-\n-  // Make RegExps say that they are RegExps\n-  if (isRegExp(value)) {\n-    base = ' ' + RegExp.prototype.toString.call(value);\n-  }\n-\n-  // Make dates with properties first say the date\n-  if (isDate(value)) {\n-    base = ' ' + Date.prototype.toUTCString.call(value);\n-  }\n-\n-  // Make error with message first say the error\n-  if (isError(value)) {\n-    base = ' ' + formatError(value);\n-  }\n-\n-  if (keys.length === 0 && (!array || value.length == 0)) {\n-    return braces[0] + base + braces[1];\n-  }\n-\n-  if (recurseTimes < 0) {\n-    if (isRegExp(value)) {\n-      return ctx.stylize(RegExp.prototype.toString.call(value), 'regexp');\n-    } else {\n-      return ctx.stylize('[Object]', 'special');\n-    }\n-  }\n-\n-  ctx.seen.push(value);\n-\n-  var output;\n-  if (array) {\n-    output = formatArray(ctx, value, recurseTimes, visibleKeys, keys);\n-  } else {\n-    output = keys.map(function(key) {\n-      return formatProperty(ctx, value, recurseTimes, visibleKeys, key, array);\n-    });\n-  }\n-\n-  ctx.seen.pop();\n-\n-  return reduceToSingleString(output, base, braces);\n-}\n-\n-\n-function formatPrimitive(ctx, value) {\n-  if (isUndefined(value))\n-    return ctx.stylize('undefined', 'undefined');\n-  if (isString(value)) {\n-    var simple = '\\'' + JSON.stringify(value).replace(/^\"|\"$/g, '')\n-                                             .replace(/'/g, \"\\\\'\")\n-                                             .replace(/\\\\\"/g, '\"') + '\\'';\n-    return ctx.stylize(simple, 'string');\n-  }\n-  if (isNumber(value)) {\n-    // Format -0 as '-0'. Strict equality won't distinguish 0 from -0,\n-    // so instead we use the fact that 1 / -0 < 0 whereas 1 / 0 > 0 .\n-    if (value === 0 && 1 / value < 0)\n-      return ctx.stylize('-0', 'number');\n-    return ctx.stylize('' + value, 'number');\n-  }\n-  if (isBoolean(value))\n-    return ctx.stylize('' + value, 'boolean');\n-  // For some reason typeof null is \"object\", so special case here.\n-  if (isNull(value))\n-    return ctx.stylize('null', 'null');\n-}\n-\n-\n-function formatError(value) {\n-  return '[' + Error.prototype.toString.call(value) + ']';\n-}\n-\n-\n-function formatArray(ctx, value, recurseTimes, visibleKeys, keys) {\n-  var output = [];\n-  for (var i = 0, l = value.length; i < l; ++i) {\n-    if (hasOwnProperty(value, String(i))) {\n-      output.push(formatProperty(ctx, value, recurseTimes, visibleKeys,\n-          String(i), true));\n-    } else {\n-      output.push('');\n-    }\n-  }\n-  keys.forEach(function(key) {\n-    if (!key.match(/^\\d+$/)) {\n-      output.push(formatProperty(ctx, value, recurseTimes, visibleKeys,\n-          key, true));\n-    }\n-  });\n-  return output;\n-}\n-\n-\n-function formatProperty(ctx, value, recurseTimes, visibleKeys, key, array) {\n-  var name, str, desc;\n-  desc = Object.getOwnPropertyDescriptor(value, key) || { value: value[key] };\n-  if (desc.get) {\n-    if (desc.set) {\n-      str = ctx.stylize('[Getter/Setter]', 'special');\n-    } else {\n-      str = ctx.stylize('[Getter]', 'special');\n-    }\n-  } else {\n-    if (desc.set) {\n-      str = ctx.stylize('[Setter]', 'special');\n-    }\n-  }\n-  if (!hasOwnProperty(visibleKeys, key)) {\n-    name = '[' + key + ']';\n-  }\n-  if (!str) {\n-    if (ctx.seen.indexOf(desc.value) < 0) {\n-      if (isNull(recurseTimes)) {\n-        str = formatValue(ctx, desc.value, null);\n-      } else {\n-        str = formatValue(ctx, desc.value, recurseTimes - 1);\n-      }\n-      if (str.indexOf('\\n') > -1) {\n-        if (array) {\n-          str = str.split('\\n').map(function(line) {\n-            return '  ' + line;\n-          }).join('\\n').substr(2);\n-        } else {\n-          str = '\\n' + str.split('\\n').map(function(line) {\n-            return '   ' + line;\n-          }).join('\\n');\n-        }\n-      }\n-    } else {\n-      str = ctx.stylize('[Circular]', 'special');\n-    }\n-  }\n-  if (isUndefined(name)) {\n-    if (array && key.match(/^\\d+$/)) {\n-      return str;\n-    }\n-    name = JSON.stringify('' + key);\n-    if (name.match(/^\"([a-zA-Z_][a-zA-Z_0-9]*)\"$/)) {\n-      name = name.substr(1, name.length - 2);\n-      name = ctx.stylize(name, 'name');\n-    } else {\n-      name = name.replace(/'/g, \"\\\\'\")\n-                 .replace(/\\\\\"/g, '\"')\n-                 .replace(/(^\"|\"$)/g, \"'\");\n-      name = ctx.stylize(name, 'string');\n-    }\n-  }\n-\n-  return name + ': ' + str;\n-}\n-\n-\n-function reduceToSingleString(output, base, braces) {\n-  var numLinesEst = 0;\n-  var length = output.reduce(function(prev, cur) {\n-    numLinesEst++;\n-    if (cur.indexOf('\\n') >= 0) numLinesEst++;\n-    return prev + cur.replace(/\\u001b\\[\\d\\d?m/g, '').length + 1;\n-  }, 0);\n-\n-  if (length > 60) {\n-    return braces[0] +\n-           (base === '' ? '' : base + '\\n ') +\n-           ' ' +\n-           output.join(',\\n  ') +\n-           ' ' +\n-           braces[1];\n-  }\n-\n-  return braces[0] + base + ' ' + output.join(', ') + ' ' + braces[1];\n-}\n-\n-\n // NOTE: These type checking functions intentionally don't use `instanceof`\n // because it is fragile and can be easily faked with `Object.create()`.\n function isArray(ar) {\n@@ -522,166 +98,10 @@ function isPrimitive(arg) {\n exports.isPrimitive = isPrimitive;\n\n function isBuffer(arg) {\n-  return arg instanceof Buffer;\n+  return Buffer.isBuffer(arg);\n }\n exports.isBuffer = isBuffer;\n\n function objectToString(o) {\n   return Object.prototype.toString.call(o);\n-}\n-\n-\n-function pad(n) {\n-  return n < 10 ? '0' + n.toString(10) : n.toString(10);\n-}\n-\n-\n-var months = ['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun', 'Jul', 'Aug', 'Sep',\n-              'Oct', 'Nov', 'Dec'];\n-\n-// 26 Feb 16:19:34\n-function timestamp() {\n-  var d = new Date();\n-  var time = [pad(d.getHours()),\n-              pad(d.getMinutes()),\n-              pad(d.getSeconds())].join(':');\n-  return [d.getDate(), months[d.getMonth()], time].join(' ');\n-}\n-\n-\n-// log is just a thin wrapper to console.log that prepends a timestamp\n-exports.log = function() {\n-  console.log('%s - %s', timestamp(), exports.format.apply(exports, arguments));\n-};\n-\n-\n-/**\n- * Inherit the prototype methods from one constructor into another.\n- *\n- * The Function.prototype.inherits from lang.js rewritten as a standalone\n- * function (not on Function.prototype). NOTE: If this file is to be loaded\n- * during bootstrapping this function needs to be rewritten using some native\n- * functions as prototype setup using normal JavaScript does not work as\n- * expected during bootstrapping (see mirror.js in r114903).\n- *\n- * @param {function} ctor Constructor function which needs to inherit the\n- *     prototype.\n- * @param {function} superCtor Constructor function to inherit prototype from.\n- */\n-exports.inherits = function(ctor, superCtor) {\n-  ctor.super_ = superCtor;\n-  ctor.prototype = Object.create(superCtor.prototype, {\n-    constructor: {\n-      value: ctor,\n-      enumerable: false,\n-      writable: true,\n-      configurable: true\n-    }\n-  });\n-};\n-\n-exports._extend = function(origin, add) {\n-  // Don't do anything if add isn't an object\n-  if (!add || !isObject(add)) return origin;\n-\n-  var keys = Object.keys(add);\n-  var i = keys.length;\n-  while (i--) {\n-    origin[keys[i]] = add[keys[i]];\n-  }\n-  return origin;\n-};\n-\n-function hasOwnProperty(obj, prop) {\n-  return Object.prototype.hasOwnProperty.call(obj, prop);\n-}\n-\n-\n-// Deprecated old stuff.\n-\n-exports.p = exports.deprecate(function() {\n-  for (var i = 0, len = arguments.length; i < len; ++i) {\n-    console.error(exports.inspect(arguments[i]));\n-  }\n-}, 'util.p: Use console.error() instead');\n-\n-\n-exports.exec = exports.deprecate(function() {\n-  return require('child_process').exec.apply(this, arguments);\n-}, 'util.exec is now called `child_process.exec`.');\n-\n-\n-exports.print = exports.deprecate(function() {\n-  for (var i = 0, len = arguments.length; i < len; ++i) {\n-    process.stdout.write(String(arguments[i]));\n-  }\n-}, 'util.print: Use console.log instead');\n-\n-\n-exports.puts = exports.deprecate(function() {\n-  for (var i = 0, len = arguments.length; i < len; ++i) {\n-    process.stdout.write(arguments[i] + '\\n');\n-  }\n-}, 'util.puts: Use console.log instead');\n-\n-\n-exports.debug = exports.deprecate(function(x) {\n-  process.stderr.write('DEBUG: ' + x + '\\n');\n-}, 'util.debug: Use console.error instead');\n-\n-\n-exports.error = exports.deprecate(function(x) {\n-  for (var i = 0, len = arguments.length; i < len; ++i) {\n-    process.stderr.write(arguments[i] + '\\n');\n-  }\n-}, 'util.error: Use console.error instead');\n-\n-\n-exports.pump = exports.deprecate(function(readStream, writeStream, callback) {\n-  var callbackCalled = false;\n-\n-  function call(a, b, c) {\n-    if (callback && !callbackCalled) {\n-      callback(a, b, c);\n-      callbackCalled = true;\n-    }\n-  }\n-\n-  readStream.addListener('data', function(chunk) {\n-    if (writeStream.write(chunk) === false) readStream.pause();\n-  });\n-\n-  writeStream.addListener('drain', function() {\n-    readStream.resume();\n-  });\n-\n-  readStream.addListener('end', function() {\n-    writeStream.end();\n-  });\n-\n-  readStream.addListener('close', function() {\n-    call();\n-  });\n-\n-  readStream.addListener('error', function(err) {\n-    writeStream.end();\n-    call(err);\n-  });\n-\n-  writeStream.addListener('error', function(err) {\n-    readStream.destroy();\n-    call(err);\n-  });\n-}, 'util.pump(): Use readableStream.pipe() instead');\n-\n-\n-var uv;\n-exports._errnoException = function(err, syscall) {\n-  if (isUndefined(uv)) uv = process.binding('uv');\n-  var errname = uv.errname(err);\n-  var e = new Error(syscall + ' ' + errname);\n-  e.code = errname;\n-  e.errno = errname;\n-  e.syscall = syscall;\n-  return e;\n-};\n+}",
	"transpiled": true
}; item.content= context.Buffer.from(item.content,'binary'); } return item; })
	fileData.push(function(){return {
	"stat": {
		"mtime": "2019-05-18T07:17:58.690Z",
		"mtimeMs": 1558163878690.4526,
		"atime": "2019-05-18T07:17:58.690Z",
		"atimeMs": 1558163878690.4526,
		"isdirectory": true
	},
	"filename": "node_modules/core-util-is/lib"
}})
	fileData.push(function(){ var item= cacheData[13]; if(!item){ item= cacheData[13]= {
	"stat": {
		"mtime": "2015-11-20T00:37:20.000Z",
		"mtimeMs": 1447979840000,
		"atime": "2019-05-18T07:17:58.696Z",
		"atimeMs": 1558163878696,
		"isfile": true
	},
	"filename": "node_modules/core-util-is/lib/util.js",
	"content": "// Copyright Joyent, Inc. and other Node contributors.\n//\n// Permission is hereby granted, free of charge, to any person obtaining a\n// copy of this software and associated documentation files (the\n// \"Software\"), to deal in the Software without restriction, including\n// without limitation the rights to use, copy, modify, merge, publish,\n// distribute, sublicense, and/or sell copies of the Software, and to permit\n// persons to whom the Software is furnished to do so, subject to the\n// following conditions:\n//\n// The above copyright notice and this permission notice shall be included\n// in all copies or substantial portions of the Software.\n//\n// THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS\n// OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF\n// MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN\n// NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM,\n// DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR\n// OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE\n// USE OR OTHER DEALINGS IN THE SOFTWARE.\n\n// NOTE: These type checking functions intentionally don't use `instanceof`\n// because it is fragile and can be easily faked with `Object.create()`.\n\nfunction isArray(arg) {\n  if (Array.isArray) {\n    return Array.isArray(arg);\n  }\n  return objectToString(arg) === '[object Array]';\n}\nexports.isArray = isArray;\n\nfunction isBoolean(arg) {\n  return typeof arg === 'boolean';\n}\nexports.isBoolean = isBoolean;\n\nfunction isNull(arg) {\n  return arg === null;\n}\nexports.isNull = isNull;\n\nfunction isNullOrUndefined(arg) {\n  return arg == null;\n}\nexports.isNullOrUndefined = isNullOrUndefined;\n\nfunction isNumber(arg) {\n  return typeof arg === 'number';\n}\nexports.isNumber = isNumber;\n\nfunction isString(arg) {\n  return typeof arg === 'string';\n}\nexports.isString = isString;\n\nfunction isSymbol(arg) {\n  return typeof arg === 'symbol';\n}\nexports.isSymbol = isSymbol;\n\nfunction isUndefined(arg) {\n  return arg === void 0;\n}\nexports.isUndefined = isUndefined;\n\nfunction isRegExp(re) {\n  return objectToString(re) === '[object RegExp]';\n}\nexports.isRegExp = isRegExp;\n\nfunction isObject(arg) {\n  return typeof arg === 'object' && arg !== null;\n}\nexports.isObject = isObject;\n\nfunction isDate(d) {\n  return objectToString(d) === '[object Date]';\n}\nexports.isDate = isDate;\n\nfunction isError(e) {\n  return (objectToString(e) === '[object Error]' || e instanceof Error);\n}\nexports.isError = isError;\n\nfunction isFunction(arg) {\n  return typeof arg === 'function';\n}\nexports.isFunction = isFunction;\n\nfunction isPrimitive(arg) {\n  return arg === null ||\n         typeof arg === 'boolean' ||\n         typeof arg === 'number' ||\n         typeof arg === 'string' ||\n         typeof arg === 'symbol' ||  // ES6 symbol\n         typeof arg === 'undefined';\n}\nexports.isPrimitive = isPrimitive;\n\nexports.isBuffer = Buffer.isBuffer;\n\nfunction objectToString(o) {\n  return Object.prototype.toString.call(o);\n}\n",
	"transpiled": true
}; item.content= context.Buffer.from(item.content,'binary'); } return item; })
	fileData.push(function(){ var item= cacheData[14]; if(!item){ item= cacheData[14]= {
	"stat": {
		"mtime": "2015-11-20T00:37:23.000Z",
		"mtimeMs": 1447979843000,
		"atime": "2019-05-18T07:17:58.694Z",
		"atimeMs": 1558163878694.4526,
		"isfile": true
	},
	"filename": "node_modules/core-util-is/package.json",
	"content": "{\n  \"name\": \"core-util-is\",\n  \"version\": \"1.0.2\",\n  \"description\": \"The `util.is*` functions introduced in Node v0.12.\",\n  \"main\": \"lib/util.js\",\n  \"repository\": {\n    \"type\": \"git\",\n    \"url\": \"git://github.com/isaacs/core-util-is\"\n  },\n  \"keywords\": [\n    \"util\",\n    \"isBuffer\",\n    \"isArray\",\n    \"isNumber\",\n    \"isString\",\n    \"isRegExp\",\n    \"isThis\",\n    \"isThat\",\n    \"polyfill\"\n  ],\n  \"author\": \"Isaac Z. Schlueter <i@izs.me> (http://blog.izs.me/)\",\n  \"license\": \"MIT\",\n  \"bugs\": {\n    \"url\": \"https://github.com/isaacs/core-util-is/issues\"\n  },\n  \"scripts\": {\n    \"test\": \"tap test.js\"\n  },\n  \"devDependencies\": {\n    \"tap\": \"^2.3.0\"\n  }\n}\n",
	"transpiled": true
}; item.content= context.Buffer.from(item.content,'binary'); } return item; })
	fileData.push(function(){ var item= cacheData[15]; if(!item){ item= cacheData[15]= {
	"stat": {
		"mtime": "2015-11-20T00:29:18.000Z",
		"mtimeMs": 1447979358000,
		"atime": "2019-05-18T07:17:58.696Z",
		"atimeMs": 1558163878696,
		"isfile": true
	},
	"filename": "node_modules/core-util-is/test.js",
	"content": "var assert = require('tap');\n\nvar t = require('./lib/util');\n\nassert.equal(t.isArray([]), true);\nassert.equal(t.isArray({}), false);\n\nassert.equal(t.isBoolean(null), false);\nassert.equal(t.isBoolean(true), true);\nassert.equal(t.isBoolean(false), true);\n\nassert.equal(t.isNull(null), true);\nassert.equal(t.isNull(undefined), false);\nassert.equal(t.isNull(false), false);\nassert.equal(t.isNull(), false);\n\nassert.equal(t.isNullOrUndefined(null), true);\nassert.equal(t.isNullOrUndefined(undefined), true);\nassert.equal(t.isNullOrUndefined(false), false);\nassert.equal(t.isNullOrUndefined(), true);\n\nassert.equal(t.isNumber(null), false);\nassert.equal(t.isNumber('1'), false);\nassert.equal(t.isNumber(1), true);\n\nassert.equal(t.isString(null), false);\nassert.equal(t.isString('1'), true);\nassert.equal(t.isString(1), false);\n\nassert.equal(t.isSymbol(null), false);\nassert.equal(t.isSymbol('1'), false);\nassert.equal(t.isSymbol(1), false);\nassert.equal(t.isSymbol(Symbol()), true);\n\nassert.equal(t.isUndefined(null), false);\nassert.equal(t.isUndefined(undefined), true);\nassert.equal(t.isUndefined(false), false);\nassert.equal(t.isUndefined(), true);\n\nassert.equal(t.isRegExp(null), false);\nassert.equal(t.isRegExp('1'), false);\nassert.equal(t.isRegExp(new RegExp()), true);\n\nassert.equal(t.isObject({}), true);\nassert.equal(t.isObject([]), true);\nassert.equal(t.isObject(new RegExp()), true);\nassert.equal(t.isObject(new Date()), true);\n\nassert.equal(t.isDate(null), false);\nassert.equal(t.isDate('1'), false);\nassert.equal(t.isDate(new Date()), true);\n\nassert.equal(t.isError(null), false);\nassert.equal(t.isError({ err: true }), false);\nassert.equal(t.isError(new Error()), true);\n\nassert.equal(t.isFunction(null), false);\nassert.equal(t.isFunction({ }), false);\nassert.equal(t.isFunction(function() {}), true);\n\nassert.equal(t.isPrimitive(null), true);\nassert.equal(t.isPrimitive(''), true);\nassert.equal(t.isPrimitive(0), true);\nassert.equal(t.isPrimitive(new Date()), false);\n\nassert.equal(t.isBuffer(null), false);\nassert.equal(t.isBuffer({}), false);\nassert.equal(t.isBuffer(new Buffer(0)), true);\n",
	"transpiled": true
}; item.content= context.Buffer.from(item.content,'binary'); } return item; })
	fileData.push(function(){return {
	"stat": {
		"mtime": "2019-05-18T07:17:58.906Z",
		"mtimeMs": 1558163878906.4563,
		"atime": "2019-05-18T07:17:58.906Z",
		"atimeMs": 1558163878906.4563,
		"isdirectory": true
	},
	"filename": "node_modules/debug"
}})
	fileData.push(function(){ var item= cacheData[17]; if(!item){ item= cacheData[17]= {
	"stat": {
		"mtime": "2017-09-22T13:29:26.000Z",
		"mtimeMs": 1506086966000,
		"atime": "2019-05-18T07:17:58.912Z",
		"atimeMs": 1558163878912,
		"isfile": true
	},
	"filename": "node_modules/debug/Makefile",
	"content": "# get Makefile directory name: http://stackoverflow.com/a/5982798/376773\nTHIS_MAKEFILE_PATH:=$(word $(words $(MAKEFILE_LIST)),$(MAKEFILE_LIST))\nTHIS_DIR:=$(shell cd $(dir $(THIS_MAKEFILE_PATH));pwd)\n\n# BIN directory\nBIN := $(THIS_DIR)/node_modules/.bin\n\n# Path\nPATH := node_modules/.bin:$(PATH)\nSHELL := /bin/bash\n\n# applications\nNODE ?= $(shell which node)\nYARN ?= $(shell which yarn)\nPKG ?= $(if $(YARN),$(YARN),$(NODE) $(shell which npm))\nBROWSERIFY ?= $(NODE) $(BIN)/browserify\n\n.FORCE:\n\ninstall: node_modules\n\nnode_modules: package.json\n\t@NODE_ENV= $(PKG) install\n\t@touch node_modules\n\nlint: .FORCE\n\teslint browser.js debug.js index.js node.js\n\ntest-node: .FORCE\n\tistanbul cover node_modules/mocha/bin/_mocha -- test/**.js\n\ntest-browser: .FORCE\n\tmkdir -p dist\n\n\t@$(BROWSERIFY) \\\n\t\t--standalone debug \\\n\t\t. > dist/debug.js\n\n\tkarma start --single-run\n\trimraf dist\n\ntest: .FORCE\n\tconcurrently \\\n\t\t\"make test-node\" \\\n\t\t\"make test-browser\"\n\ncoveralls:\n\tcat ./coverage/lcov.info | ./node_modules/coveralls/bin/coveralls.js\n\n.PHONY: all install clean distclean\n",
	"transpiled": true
}; item.content= context.Buffer.from(item.content,'binary'); } return item; })
	fileData.push(function(){ var item= cacheData[18]; if(!item){ item= cacheData[18]= {
	"stat": {
		"mtime": "2017-09-22T13:32:09.000Z",
		"mtimeMs": 1506087129000,
		"atime": "2019-05-18T07:17:58.912Z",
		"atimeMs": 1558163878912,
		"isfile": true
	},
	"filename": "node_modules/debug/component.json",
	"content": "{\n  \"name\": \"debug\",\n  \"repo\": \"visionmedia/debug\",\n  \"description\": \"small debugging utility\",\n  \"version\": \"2.6.9\",\n  \"keywords\": [\n    \"debug\",\n    \"log\",\n    \"debugger\"\n  ],\n  \"main\": \"src/browser.js\",\n  \"scripts\": [\n    \"src/browser.js\",\n    \"src/debug.js\"\n  ],\n  \"dependencies\": {\n    \"rauchg/ms.js\": \"0.7.1\"\n  }\n}\n",
	"transpiled": true
}; item.content= context.Buffer.from(item.content,'binary'); } return item; })
	fileData.push(function(){ var item= cacheData[19]; if(!item){ item= cacheData[19]= {
	"stat": {
		"mtime": "2017-06-15T00:16:23.000Z",
		"mtimeMs": 1497485783000,
		"atime": "2019-05-18T07:17:58.912Z",
		"atimeMs": 1558163878912,
		"isfile": true
	},
	"filename": "node_modules/debug/karma.conf.js",
	"content": "// Karma configuration\n// Generated on Fri Dec 16 2016 13:09:51 GMT+0000 (UTC)\n\nmodule.exports = function(config) {\n  config.set({\n\n    // base path that will be used to resolve all patterns (eg. files, exclude)\n    basePath: '',\n\n\n    // frameworks to use\n    // available frameworks: https://npmjs.org/browse/keyword/karma-adapter\n    frameworks: ['mocha', 'chai', 'sinon'],\n\n\n    // list of files / patterns to load in the browser\n    files: [\n      'dist/debug.js',\n      'test/*spec.js'\n    ],\n\n\n    // list of files to exclude\n    exclude: [\n      'src/node.js'\n    ],\n\n\n    // preprocess matching files before serving them to the browser\n    // available preprocessors: https://npmjs.org/browse/keyword/karma-preprocessor\n    preprocessors: {\n    },\n\n    // test results reporter to use\n    // possible values: 'dots', 'progress'\n    // available reporters: https://npmjs.org/browse/keyword/karma-reporter\n    reporters: ['progress'],\n\n\n    // web server port\n    port: 9876,\n\n\n    // enable / disable colors in the output (reporters and logs)\n    colors: true,\n\n\n    // level of logging\n    // possible values: config.LOG_DISABLE || config.LOG_ERROR || config.LOG_WARN || config.LOG_INFO || config.LOG_DEBUG\n    logLevel: config.LOG_INFO,\n\n\n    // enable / disable watching file and executing tests whenever any file changes\n    autoWatch: true,\n\n\n    // start these browsers\n    // available browser launchers: https://npmjs.org/browse/keyword/karma-launcher\n    browsers: ['PhantomJS'],\n\n\n    // Continuous Integration mode\n    // if true, Karma captures browsers, runs the tests and exits\n    singleRun: false,\n\n    // Concurrency level\n    // how many browser should be started simultaneous\n    concurrency: Infinity\n  })\n}\n",
	"transpiled": true
}; item.content= context.Buffer.from(item.content,'binary'); } return item; })
	fileData.push(function(){ var item= cacheData[20]; if(!item){ item= cacheData[20]= {
	"stat": {
		"mtime": "2017-06-15T00:16:23.000Z",
		"mtimeMs": 1497485783000,
		"atime": "2019-05-18T07:17:58.912Z",
		"atimeMs": 1558163878912,
		"isfile": true
	},
	"filename": "node_modules/debug/node.js",
	"content": "module.exports = require('./src/node');\n",
	"transpiled": true
}; item.content= context.Buffer.from(item.content,'binary'); } return item; })
	fileData.push(function(){ var item= cacheData[21]; if(!item){ item= cacheData[21]= {
	"stat": {
		"mtime": "2017-09-22T13:32:09.000Z",
		"mtimeMs": 1506087129000,
		"atime": "2019-05-18T07:17:58.910Z",
		"atimeMs": 1558163878910.4563,
		"isfile": true
	},
	"filename": "node_modules/debug/package.json",
	"content": "{\n  \"name\": \"debug\",\n  \"version\": \"2.6.9\",\n  \"repository\": {\n    \"type\": \"git\",\n    \"url\": \"git://github.com/visionmedia/debug.git\"\n  },\n  \"description\": \"small debugging utility\",\n  \"keywords\": [\n    \"debug\",\n    \"log\",\n    \"debugger\"\n  ],\n  \"author\": \"TJ Holowaychuk <tj@vision-media.ca>\",\n  \"contributors\": [\n    \"Nathan Rajlich <nathan@tootallnate.net> (http://n8.io)\",\n    \"Andrew Rhyne <rhyneandrew@gmail.com>\"\n  ],\n  \"license\": \"MIT\",\n  \"dependencies\": {\n    \"ms\": \"2.0.0\"\n  },\n  \"devDependencies\": {\n    \"browserify\": \"9.0.3\",\n    \"chai\": \"^3.5.0\",\n    \"concurrently\": \"^3.1.0\",\n    \"coveralls\": \"^2.11.15\",\n    \"eslint\": \"^3.12.1\",\n    \"istanbul\": \"^0.4.5\",\n    \"karma\": \"^1.3.0\",\n    \"karma-chai\": \"^0.1.0\",\n    \"karma-mocha\": \"^1.3.0\",\n    \"karma-phantomjs-launcher\": \"^1.0.2\",\n    \"karma-sinon\": \"^1.0.5\",\n    \"mocha\": \"^3.2.0\",\n    \"mocha-lcov-reporter\": \"^1.2.0\",\n    \"rimraf\": \"^2.5.4\",\n    \"sinon\": \"^1.17.6\",\n    \"sinon-chai\": \"^2.8.0\"\n  },\n  \"main\": \"./src/index.js\",\n  \"browser\": \"./src/browser.js\",\n  \"component\": {\n    \"scripts\": {\n      \"debug/index.js\": \"browser.js\",\n      \"debug/debug.js\": \"debug.js\"\n    }\n  }\n}\n",
	"transpiled": true
}; item.content= context.Buffer.from(item.content,'binary'); } return item; })
	fileData.push(function(){return {
	"stat": {
		"mtime": "2019-05-18T07:17:58.906Z",
		"mtimeMs": 1558163878906.4563,
		"atime": "2019-05-18T07:17:58.906Z",
		"atimeMs": 1558163878906.4563,
		"isdirectory": true
	},
	"filename": "node_modules/debug/src"
}})
	fileData.push(function(){ var item= cacheData[23]; if(!item){ item= cacheData[23]= {
	"stat": {
		"mtime": "2017-09-22T13:29:26.000Z",
		"mtimeMs": 1506086966000,
		"atime": "2019-05-18T07:17:58.912Z",
		"atimeMs": 1558163878912,
		"isfile": true
	},
	"filename": "node_modules/debug/src/browser.js",
	"content": "/**\n * This is the web browser implementation of `debug()`.\n *\n * Expose `debug()` as the module.\n */\n\nexports = module.exports = require('./debug');\nexports.log = log;\nexports.formatArgs = formatArgs;\nexports.save = save;\nexports.load = load;\nexports.useColors = useColors;\nexports.storage = 'undefined' != typeof chrome\n               && 'undefined' != typeof chrome.storage\n                  ? chrome.storage.local\n                  : localstorage();\n\n/**\n * Colors.\n */\n\nexports.colors = [\n  'lightseagreen',\n  'forestgreen',\n  'goldenrod',\n  'dodgerblue',\n  'darkorchid',\n  'crimson'\n];\n\n/**\n * Currently only WebKit-based Web Inspectors, Firefox >= v31,\n * and the Firebug extension (any Firefox version) are known\n * to support \"%c\" CSS customizations.\n *\n * TODO: add a `localStorage` variable to explicitly enable/disable colors\n */\n\nfunction useColors() {\n  // NB: In an Electron preload script, document will be defined but not fully\n  // initialized. Since we know we're in Chrome, we'll just detect this case\n  // explicitly\n  if (typeof window !== 'undefined' && window.process && window.process.type === 'renderer') {\n    return true;\n  }\n\n  // is webkit? http://stackoverflow.com/a/16459606/376773\n  // document is undefined in react-native: https://github.com/facebook/react-native/pull/1632\n  return (typeof document !== 'undefined' && document.documentElement && document.documentElement.style && document.documentElement.style.WebkitAppearance) ||\n    // is firebug? http://stackoverflow.com/a/398120/376773\n    (typeof window !== 'undefined' && window.console && (window.console.firebug || (window.console.exception && window.console.table))) ||\n    // is firefox >= v31?\n    // https://developer.mozilla.org/en-US/docs/Tools/Web_Console#Styling_messages\n    (typeof navigator !== 'undefined' && navigator.userAgent && navigator.userAgent.toLowerCase().match(/firefox\\/(\\d+)/) && parseInt(RegExp.$1, 10) >= 31) ||\n    // double check webkit in userAgent just in case we are in a worker\n    (typeof navigator !== 'undefined' && navigator.userAgent && navigator.userAgent.toLowerCase().match(/applewebkit\\/(\\d+)/));\n}\n\n/**\n * Map %j to `JSON.stringify()`, since no Web Inspectors do that by default.\n */\n\nexports.formatters.j = function(v) {\n  try {\n    return JSON.stringify(v);\n  } catch (err) {\n    return '[UnexpectedJSONParseError]: ' + err.message;\n  }\n};\n\n\n/**\n * Colorize log arguments if enabled.\n *\n * @api public\n */\n\nfunction formatArgs(args) {\n  var useColors = this.useColors;\n\n  args[0] = (useColors ? '%c' : '')\n    + this.namespace\n    + (useColors ? ' %c' : ' ')\n    + args[0]\n    + (useColors ? '%c ' : ' ')\n    + '+' + exports.humanize(this.diff);\n\n  if (!useColors) return;\n\n  var c = 'color: ' + this.color;\n  args.splice(1, 0, c, 'color: inherit')\n\n  // the final \"%c\" is somewhat tricky, because there could be other\n  // arguments passed either before or after the %c, so we need to\n  // figure out the correct index to insert the CSS into\n  var index = 0;\n  var lastC = 0;\n  args[0].replace(/%[a-zA-Z%]/g, function(match) {\n    if ('%%' === match) return;\n    index++;\n    if ('%c' === match) {\n      // we only are interested in the *last* %c\n      // (the user may have provided their own)\n      lastC = index;\n    }\n  });\n\n  args.splice(lastC, 0, c);\n}\n\n/**\n * Invokes `console.log()` when available.\n * No-op when `console.log` is not a \"function\".\n *\n * @api public\n */\n\nfunction log() {\n  // this hackery is required for IE8/9, where\n  // the `console.log` function doesn't have 'apply'\n  return 'object' === typeof console\n    && console.log\n    && Function.prototype.apply.call(console.log, console, arguments);\n}\n\n/**\n * Save `namespaces`.\n *\n * @param {String} namespaces\n * @api private\n */\n\nfunction save(namespaces) {\n  try {\n    if (null == namespaces) {\n      exports.storage.removeItem('debug');\n    } else {\n      exports.storage.debug = namespaces;\n    }\n  } catch(e) {}\n}\n\n/**\n * Load `namespaces`.\n *\n * @return {String} returns the previously persisted debug modes\n * @api private\n */\n\nfunction load() {\n  var r;\n  try {\n    r = exports.storage.debug;\n  } catch(e) {}\n\n  // If debug isn't set in LS, and we're in Electron, try to load $DEBUG\n  if (!r && typeof process !== 'undefined' && 'env' in process) {\n    r = process.env.DEBUG;\n  }\n\n  return r;\n}\n\n/**\n * Enable namespaces listed in `localStorage.debug` initially.\n */\n\nexports.enable(load());\n\n/**\n * Localstorage attempts to return the localstorage.\n *\n * This is necessary because safari throws\n * when a user disables cookies/localstorage\n * and you attempt to access it.\n *\n * @return {LocalStorage}\n * @api private\n */\n\nfunction localstorage() {\n  try {\n    return window.localStorage;\n  } catch (e) {}\n}\n",
	"transpiled": true
}; item.content= context.Buffer.from(item.content,'binary'); } return item; })
	fileData.push(function(){ var item= cacheData[24]; if(!item){ item= cacheData[24]= {
	"stat": {
		"mtime": "2017-09-22T13:29:26.000Z",
		"mtimeMs": 1506086966000,
		"atime": "2019-05-18T07:17:58.912Z",
		"atimeMs": 1558163878912,
		"isfile": true
	},
	"filename": "node_modules/debug/src/debug.js",
	"content": "\n/**\n * This is the common logic for both the Node.js and web browser\n * implementations of `debug()`.\n *\n * Expose `debug()` as the module.\n */\n\nexports = module.exports = createDebug.debug = createDebug['default'] = createDebug;\nexports.coerce = coerce;\nexports.disable = disable;\nexports.enable = enable;\nexports.enabled = enabled;\nexports.humanize = require('ms');\n\n/**\n * The currently active debug mode names, and names to skip.\n */\n\nexports.names = [];\nexports.skips = [];\n\n/**\n * Map of special \"%n\" handling functions, for the debug \"format\" argument.\n *\n * Valid key names are a single, lower or upper-case letter, i.e. \"n\" and \"N\".\n */\n\nexports.formatters = {};\n\n/**\n * Previous log timestamp.\n */\n\nvar prevTime;\n\n/**\n * Select a color.\n * @param {String} namespace\n * @return {Number}\n * @api private\n */\n\nfunction selectColor(namespace) {\n  var hash = 0, i;\n\n  for (i in namespace) {\n    hash  = ((hash << 5) - hash) + namespace.charCodeAt(i);\n    hash |= 0; // Convert to 32bit integer\n  }\n\n  return exports.colors[Math.abs(hash) % exports.colors.length];\n}\n\n/**\n * Create a debugger with the given `namespace`.\n *\n * @param {String} namespace\n * @return {Function}\n * @api public\n */\n\nfunction createDebug(namespace) {\n\n  function debug() {\n    // disabled?\n    if (!debug.enabled) return;\n\n    var self = debug;\n\n    // set `diff` timestamp\n    var curr = +new Date();\n    var ms = curr - (prevTime || curr);\n    self.diff = ms;\n    self.prev = prevTime;\n    self.curr = curr;\n    prevTime = curr;\n\n    // turn the `arguments` into a proper Array\n    var args = new Array(arguments.length);\n    for (var i = 0; i < args.length; i++) {\n      args[i] = arguments[i];\n    }\n\n    args[0] = exports.coerce(args[0]);\n\n    if ('string' !== typeof args[0]) {\n      // anything else let's inspect with %O\n      args.unshift('%O');\n    }\n\n    // apply any `formatters` transformations\n    var index = 0;\n    args[0] = args[0].replace(/%([a-zA-Z%])/g, function(match, format) {\n      // if we encounter an escaped % then don't increase the array index\n      if (match === '%%') return match;\n      index++;\n      var formatter = exports.formatters[format];\n      if ('function' === typeof formatter) {\n        var val = args[index];\n        match = formatter.call(self, val);\n\n        // now we need to remove `args[index]` since it's inlined in the `format`\n        args.splice(index, 1);\n        index--;\n      }\n      return match;\n    });\n\n    // apply env-specific formatting (colors, etc.)\n    exports.formatArgs.call(self, args);\n\n    var logFn = debug.log || exports.log || console.log.bind(console);\n    logFn.apply(self, args);\n  }\n\n  debug.namespace = namespace;\n  debug.enabled = exports.enabled(namespace);\n  debug.useColors = exports.useColors();\n  debug.color = selectColor(namespace);\n\n  // env-specific initialization logic for debug instances\n  if ('function' === typeof exports.init) {\n    exports.init(debug);\n  }\n\n  return debug;\n}\n\n/**\n * Enables a debug mode by namespaces. This can include modes\n * separated by a colon and wildcards.\n *\n * @param {String} namespaces\n * @api public\n */\n\nfunction enable(namespaces) {\n  exports.save(namespaces);\n\n  exports.names = [];\n  exports.skips = [];\n\n  var split = (typeof namespaces === 'string' ? namespaces : '').split(/[\\s,]+/);\n  var len = split.length;\n\n  for (var i = 0; i < len; i++) {\n    if (!split[i]) continue; // ignore empty strings\n    namespaces = split[i].replace(/\\*/g, '.*?');\n    if (namespaces[0] === '-') {\n      exports.skips.push(new RegExp('^' + namespaces.substr(1) + '$'));\n    } else {\n      exports.names.push(new RegExp('^' + namespaces + '$'));\n    }\n  }\n}\n\n/**\n * Disable debug output.\n *\n * @api public\n */\n\nfunction disable() {\n  exports.enable('');\n}\n\n/**\n * Returns true if the given mode name is enabled, false otherwise.\n *\n * @param {String} name\n * @return {Boolean}\n * @api public\n */\n\nfunction enabled(name) {\n  var i, len;\n  for (i = 0, len = exports.skips.length; i < len; i++) {\n    if (exports.skips[i].test(name)) {\n      return false;\n    }\n  }\n  for (i = 0, len = exports.names.length; i < len; i++) {\n    if (exports.names[i].test(name)) {\n      return true;\n    }\n  }\n  return false;\n}\n\n/**\n * Coerce `val`.\n *\n * @param {Mixed} val\n * @return {Mixed}\n * @api private\n */\n\nfunction coerce(val) {\n  if (val instanceof Error) return val.stack || val.message;\n  return val;\n}\n",
	"transpiled": true
}; item.content= context.Buffer.from(item.content,'binary'); } return item; })
	fileData.push(function(){ var item= cacheData[25]; if(!item){ item= cacheData[25]= {
	"stat": {
		"mtime": "2017-09-22T13:29:26.000Z",
		"mtimeMs": 1506086966000,
		"atime": "2019-05-18T07:17:58.912Z",
		"atimeMs": 1558163878912,
		"isfile": true
	},
	"filename": "node_modules/debug/src/index.js",
	"content": "/**\n * Detect Electron renderer process, which is node, but we should\n * treat as a browser.\n */\n\nif (typeof process !== 'undefined' && process.type === 'renderer') {\n  module.exports = require('./browser.js');\n} else {\n  module.exports = require('./node.js');\n}\n",
	"transpiled": true
}; item.content= context.Buffer.from(item.content,'binary'); } return item; })
	fileData.push(function(){ var item= cacheData[26]; if(!item){ item= cacheData[26]= {
	"stat": {
		"mtime": "2017-09-21T18:04:48.000Z",
		"mtimeMs": 1506017088000,
		"atime": "2019-05-18T07:17:58.913Z",
		"atimeMs": 1558163878913,
		"isfile": true
	},
	"filename": "node_modules/debug/src/inspector-log.js",
	"content": "module.exports = inspectorLog;\n\n// black hole\nconst nullStream = new (require('stream').Writable)();\nnullStream._write = () => {};\n\n/**\n * Outputs a `console.log()` to the Node.js Inspector console *only*.\n */\nfunction inspectorLog() {\n  const stdout = console._stdout;\n  console._stdout = nullStream;\n  console.log.apply(console, arguments);\n  console._stdout = stdout;\n}\n",
	"transpiled": true
}; item.content= context.Buffer.from(item.content,'binary'); } return item; })
	fileData.push(function(){ var item= cacheData[27]; if(!item){ item= cacheData[27]= {
	"stat": {
		"mtime": "2017-09-22T13:31:40.000Z",
		"mtimeMs": 1506087100000,
		"atime": "2019-05-18T07:17:58.913Z",
		"atimeMs": 1558163878913,
		"isfile": true
	},
	"filename": "node_modules/debug/src/node.js",
	"content": "/**\n * Module dependencies.\n */\n\nvar tty = require('tty');\nvar util = require('util');\n\n/**\n * This is the Node.js implementation of `debug()`.\n *\n * Expose `debug()` as the module.\n */\n\nexports = module.exports = require('./debug');\nexports.init = init;\nexports.log = log;\nexports.formatArgs = formatArgs;\nexports.save = save;\nexports.load = load;\nexports.useColors = useColors;\n\n/**\n * Colors.\n */\n\nexports.colors = [6, 2, 3, 4, 5, 1];\n\n/**\n * Build up the default `inspectOpts` object from the environment variables.\n *\n *   $ DEBUG_COLORS=no DEBUG_DEPTH=10 DEBUG_SHOW_HIDDEN=enabled node script.js\n */\n\nexports.inspectOpts = Object.keys(process.env).filter(function (key) {\n  return /^debug_/i.test(key);\n}).reduce(function (obj, key) {\n  // camel-case\n  var prop = key\n    .substring(6)\n    .toLowerCase()\n    .replace(/_([a-z])/g, function (_, k) { return k.toUpperCase() });\n\n  // coerce string value into JS value\n  var val = process.env[key];\n  if (/^(yes|on|true|enabled)$/i.test(val)) val = true;\n  else if (/^(no|off|false|disabled)$/i.test(val)) val = false;\n  else if (val === 'null') val = null;\n  else val = Number(val);\n\n  obj[prop] = val;\n  return obj;\n}, {});\n\n/**\n * The file descriptor to write the `debug()` calls to.\n * Set the `DEBUG_FD` env variable to override with another value. i.e.:\n *\n *   $ DEBUG_FD=3 node script.js 3>debug.log\n */\n\nvar fd = parseInt(process.env.DEBUG_FD, 10) || 2;\n\nif (1 !== fd && 2 !== fd) {\n  util.deprecate(function(){}, 'except for stderr(2) and stdout(1), any other usage of DEBUG_FD is deprecated. Override debug.log if you want to use a different log function (https://git.io/debug_fd)')()\n}\n\nvar stream = 1 === fd ? process.stdout :\n             2 === fd ? process.stderr :\n             createWritableStdioStream(fd);\n\n/**\n * Is stdout a TTY? Colored output is enabled when `true`.\n */\n\nfunction useColors() {\n  return 'colors' in exports.inspectOpts\n    ? Boolean(exports.inspectOpts.colors)\n    : tty.isatty(fd);\n}\n\n/**\n * Map %o to `util.inspect()`, all on a single line.\n */\n\nexports.formatters.o = function(v) {\n  this.inspectOpts.colors = this.useColors;\n  return util.inspect(v, this.inspectOpts)\n    .split('\\n').map(function(str) {\n      return str.trim()\n    }).join(' ');\n};\n\n/**\n * Map %o to `util.inspect()`, allowing multiple lines if needed.\n */\n\nexports.formatters.O = function(v) {\n  this.inspectOpts.colors = this.useColors;\n  return util.inspect(v, this.inspectOpts);\n};\n\n/**\n * Adds ANSI color escape codes if enabled.\n *\n * @api public\n */\n\nfunction formatArgs(args) {\n  var name = this.namespace;\n  var useColors = this.useColors;\n\n  if (useColors) {\n    var c = this.color;\n    var prefix = '  \\u001b[3' + c + ';1m' + name + ' ' + '\\u001b[0m';\n\n    args[0] = prefix + args[0].split('\\n').join('\\n' + prefix);\n    args.push('\\u001b[3' + c + 'm+' + exports.humanize(this.diff) + '\\u001b[0m');\n  } else {\n    args[0] = new Date().toUTCString()\n      + ' ' + name + ' ' + args[0];\n  }\n}\n\n/**\n * Invokes `util.format()` with the specified arguments and writes to `stream`.\n */\n\nfunction log() {\n  return stream.write(util.format.apply(util, arguments) + '\\n');\n}\n\n/**\n * Save `namespaces`.\n *\n * @param {String} namespaces\n * @api private\n */\n\nfunction save(namespaces) {\n  if (null == namespaces) {\n    // If you set a process.env field to null or undefined, it gets cast to the\n    // string 'null' or 'undefined'. Just delete instead.\n    delete process.env.DEBUG;\n  } else {\n    process.env.DEBUG = namespaces;\n  }\n}\n\n/**\n * Load `namespaces`.\n *\n * @return {String} returns the previously persisted debug modes\n * @api private\n */\n\nfunction load() {\n  return process.env.DEBUG;\n}\n\n/**\n * Copied from `node/src/node.js`.\n *\n * XXX: It's lame that node doesn't expose this API out-of-the-box. It also\n * relies on the undocumented `tty_wrap.guessHandleType()` which is also lame.\n */\n\nfunction createWritableStdioStream (fd) {\n  var stream;\n  var tty_wrap = process.binding('tty_wrap');\n\n  // Note stream._type is used for test-module-load-list.js\n\n  switch (tty_wrap.guessHandleType(fd)) {\n    case 'TTY':\n      stream = new tty.WriteStream(fd);\n      stream._type = 'tty';\n\n      // Hack to have stream not keep the event loop alive.\n      // See https://github.com/joyent/node/issues/1726\n      if (stream._handle && stream._handle.unref) {\n        stream._handle.unref();\n      }\n      break;\n\n    case 'FILE':\n      var fs = require('fs');\n      stream = new fs.SyncWriteStream(fd, { autoClose: false });\n      stream._type = 'fs';\n      break;\n\n    case 'PIPE':\n    case 'TCP':\n      var net = require('net');\n      stream = new net.Socket({\n        fd: fd,\n        readable: false,\n        writable: true\n      });\n\n      // FIXME Should probably have an option in net.Socket to create a\n      // stream from an existing fd which is writable only. But for now\n      // we'll just add this hack and set the `readable` member to false.\n      // Test: ./node test/fixtures/echo.js < /etc/passwd\n      stream.readable = false;\n      stream.read = null;\n      stream._type = 'pipe';\n\n      // FIXME Hack to have stream not keep the event loop alive.\n      // See https://github.com/joyent/node/issues/1726\n      if (stream._handle && stream._handle.unref) {\n        stream._handle.unref();\n      }\n      break;\n\n    default:\n      // Probably an error on in uv_guess_handle()\n      throw new Error('Implement me. Unknown stream file type!');\n  }\n\n  // For supporting legacy API we put the FD here.\n  stream.fd = fd;\n\n  stream._isStdio = true;\n\n  return stream;\n}\n\n/**\n * Init logic for `debug` instances.\n *\n * Create a new `inspectOpts` object in case `useColors` is set\n * differently for a particular `debug` instance.\n */\n\nfunction init (debug) {\n  debug.inspectOpts = {};\n\n  var keys = Object.keys(exports.inspectOpts);\n  for (var i = 0; i < keys.length; i++) {\n    debug.inspectOpts[keys[i]] = exports.inspectOpts[keys[i]];\n  }\n}\n\n/**\n * Enable namespaces listed in `process.env.DEBUG` initially.\n */\n\nexports.enable(load());\n",
	"transpiled": true
}; item.content= context.Buffer.from(item.content,'binary'); } return item; })
	fileData.push(function(){return {
	"stat": {
		"mtime": "2019-05-18T07:17:58.958Z",
		"mtimeMs": 1558163878958.4573,
		"atime": "2019-05-18T07:17:58.954Z",
		"atimeMs": 1558163878954.4573,
		"isdirectory": true
	},
	"filename": "node_modules/fd-slicer"
}})
	fileData.push(function(){ var item= cacheData[29]; if(!item){ item= cacheData[29]= {
	"stat": {
		"mtime": "2015-01-12T16:29:55.000Z",
		"mtimeMs": 1421080195000,
		"atime": "2019-05-18T07:17:58.961Z",
		"atimeMs": 1558163878961,
		"isfile": true
	},
	"filename": "node_modules/fd-slicer/index.js",
	"content": "var fs = require('fs');\nvar util = require('util');\nvar stream = require('stream');\nvar Readable = stream.Readable;\nvar Writable = stream.Writable;\nvar PassThrough = stream.PassThrough;\nvar Pend = require('pend');\nvar EventEmitter = require('events').EventEmitter;\n\nexports.createFromBuffer = createFromBuffer;\nexports.createFromFd = createFromFd;\nexports.BufferSlicer = BufferSlicer;\nexports.FdSlicer = FdSlicer;\n\nutil.inherits(FdSlicer, EventEmitter);\nfunction FdSlicer(fd, options) {\n  options = options || {};\n  EventEmitter.call(this);\n\n  this.fd = fd;\n  this.pend = new Pend();\n  this.pend.max = 1;\n  this.refCount = 0;\n  this.autoClose = !!options.autoClose;\n}\n\nFdSlicer.prototype.read = function(buffer, offset, length, position, callback) {\n  var self = this;\n  self.pend.go(function(cb) {\n    fs.read(self.fd, buffer, offset, length, position, function(err, bytesRead, buffer) {\n      cb();\n      callback(err, bytesRead, buffer);\n    });\n  });\n};\n\nFdSlicer.prototype.write = function(buffer, offset, length, position, callback) {\n  var self = this;\n  self.pend.go(function(cb) {\n    fs.write(self.fd, buffer, offset, length, position, function(err, written, buffer) {\n      cb();\n      callback(err, written, buffer);\n    });\n  });\n};\n\nFdSlicer.prototype.createReadStream = function(options) {\n  return new ReadStream(this, options);\n};\n\nFdSlicer.prototype.createWriteStream = function(options) {\n  return new WriteStream(this, options);\n};\n\nFdSlicer.prototype.ref = function() {\n  this.refCount += 1;\n};\n\nFdSlicer.prototype.unref = function() {\n  var self = this;\n  self.refCount -= 1;\n\n  if (self.refCount > 0) return;\n  if (self.refCount < 0) throw new Error(\"invalid unref\");\n\n  if (self.autoClose) {\n    fs.close(self.fd, onCloseDone);\n  }\n\n  function onCloseDone(err) {\n    if (err) {\n      self.emit('error', err);\n    } else {\n      self.emit('close');\n    }\n  }\n};\n\nutil.inherits(ReadStream, Readable);\nfunction ReadStream(context, options) {\n  options = options || {};\n  Readable.call(this, options);\n\n  this.context = context;\n  this.context.ref();\n\n  this.start = options.start || 0;\n  this.endOffset = options.end;\n  this.pos = this.start;\n  this.destroyed = false;\n}\n\nReadStream.prototype._read = function(n) {\n  var self = this;\n  if (self.destroyed) return;\n\n  var toRead = Math.min(self._readableState.highWaterMark, n);\n  if (self.endOffset != null) {\n    toRead = Math.min(toRead, self.endOffset - self.pos);\n  }\n  if (toRead <= 0) {\n    self.destroyed = true;\n    self.push(null);\n    self.context.unref();\n    return;\n  }\n  self.context.pend.go(function(cb) {\n    if (self.destroyed) return cb();\n    var buffer = new Buffer(toRead);\n    fs.read(self.context.fd, buffer, 0, toRead, self.pos, function(err, bytesRead) {\n      if (err) {\n        self.destroy(err);\n      } else if (bytesRead === 0) {\n        self.destroyed = true;\n        self.push(null);\n        self.context.unref();\n      } else {\n        self.pos += bytesRead;\n        self.push(buffer.slice(0, bytesRead));\n      }\n      cb();\n    });\n  });\n};\n\nReadStream.prototype.destroy = function(err) {\n  if (this.destroyed) return;\n  err = err || new Error(\"stream destroyed\");\n  this.destroyed = true;\n  this.emit('error', err);\n  this.context.unref();\n};\n\nutil.inherits(WriteStream, Writable);\nfunction WriteStream(context, options) {\n  options = options || {};\n  Writable.call(this, options);\n\n  this.context = context;\n  this.context.ref();\n\n  this.start = options.start || 0;\n  this.endOffset = (options.end == null) ? Infinity : +options.end;\n  this.bytesWritten = 0;\n  this.pos = this.start;\n  this.destroyed = false;\n\n  this.on('finish', this.destroy.bind(this));\n}\n\nWriteStream.prototype._write = function(buffer, encoding, callback) {\n  var self = this;\n  if (self.destroyed) return;\n\n  if (self.pos + buffer.length > self.endOffset) {\n    var err = new Error(\"maximum file length exceeded\");\n    err.code = 'ETOOBIG';\n    self.destroy();\n    callback(err);\n    return;\n  }\n  self.context.pend.go(function(cb) {\n    if (self.destroyed) return cb();\n    fs.write(self.context.fd, buffer, 0, buffer.length, self.pos, function(err, bytes) {\n      if (err) {\n        self.destroy();\n        cb();\n        callback(err);\n      } else {\n        self.bytesWritten += bytes;\n        self.pos += bytes;\n        self.emit('progress');\n        cb();\n        callback();\n      }\n    });\n  });\n};\n\nWriteStream.prototype.destroy = function() {\n  if (this.destroyed) return;\n  this.destroyed = true;\n  this.context.unref();\n};\n\nutil.inherits(BufferSlicer, EventEmitter);\nfunction BufferSlicer(buffer) {\n  EventEmitter.call(this);\n\n  this.refCount = 0;\n  this.buffer = buffer;\n}\n\nBufferSlicer.prototype.read = function(buffer, offset, length, position, callback) {\n  var end = position + length;\n  var delta = end - this.buffer.length;\n  var written = (delta > 0) ? delta : length;\n  this.buffer.copy(buffer, offset, position, end);\n  setImmediate(function() {\n    callback(null, written);\n  });\n};\n\nBufferSlicer.prototype.write = function(buffer, offset, length, position, callback) {\n  buffer.copy(this.buffer, position, offset, offset + length);\n  setImmediate(function() {\n    callback(null, length, buffer);\n  });\n};\n\nBufferSlicer.prototype.createReadStream = function(options) {\n  options = options || {};\n  var readStream = new PassThrough(options);\n  readStream.start = options.start || 0;\n  readStream.endOffset = options.end;\n  readStream.pos = readStream.endOffset || this.buffer.length; // yep, we're already done\n  readStream.destroyed = false;\n  readStream.write(this.buffer.slice(readStream.start, readStream.pos));\n  readStream.end();\n  readStream.destroy = function() {\n    readStream.destroyed = true;\n  };\n  return readStream;\n};\n\nBufferSlicer.prototype.createWriteStream = function(options) {\n  var bufferSlicer = this;\n  options = options || {};\n  var writeStream = new Writable(options);\n  writeStream.start = options.start || 0;\n  writeStream.endOffset = (options.end == null) ? this.buffer.length : +options.end;\n  writeStream.bytesWritten = 0;\n  writeStream.pos = writeStream.start;\n  writeStream.destroyed = false;\n  writeStream._write = function(buffer, encoding, callback) {\n    if (writeStream.destroyed) return;\n\n    var end = writeStream.pos + buffer.length;\n    if (end > writeStream.endOffset) {\n      var err = new Error(\"maximum file length exceeded\");\n      err.code = 'ETOOBIG';\n      writeStream.destroyed = true;\n      callback(err);\n      return;\n    }\n    buffer.copy(bufferSlicer.buffer, writeStream.pos, 0, buffer.length);\n\n    writeStream.bytesWritten += buffer.length;\n    writeStream.pos = end;\n    writeStream.emit('progress');\n    callback();\n  };\n  writeStream.destroy = function() {\n    writeStream.destroyed = true;\n  };\n  return writeStream;\n};\n\nBufferSlicer.prototype.ref = function() {\n  this.refCount += 1;\n};\n\nBufferSlicer.prototype.unref = function() {\n  this.refCount -= 1;\n\n  if (this.refCount < 0) {\n    throw new Error(\"invalid unref\");\n  }\n};\n\nfunction createFromBuffer(buffer) {\n  return new BufferSlicer(buffer);\n}\n\nfunction createFromFd(fd, options) {\n  return new FdSlicer(fd, options);\n}\n",
	"transpiled": true
}; item.content= context.Buffer.from(item.content,'binary'); } return item; })
	fileData.push(function(){ var item= cacheData[30]; if(!item){ item= cacheData[30]= {
	"stat": {
		"mtime": "2015-01-12T16:31:28.000Z",
		"mtimeMs": 1421080288000,
		"atime": "2019-05-18T07:17:58.958Z",
		"atimeMs": 1558163878958.4573,
		"isfile": true
	},
	"filename": "node_modules/fd-slicer/package.json",
	"content": "{\n  \"name\": \"fd-slicer\",\n  \"version\": \"1.0.1\",\n  \"description\": \"safely create multiple ReadStream or WriteStream objects from the same file descriptor\",\n  \"main\": \"index.js\",\n  \"scripts\": {\n    \"test\": \"mocha --reporter spec --check-leaks\",\n    \"test-cov\": \"istanbul cover node_modules/mocha/bin/_mocha -- --reporter dot --check-leaks test/test.js\",\n    \"test-travis\": \"istanbul cover node_modules/mocha/bin/_mocha --report lcovonly -- --timeout 10000 --reporter spec --check-leaks test/test.js\"\n  },\n  \"author\": \"Andrew Kelley <superjoe30@gmail.com>\",\n  \"license\": \"MIT\",\n  \"devDependencies\": {\n    \"istanbul\": \"~0.3.3\",\n    \"mocha\": \"~2.0.1\",\n    \"stream-equal\": \"~0.1.5\",\n    \"streamsink\": \"~1.2.0\"\n  },\n  \"dependencies\": {\n    \"pend\": \"~1.2.0\"\n  },\n  \"directories\": {\n    \"test\": \"test\"\n  },\n  \"repository\": {\n    \"type\": \"git\",\n    \"url\": \"git://github.com/andrewrk/node-fd-slicer.git\"\n  },\n  \"bugs\": {\n    \"url\": \"https://github.com/andrewrk/node-fd-slicer/issues\"\n  },\n  \"keywords\": [\n    \"createReadStream\",\n    \"createWriteStream\"\n  ]\n}\n",
	"transpiled": true
}; item.content= context.Buffer.from(item.content,'binary'); } return item; })
	fileData.push(function(){return {
	"stat": {
		"mtime": "2019-05-18T07:17:58.618Z",
		"mtimeMs": 1558163878618.4514,
		"atime": "2019-05-18T07:17:58.618Z",
		"atimeMs": 1558163878618.4514,
		"isdirectory": true
	},
	"filename": "node_modules/inherits"
}})
	fileData.push(function(){ var item= cacheData[32]; if(!item){ item= cacheData[32]= {
	"stat": {
		"mtime": "2016-09-07T20:29:21.000Z",
		"mtimeMs": 1473280161000,
		"atime": "2019-05-18T07:17:58.624Z",
		"atimeMs": 1558163878624,
		"isfile": true
	},
	"filename": "node_modules/inherits/inherits.js",
	"content": "try {\n  var util = require('util');\n  if (typeof util.inherits !== 'function') throw '';\n  module.exports = util.inherits;\n} catch (e) {\n  module.exports = require('./inherits_browser.js');\n}\n",
	"transpiled": true
}; item.content= context.Buffer.from(item.content,'binary'); } return item; })
	fileData.push(function(){ var item= cacheData[33]; if(!item){ item= cacheData[33]= {
	"stat": {
		"mtime": "2013-05-16T14:39:58.000Z",
		"mtimeMs": 1368715198000,
		"atime": "2019-05-18T07:17:58.624Z",
		"atimeMs": 1558163878624,
		"isfile": true
	},
	"filename": "node_modules/inherits/inherits_browser.js",
	"content": "if (typeof Object.create === 'function') {\n  // implementation from standard node.js 'util' module\n  module.exports = function inherits(ctor, superCtor) {\n    ctor.super_ = superCtor\n    ctor.prototype = Object.create(superCtor.prototype, {\n      constructor: {\n        value: ctor,\n        enumerable: false,\n        writable: true,\n        configurable: true\n      }\n    });\n  };\n} else {\n  // old school shim for old browsers\n  module.exports = function inherits(ctor, superCtor) {\n    ctor.super_ = superCtor\n    var TempCtor = function () {}\n    TempCtor.prototype = superCtor.prototype\n    ctor.prototype = new TempCtor()\n    ctor.prototype.constructor = ctor\n  }\n}\n",
	"transpiled": true
}; item.content= context.Buffer.from(item.content,'binary'); } return item; })
	fileData.push(function(){ var item= cacheData[34]; if(!item){ item= cacheData[34]= {
	"stat": {
		"mtime": "2016-09-08T00:49:29.000Z",
		"mtimeMs": 1473295769000,
		"atime": "2019-05-18T07:17:58.714Z",
		"atimeMs": 1558163878714.4531,
		"isfile": true
	},
	"filename": "node_modules/inherits/package.json",
	"content": "{\n  \"name\": \"inherits\",\n  \"description\": \"Browser-friendly inheritance fully compatible with standard node.js inherits()\",\n  \"version\": \"2.0.3\",\n  \"keywords\": [\n    \"inheritance\",\n    \"class\",\n    \"klass\",\n    \"oop\",\n    \"object-oriented\",\n    \"inherits\",\n    \"browser\",\n    \"browserify\"\n  ],\n  \"main\": \"./inherits.js\",\n  \"browser\": \"./inherits_browser.js\",\n  \"repository\": \"git://github.com/isaacs/inherits\",\n  \"license\": \"ISC\",\n  \"scripts\": {\n    \"test\": \"node test\"\n  },\n  \"devDependencies\": {\n    \"tap\": \"^7.1.0\"\n  },\n  \"files\": [\n    \"inherits.js\",\n    \"inherits_browser.js\"\n  ]\n}\n",
	"transpiled": true
}; item.content= context.Buffer.from(item.content,'binary'); } return item; })
	fileData.push(function(){return {
	"stat": {
		"mtime": "2019-05-18T07:17:58.738Z",
		"mtimeMs": 1558163878738.4534,
		"atime": "2019-05-18T07:17:58.738Z",
		"atimeMs": 1558163878738.4534,
		"isdirectory": true
	},
	"filename": "node_modules/isarray"
}})
	fileData.push(function(){ var item= cacheData[36]; if(!item){ item= cacheData[36]= {
	"stat": {
		"mtime": "2015-12-10T10:04:05.000Z",
		"mtimeMs": 1449741845000,
		"atime": "2019-05-18T07:17:58.743Z",
		"atimeMs": 1558163878743,
		"isfile": true
	},
	"filename": "node_modules/isarray/Makefile",
	"content": "\ntest:\n\t@node_modules/.bin/tape test.js\n\n.PHONY: test\n\n",
	"transpiled": true
}; item.content= context.Buffer.from(item.content,'binary'); } return item; })
	fileData.push(function(){ var item= cacheData[37]; if(!item){ item= cacheData[37]= {
	"stat": {
		"mtime": "2015-12-10T10:04:05.000Z",
		"mtimeMs": 1449741845000,
		"atime": "2019-05-18T07:17:58.743Z",
		"atimeMs": 1558163878743,
		"isfile": true
	},
	"filename": "node_modules/isarray/component.json",
	"content": "{\n  \"name\" : \"isarray\",\n  \"description\" : \"Array#isArray for older browsers\",\n  \"version\" : \"0.0.1\",\n  \"repository\" : \"juliangruber/isarray\",\n  \"homepage\": \"https://github.com/juliangruber/isarray\",\n  \"main\" : \"index.js\",\n  \"scripts\" : [\n    \"index.js\"\n  ],\n  \"dependencies\" : {},\n  \"keywords\": [\"browser\",\"isarray\",\"array\"],\n  \"author\": {\n    \"name\": \"Julian Gruber\",\n    \"email\": \"mail@juliangruber.com\",\n    \"url\": \"http://juliangruber.com\"\n  },\n  \"license\": \"MIT\"\n}\n",
	"transpiled": true
}; item.content= context.Buffer.from(item.content,'binary'); } return item; })
	fileData.push(function(){ var item= cacheData[38]; if(!item){ item= cacheData[38]= {
	"stat": {
		"mtime": "2015-12-10T10:04:41.000Z",
		"mtimeMs": 1449741881000,
		"atime": "2019-05-18T07:17:58.743Z",
		"atimeMs": 1558163878743,
		"isfile": true
	},
	"filename": "node_modules/isarray/index.js",
	"content": "var toString = {}.toString;\n\nmodule.exports = Array.isArray || function (arr) {\n  return toString.call(arr) == '[object Array]';\n};\n",
	"transpiled": true
}; item.content= context.Buffer.from(item.content,'binary'); } return item; })
	fileData.push(function(){ var item= cacheData[39]; if(!item){ item= cacheData[39]= {
	"stat": {
		"mtime": "2015-12-10T10:04:53.000Z",
		"mtimeMs": 1449741893000,
		"atime": "2019-05-18T07:17:58.738Z",
		"atimeMs": 1558163878738.4534,
		"isfile": true
	},
	"filename": "node_modules/isarray/package.json",
	"content": "{\n  \"name\": \"isarray\",\n  \"description\": \"Array#isArray for older browsers\",\n  \"version\": \"1.0.0\",\n  \"repository\": {\n    \"type\": \"git\",\n    \"url\": \"git://github.com/juliangruber/isarray.git\"\n  },\n  \"homepage\": \"https://github.com/juliangruber/isarray\",\n  \"main\": \"index.js\",\n  \"dependencies\": {},\n  \"devDependencies\": {\n    \"tape\": \"~2.13.4\"\n  },\n  \"keywords\": [\n    \"browser\",\n    \"isarray\",\n    \"array\"\n  ],\n  \"author\": {\n    \"name\": \"Julian Gruber\",\n    \"email\": \"mail@juliangruber.com\",\n    \"url\": \"http://juliangruber.com\"\n  },\n  \"license\": \"MIT\",\n  \"testling\": {\n    \"files\": \"test.js\",\n    \"browsers\": [\n      \"ie/8..latest\",\n      \"firefox/17..latest\",\n      \"firefox/nightly\",\n      \"chrome/22..latest\",\n      \"chrome/canary\",\n      \"opera/12..latest\",\n      \"opera/next\",\n      \"safari/5.1..latest\",\n      \"ipad/6.0..latest\",\n      \"iphone/6.0..latest\",\n      \"android-browser/4.2..latest\"\n    ]\n  },\n  \"scripts\": {\n    \"test\": \"tape test.js\"\n  }\n}\n",
	"transpiled": true
}; item.content= context.Buffer.from(item.content,'binary'); } return item; })
	fileData.push(function(){ var item= cacheData[40]; if(!item){ item= cacheData[40]= {
	"stat": {
		"mtime": "2015-12-10T10:04:05.000Z",
		"mtimeMs": 1449741845000,
		"atime": "2019-05-18T07:17:58.743Z",
		"atimeMs": 1558163878743,
		"isfile": true
	},
	"filename": "node_modules/isarray/test.js",
	"content": "var isArray = require('./');\nvar test = require('tape');\n\ntest('is array', function(t){\n  t.ok(isArray([]));\n  t.notOk(isArray({}));\n  t.notOk(isArray(null));\n  t.notOk(isArray(false));\n\n  var obj = {};\n  obj[0] = true;\n  t.notOk(isArray(obj));\n\n  var arr = [];\n  arr.foo = 'bar';\n  t.ok(isArray(arr));\n\n  t.end();\n});\n\n",
	"transpiled": true
}; item.content= context.Buffer.from(item.content,'binary'); } return item; })
	fileData.push(function(){return {
	"stat": {
		"mtime": "2019-05-18T07:17:58.926Z",
		"mtimeMs": 1558163878926.4568,
		"atime": "2019-05-18T07:17:58.926Z",
		"atimeMs": 1558163878926.4568,
		"isdirectory": true
	},
	"filename": "node_modules/minimist"
}})
	fileData.push(function(){ var item= cacheData[42]; if(!item){ item= cacheData[42]= {
	"stat": {
		"mtime": "2014-02-21T04:46:01.000Z",
		"mtimeMs": 1392957961000,
		"atime": "2019-05-18T07:17:58.931Z",
		"atimeMs": 1558163878931,
		"isfile": true
	},
	"filename": "node_modules/minimist/index.js",
	"content": "module.exports = function (args, opts) {\n    if (!opts) opts = {};\n    \n    var flags = { bools : {}, strings : {} };\n    \n    [].concat(opts['boolean']).filter(Boolean).forEach(function (key) {\n        flags.bools[key] = true;\n    });\n    \n    [].concat(opts.string).filter(Boolean).forEach(function (key) {\n        flags.strings[key] = true;\n    });\n    \n    var aliases = {};\n    Object.keys(opts.alias || {}).forEach(function (key) {\n        aliases[key] = [].concat(opts.alias[key]);\n        aliases[key].forEach(function (x) {\n            aliases[x] = [key].concat(aliases[key].filter(function (y) {\n                return x !== y;\n            }));\n        });\n    });\n    \n    var defaults = opts['default'] || {};\n    \n    var argv = { _ : [] };\n    Object.keys(flags.bools).forEach(function (key) {\n        setArg(key, defaults[key] === undefined ? false : defaults[key]);\n    });\n    \n    var notFlags = [];\n\n    if (args.indexOf('--') !== -1) {\n        notFlags = args.slice(args.indexOf('--')+1);\n        args = args.slice(0, args.indexOf('--'));\n    }\n\n    function setArg (key, val) {\n        var value = !flags.strings[key] && isNumber(val)\n            ? Number(val) : val\n        ;\n        setKey(argv, key.split('.'), value);\n        \n        (aliases[key] || []).forEach(function (x) {\n            setKey(argv, x.split('.'), value);\n        });\n    }\n    \n    for (var i = 0; i < args.length; i++) {\n        var arg = args[i];\n        \n        if (/^--.+=/.test(arg)) {\n            // Using [\\s\\S] instead of . because js doesn't support the\n            // 'dotall' regex modifier. See:\n            // http://stackoverflow.com/a/1068308/13216\n            var m = arg.match(/^--([^=]+)=([\\s\\S]*)$/);\n            setArg(m[1], m[2]);\n        }\n        else if (/^--no-.+/.test(arg)) {\n            var key = arg.match(/^--no-(.+)/)[1];\n            setArg(key, false);\n        }\n        else if (/^--.+/.test(arg)) {\n            var key = arg.match(/^--(.+)/)[1];\n            var next = args[i + 1];\n            if (next !== undefined && !/^-/.test(next)\n            && !flags.bools[key]\n            && (aliases[key] ? !flags.bools[aliases[key]] : true)) {\n                setArg(key, next);\n                i++;\n            }\n            else if (/^(true|false)$/.test(next)) {\n                setArg(key, next === 'true');\n                i++;\n            }\n            else {\n                setArg(key, flags.strings[key] ? '' : true);\n            }\n        }\n        else if (/^-[^-]+/.test(arg)) {\n            var letters = arg.slice(1,-1).split('');\n            \n            var broken = false;\n            for (var j = 0; j < letters.length; j++) {\n                var next = arg.slice(j+2);\n                \n                if (next === '-') {\n                    setArg(letters[j], next)\n                    continue;\n                }\n                \n                if (/[A-Za-z]/.test(letters[j])\n                && /-?\\d+(\\.\\d*)?(e-?\\d+)?$/.test(next)) {\n                    setArg(letters[j], next);\n                    broken = true;\n                    break;\n                }\n                \n                if (letters[j+1] && letters[j+1].match(/\\W/)) {\n                    setArg(letters[j], arg.slice(j+2));\n                    broken = true;\n                    break;\n                }\n                else {\n                    setArg(letters[j], flags.strings[letters[j]] ? '' : true);\n                }\n            }\n            \n            var key = arg.slice(-1)[0];\n            if (!broken && key !== '-') {\n                if (args[i+1] && !/^(-|--)[^-]/.test(args[i+1])\n                && !flags.bools[key]\n                && (aliases[key] ? !flags.bools[aliases[key]] : true)) {\n                    setArg(key, args[i+1]);\n                    i++;\n                }\n                else if (args[i+1] && /true|false/.test(args[i+1])) {\n                    setArg(key, args[i+1] === 'true');\n                    i++;\n                }\n                else {\n                    setArg(key, flags.strings[key] ? '' : true);\n                }\n            }\n        }\n        else {\n            argv._.push(\n                flags.strings['_'] || !isNumber(arg) ? arg : Number(arg)\n            );\n        }\n    }\n    \n    Object.keys(defaults).forEach(function (key) {\n        if (!hasKey(argv, key.split('.'))) {\n            setKey(argv, key.split('.'), defaults[key]);\n            \n            (aliases[key] || []).forEach(function (x) {\n                setKey(argv, x.split('.'), defaults[key]);\n            });\n        }\n    });\n    \n    notFlags.forEach(function(key) {\n        argv._.push(key);\n    });\n\n    return argv;\n};\n\nfunction hasKey (obj, keys) {\n    var o = obj;\n    keys.slice(0,-1).forEach(function (key) {\n        o = (o[key] || {});\n    });\n\n    var key = keys[keys.length - 1];\n    return key in o;\n}\n\nfunction setKey (obj, keys, value) {\n    var o = obj;\n    keys.slice(0,-1).forEach(function (key) {\n        if (o[key] === undefined) o[key] = {};\n        o = o[key];\n    });\n    \n    var key = keys[keys.length - 1];\n    if (o[key] === undefined || typeof o[key] === 'boolean') {\n        o[key] = value;\n    }\n    else if (Array.isArray(o[key])) {\n        o[key].push(value);\n    }\n    else {\n        o[key] = [ o[key], value ];\n    }\n}\n\nfunction isNumber (x) {\n    if (typeof x === 'number') return true;\n    if (/^0x[0-9a-f]+$/i.test(x)) return true;\n    return /^[-+]?(?:\\d+(?:\\.\\d*)?|\\.\\d+)(e[-+]?\\d+)?$/.test(x);\n}\n\nfunction longest (xs) {\n    return Math.max.apply(null, xs.map(function (x) { return x.length }));\n}\n",
	"transpiled": true
}; item.content= context.Buffer.from(item.content,'binary'); } return item; })
	fileData.push(function(){ var item= cacheData[43]; if(!item){ item= cacheData[43]= {
	"stat": {
		"mtime": "2014-02-21T04:46:10.000Z",
		"mtimeMs": 1392957970000,
		"atime": "2019-05-18T07:17:58.930Z",
		"atimeMs": 1558163878930.4568,
		"isfile": true
	},
	"filename": "node_modules/minimist/package.json",
	"content": "{\n    \"name\": \"minimist\",\n    \"version\": \"0.0.8\",\n    \"description\": \"parse argument options\",\n    \"main\": \"index.js\",\n    \"devDependencies\": {\n        \"tape\": \"~1.0.4\",\n        \"tap\": \"~0.4.0\"\n    },\n    \"scripts\": {\n        \"test\": \"tap test/*.js\"\n    },\n    \"testling\" : {\n        \"files\" : \"test/*.js\",\n        \"browsers\" : [\n            \"ie/6..latest\",\n            \"ff/5\", \"firefox/latest\",\n            \"chrome/10\", \"chrome/latest\",\n            \"safari/5.1\", \"safari/latest\",\n            \"opera/12\"\n        ]\n    },\n    \"repository\": {\n        \"type\": \"git\",\n        \"url\": \"git://github.com/substack/minimist.git\"\n    },\n    \"homepage\": \"https://github.com/substack/minimist\",\n    \"keywords\": [\n        \"argv\",\n        \"getopt\",\n        \"parser\",\n        \"optimist\"\n    ],\n    \"author\": {\n        \"name\": \"James Halliday\",\n        \"email\": \"mail@substack.net\",\n        \"url\": \"http://substack.net\"\n    },\n    \"license\": \"MIT\"\n}\n",
	"transpiled": true
}; item.content= context.Buffer.from(item.content,'binary'); } return item; })
	fileData.push(function(){ var item= cacheData[44]; if(!item){ item= cacheData[44]= {
	"stat": {
		"mtime": "2013-06-25T08:16:36.000Z",
		"mtimeMs": 1372148196000,
		"atime": "2019-05-18T07:17:58.931Z",
		"atimeMs": 1558163878931,
		"isfile": true
	},
	"filename": "node_modules/minimist/readme.markdown",
	"content": "# minimist\n\nparse argument options\n\nThis module is the guts of optimist's argument parser without all the\nfanciful decoration.\n\n[![browser support](https://ci.testling.com/substack/minimist.png)](http://ci.testling.com/substack/minimist)\n\n[![build status](https://secure.travis-ci.org/substack/minimist.png)](http://travis-ci.org/substack/minimist)\n\n# example\n\n``` js\nvar argv = require('minimist')(process.argv.slice(2));\nconsole.dir(argv);\n```\n\n```\n$ node example/parse.js -a beep -b boop\n{ _: [], a: 'beep', b: 'boop' }\n```\n\n```\n$ node example/parse.js -x 3 -y 4 -n5 -abc --beep=boop foo bar baz\n{ _: [ 'foo', 'bar', 'baz' ],\n  x: 3,\n  y: 4,\n  n: 5,\n  a: true,\n  b: true,\n  c: true,\n  beep: 'boop' }\n```\n\n# methods\n\n``` js\nvar parseArgs = require('minimist')\n```\n\n## var argv = parseArgs(args, opts={})\n\nReturn an argument object `argv` populated with the array arguments from `args`.\n\n`argv._` contains all the arguments that didn't have an option associated with\nthem.\n\nNumeric-looking arguments will be returned as numbers unless `opts.string` or\n`opts.boolean` is set for that argument name.\n\nAny arguments after `'--'` will not be parsed and will end up in `argv._`.\n\noptions can be:\n\n* `opts.string` - a string or array of strings argument names to always treat as\nstrings\n* `opts.boolean` - a string or array of strings to always treat as booleans\n* `opts.alias` - an object mapping string names to strings or arrays of string\nargument names to use as aliases\n* `opts.default` - an object mapping string argument names to default values\n\n# install\n\nWith [npm](https://npmjs.org) do:\n\n```\nnpm install minimist\n```\n\n# license\n\nMIT\n",
	"transpiled": true
}; item.content= context.Buffer.from(item.content,'binary'); } return item; })
	fileData.push(function(){return {
	"stat": {
		"mtime": "2019-05-18T07:17:58.918Z",
		"mtimeMs": 1558163878918.4565,
		"atime": "2019-05-18T07:17:58.918Z",
		"atimeMs": 1558163878918.4565,
		"isdirectory": true
	},
	"filename": "node_modules/mkdirp"
}})
	fileData.push(function(){return {
	"stat": {
		"mtime": "2019-05-18T07:17:58.918Z",
		"mtimeMs": 1558163878918.4565,
		"atime": "2019-05-18T07:17:58.918Z",
		"atimeMs": 1558163878918.4565,
		"isdirectory": true
	},
	"filename": "node_modules/mkdirp/bin"
}})
	fileData.push(function(){ var item= cacheData[47]; if(!item){ item= cacheData[47]= {
	"stat": {
		"mtime": "2014-12-26T20:47:21.000Z",
		"mtimeMs": 1419626841000,
		"atime": "2019-05-18T07:17:58.924Z",
		"atimeMs": 1558163878924,
		"isfile": true
	},
	"filename": "node_modules/mkdirp/bin/cmd.js",
	"content": "#!/usr/bin/env node\n\nvar mkdirp = require('../');\nvar minimist = require('minimist');\nvar fs = require('fs');\n\nvar argv = minimist(process.argv.slice(2), {\n    alias: { m: 'mode', h: 'help' },\n    string: [ 'mode' ]\n});\nif (argv.help) {\n    fs.createReadStream(__dirname + '/usage.txt').pipe(process.stdout);\n    return;\n}\n\nvar paths = argv._.slice();\nvar mode = argv.mode ? parseInt(argv.mode, 8) : undefined;\n\n(function next () {\n    if (paths.length === 0) return;\n    var p = paths.shift();\n    \n    if (mode === undefined) mkdirp(p, cb)\n    else mkdirp(p, mode, cb)\n    \n    function cb (err) {\n        if (err) {\n            console.error(err.message);\n            process.exit(1);\n        }\n        else next();\n    }\n})();\n",
	"transpiled": true
}; item.content= context.Buffer.from(item.content,'binary'); } return item; })
	fileData.push(function(){ var item= cacheData[48]; if(!item){ item= cacheData[48]= {
	"stat": {
		"mtime": "2014-12-26T20:47:21.000Z",
		"mtimeMs": 1419626841000,
		"atime": "2019-05-18T07:17:58.924Z",
		"atimeMs": 1558163878924,
		"isfile": true
	},
	"filename": "node_modules/mkdirp/bin/usage.txt",
	"content": "usage: mkdirp [DIR1,DIR2..] {OPTIONS}\n\n  Create each supplied directory including any necessary parent directories that\n  don't yet exist.\n  \n  If the directory already exists, do nothing.\n\nOPTIONS are:\n\n  -m, --mode   If a directory needs to be created, set the mode as an octal\n               permission string.\n\n",
	"transpiled": true
}; item.content= context.Buffer.from(item.content,'binary'); } return item; })
	fileData.push(function(){ var item= cacheData[49]; if(!item){ item= cacheData[49]= {
	"stat": {
		"mtime": "2015-05-14T02:31:34.000Z",
		"mtimeMs": 1431570694000,
		"atime": "2019-05-18T07:17:58.924Z",
		"atimeMs": 1558163878924,
		"isfile": true
	},
	"filename": "node_modules/mkdirp/index.js",
	"content": "var path = require('path');\nvar fs = require('fs');\nvar _0777 = parseInt('0777', 8);\n\nmodule.exports = mkdirP.mkdirp = mkdirP.mkdirP = mkdirP;\n\nfunction mkdirP (p, opts, f, made) {\n    if (typeof opts === 'function') {\n        f = opts;\n        opts = {};\n    }\n    else if (!opts || typeof opts !== 'object') {\n        opts = { mode: opts };\n    }\n    \n    var mode = opts.mode;\n    var xfs = opts.fs || fs;\n    \n    if (mode === undefined) {\n        mode = _0777 & (~process.umask());\n    }\n    if (!made) made = null;\n    \n    var cb = f || function () {};\n    p = path.resolve(p);\n    \n    xfs.mkdir(p, mode, function (er) {\n        if (!er) {\n            made = made || p;\n            return cb(null, made);\n        }\n        switch (er.code) {\n            case 'ENOENT':\n                mkdirP(path.dirname(p), opts, function (er, made) {\n                    if (er) cb(er, made);\n                    else mkdirP(p, opts, cb, made);\n                });\n                break;\n\n            // In the case of any other error, just see if there's a dir\n            // there already.  If so, then hooray!  If not, then something\n            // is borked.\n            default:\n                xfs.stat(p, function (er2, stat) {\n                    // if the stat fails, then that's super weird.\n                    // let the original error be the failure reason.\n                    if (er2 || !stat.isDirectory()) cb(er, made)\n                    else cb(null, made);\n                });\n                break;\n        }\n    });\n}\n\nmkdirP.sync = function sync (p, opts, made) {\n    if (!opts || typeof opts !== 'object') {\n        opts = { mode: opts };\n    }\n    \n    var mode = opts.mode;\n    var xfs = opts.fs || fs;\n    \n    if (mode === undefined) {\n        mode = _0777 & (~process.umask());\n    }\n    if (!made) made = null;\n\n    p = path.resolve(p);\n\n    try {\n        xfs.mkdirSync(p, mode);\n        made = made || p;\n    }\n    catch (err0) {\n        switch (err0.code) {\n            case 'ENOENT' :\n                made = sync(path.dirname(p), opts, made);\n                sync(p, opts, made);\n                break;\n\n            // In the case of any other error, just see if there's a dir\n            // there already.  If so, then hooray!  If not, then something\n            // is borked.\n            default:\n                var stat;\n                try {\n                    stat = xfs.statSync(p);\n                }\n                catch (err1) {\n                    throw err0;\n                }\n                if (!stat.isDirectory()) throw err0;\n                break;\n        }\n    }\n\n    return made;\n};\n",
	"transpiled": true
}; item.content= context.Buffer.from(item.content,'binary'); } return item; })
	fileData.push(function(){ var item= cacheData[50]; if(!item){ item= cacheData[50]= {
	"stat": {
		"mtime": "2015-05-14T02:31:37.000Z",
		"mtimeMs": 1431570697000,
		"atime": "2019-05-18T07:17:58.922Z",
		"atimeMs": 1558163878922.4565,
		"isfile": true
	},
	"filename": "node_modules/mkdirp/package.json",
	"content": "{\n  \"name\": \"mkdirp\",\n  \"description\": \"Recursively mkdir, like `mkdir -p`\",\n  \"version\": \"0.5.1\",\n  \"author\": \"James Halliday <mail@substack.net> (http://substack.net)\",\n  \"main\": \"index.js\",\n  \"keywords\": [\n    \"mkdir\",\n    \"directory\"\n  ],\n  \"repository\": {\n    \"type\": \"git\",\n    \"url\": \"https://github.com/substack/node-mkdirp.git\"\n  },\n  \"scripts\": {\n    \"test\": \"tap test/*.js\"\n  },\n  \"dependencies\": {\n    \"minimist\": \"0.0.8\"\n  },\n  \"devDependencies\": {\n    \"tap\": \"1\",\n    \"mock-fs\": \"2 >=2.7.0\"\n  },\n  \"bin\": \"bin/cmd.js\",\n  \"license\": \"MIT\"\n}\n",
	"transpiled": true
}; item.content= context.Buffer.from(item.content,'binary'); } return item; })
	fileData.push(function(){ var item= cacheData[51]; if(!item){ item= cacheData[51]= {
	"stat": {
		"mtime": "2014-12-26T20:47:21.000Z",
		"mtimeMs": 1419626841000,
		"atime": "2019-05-18T07:17:58.924Z",
		"atimeMs": 1558163878924,
		"isfile": true
	},
	"filename": "node_modules/mkdirp/readme.markdown",
	"content": "# mkdirp\n\nLike `mkdir -p`, but in node.js!\n\n[![build status](https://secure.travis-ci.org/substack/node-mkdirp.png)](http://travis-ci.org/substack/node-mkdirp)\n\n# example\n\n## pow.js\n\n```js\nvar mkdirp = require('mkdirp');\n    \nmkdirp('/tmp/foo/bar/baz', function (err) {\n    if (err) console.error(err)\n    else console.log('pow!')\n});\n```\n\nOutput\n\n```\npow!\n```\n\nAnd now /tmp/foo/bar/baz exists, huzzah!\n\n# methods\n\n```js\nvar mkdirp = require('mkdirp');\n```\n\n## mkdirp(dir, opts, cb)\n\nCreate a new directory and any necessary subdirectories at `dir` with octal\npermission string `opts.mode`. If `opts` is a non-object, it will be treated as\nthe `opts.mode`.\n\nIf `opts.mode` isn't specified, it defaults to `0777 & (~process.umask())`.\n\n`cb(err, made)` fires with the error or the first directory `made`\nthat had to be created, if any.\n\nYou can optionally pass in an alternate `fs` implementation by passing in\n`opts.fs`. Your implementation should have `opts.fs.mkdir(path, mode, cb)` and\n`opts.fs.stat(path, cb)`.\n\n## mkdirp.sync(dir, opts)\n\nSynchronously create a new directory and any necessary subdirectories at `dir`\nwith octal permission string `opts.mode`. If `opts` is a non-object, it will be\ntreated as the `opts.mode`.\n\nIf `opts.mode` isn't specified, it defaults to `0777 & (~process.umask())`.\n\nReturns the first directory that had to be created, if any.\n\nYou can optionally pass in an alternate `fs` implementation by passing in\n`opts.fs`. Your implementation should have `opts.fs.mkdirSync(path, mode)` and\n`opts.fs.statSync(path)`.\n\n# usage\n\nThis package also ships with a `mkdirp` command.\n\n```\nusage: mkdirp [DIR1,DIR2..] {OPTIONS}\n\n  Create each supplied directory including any necessary parent directories that\n  don't yet exist.\n  \n  If the directory already exists, do nothing.\n\nOPTIONS are:\n\n  -m, --mode   If a directory needs to be created, set the mode as an octal\n               permission string.\n\n```\n\n# install\n\nWith [npm](http://npmjs.org) do:\n\n```\nnpm install mkdirp\n```\n\nto get the library, or\n\n```\nnpm install -g mkdirp\n```\n\nto get the command.\n\n# license\n\nMIT\n",
	"transpiled": true
}; item.content= context.Buffer.from(item.content,'binary'); } return item; })
	fileData.push(function(){return {
	"stat": {
		"mtime": "2019-05-18T07:17:58.914Z",
		"mtimeMs": 1558163878914.4565,
		"atime": "2019-05-18T07:17:58.914Z",
		"atimeMs": 1558163878914.4565,
		"isdirectory": true
	},
	"filename": "node_modules/ms"
}})
	fileData.push(function(){ var item= cacheData[53]; if(!item){ item= cacheData[53]= {
	"stat": {
		"mtime": "2017-05-16T12:22:00.000Z",
		"mtimeMs": 1494937320000,
		"atime": "2019-05-18T07:17:58.919Z",
		"atimeMs": 1558163878919,
		"isfile": true
	},
	"filename": "node_modules/ms/index.js",
	"content": "/**\n * Helpers.\n */\n\nvar s = 1000;\nvar m = s * 60;\nvar h = m * 60;\nvar d = h * 24;\nvar y = d * 365.25;\n\n/**\n * Parse or format the given `val`.\n *\n * Options:\n *\n *  - `long` verbose formatting [false]\n *\n * @param {String|Number} val\n * @param {Object} [options]\n * @throws {Error} throw an error if val is not a non-empty string or a number\n * @return {String|Number}\n * @api public\n */\n\nmodule.exports = function(val, options) {\n  options = options || {};\n  var type = typeof val;\n  if (type === 'string' && val.length > 0) {\n    return parse(val);\n  } else if (type === 'number' && isNaN(val) === false) {\n    return options.long ? fmtLong(val) : fmtShort(val);\n  }\n  throw new Error(\n    'val is not a non-empty string or a valid number. val=' +\n      JSON.stringify(val)\n  );\n};\n\n/**\n * Parse the given `str` and return milliseconds.\n *\n * @param {String} str\n * @return {Number}\n * @api private\n */\n\nfunction parse(str) {\n  str = String(str);\n  if (str.length > 100) {\n    return;\n  }\n  var match = /^((?:\\d+)?\\.?\\d+) *(milliseconds?|msecs?|ms|seconds?|secs?|s|minutes?|mins?|m|hours?|hrs?|h|days?|d|years?|yrs?|y)?$/i.exec(\n    str\n  );\n  if (!match) {\n    return;\n  }\n  var n = parseFloat(match[1]);\n  var type = (match[2] || 'ms').toLowerCase();\n  switch (type) {\n    case 'years':\n    case 'year':\n    case 'yrs':\n    case 'yr':\n    case 'y':\n      return n * y;\n    case 'days':\n    case 'day':\n    case 'd':\n      return n * d;\n    case 'hours':\n    case 'hour':\n    case 'hrs':\n    case 'hr':\n    case 'h':\n      return n * h;\n    case 'minutes':\n    case 'minute':\n    case 'mins':\n    case 'min':\n    case 'm':\n      return n * m;\n    case 'seconds':\n    case 'second':\n    case 'secs':\n    case 'sec':\n    case 's':\n      return n * s;\n    case 'milliseconds':\n    case 'millisecond':\n    case 'msecs':\n    case 'msec':\n    case 'ms':\n      return n;\n    default:\n      return undefined;\n  }\n}\n\n/**\n * Short format for `ms`.\n *\n * @param {Number} ms\n * @return {String}\n * @api private\n */\n\nfunction fmtShort(ms) {\n  if (ms >= d) {\n    return Math.round(ms / d) + 'd';\n  }\n  if (ms >= h) {\n    return Math.round(ms / h) + 'h';\n  }\n  if (ms >= m) {\n    return Math.round(ms / m) + 'm';\n  }\n  if (ms >= s) {\n    return Math.round(ms / s) + 's';\n  }\n  return ms + 'ms';\n}\n\n/**\n * Long format for `ms`.\n *\n * @param {Number} ms\n * @return {String}\n * @api private\n */\n\nfunction fmtLong(ms) {\n  return plural(ms, d, 'day') ||\n    plural(ms, h, 'hour') ||\n    plural(ms, m, 'minute') ||\n    plural(ms, s, 'second') ||\n    ms + ' ms';\n}\n\n/**\n * Pluralization helper.\n */\n\nfunction plural(ms, n, name) {\n  if (ms < n) {\n    return;\n  }\n  if (ms < n * 1.5) {\n    return Math.floor(ms / n) + ' ' + name;\n  }\n  return Math.ceil(ms / n) + ' ' + name + 's';\n}\n",
	"transpiled": true
}; item.content= context.Buffer.from(item.content,'binary'); } return item; })
	fileData.push(function(){ var item= cacheData[54]; if(!item){ item= cacheData[54]= {
	"stat": {
		"mtime": "2017-05-16T12:25:16.000Z",
		"mtimeMs": 1494937516000,
		"atime": "2019-05-18T07:17:58.914Z",
		"atimeMs": 1558163878914.4565,
		"isfile": true
	},
	"filename": "node_modules/ms/package.json",
	"content": "{\n  \"name\": \"ms\",\n  \"version\": \"2.0.0\",\n  \"description\": \"Tiny milisecond conversion utility\",\n  \"repository\": \"zeit/ms\",\n  \"main\": \"./index\",\n  \"files\": [\n    \"index.js\"\n  ],\n  \"scripts\": {\n    \"precommit\": \"lint-staged\",\n    \"lint\": \"eslint lib/* bin/*\",\n    \"test\": \"mocha tests.js\"\n  },\n  \"eslintConfig\": {\n    \"extends\": \"eslint:recommended\",\n    \"env\": {\n      \"node\": true,\n      \"es6\": true\n    }\n  },\n  \"lint-staged\": {\n    \"*.js\": [\n      \"npm run lint\",\n      \"prettier --single-quote --write\",\n      \"git add\"\n    ]\n  },\n  \"license\": \"MIT\",\n  \"devDependencies\": {\n    \"eslint\": \"3.19.0\",\n    \"expect.js\": \"0.3.1\",\n    \"husky\": \"0.13.3\",\n    \"lint-staged\": \"3.4.1\",\n    \"mocha\": \"3.4.1\"\n  }\n}\n",
	"transpiled": true
}; item.content= context.Buffer.from(item.content,'binary'); } return item; })
	fileData.push(function(){return {
	"stat": {
		"mtime": "2019-05-18T07:17:58.978Z",
		"mtimeMs": 1558163878978.4575,
		"atime": "2019-05-18T07:17:58.978Z",
		"atimeMs": 1558163878978.4575,
		"isdirectory": true
	},
	"filename": "node_modules/pend"
}})
	fileData.push(function(){ var item= cacheData[56]; if(!item){ item= cacheData[56]= {
	"stat": {
		"mtime": "2014-11-23T21:47:55.000Z",
		"mtimeMs": 1416779275000,
		"atime": "2019-05-18T07:17:58.983Z",
		"atimeMs": 1558163878983,
		"isfile": true
	},
	"filename": "node_modules/pend/index.js",
	"content": "module.exports = Pend;\n\nfunction Pend() {\n  this.pending = 0;\n  this.max = Infinity;\n  this.listeners = [];\n  this.waiting = [];\n  this.error = null;\n}\n\nPend.prototype.go = function(fn) {\n  if (this.pending < this.max) {\n    pendGo(this, fn);\n  } else {\n    this.waiting.push(fn);\n  }\n};\n\nPend.prototype.wait = function(cb) {\n  if (this.pending === 0) {\n    cb(this.error);\n  } else {\n    this.listeners.push(cb);\n  }\n};\n\nPend.prototype.hold = function() {\n  return pendHold(this);\n};\n\nfunction pendHold(self) {\n  self.pending += 1;\n  var called = false;\n  return onCb;\n  function onCb(err) {\n    if (called) throw new Error(\"callback called twice\");\n    called = true;\n    self.error = self.error || err;\n    self.pending -= 1;\n    if (self.waiting.length > 0 && self.pending < self.max) {\n      pendGo(self, self.waiting.shift());\n    } else if (self.pending === 0) {\n      var listeners = self.listeners;\n      self.listeners = [];\n      listeners.forEach(cbListener);\n    }\n  }\n  function cbListener(listener) {\n    listener(self.error);\n  }\n}\n\nfunction pendGo(self, fn) {\n  fn(pendHold(self));\n}\n",
	"transpiled": true
}; item.content= context.Buffer.from(item.content,'binary'); } return item; })
	fileData.push(function(){ var item= cacheData[57]; if(!item){ item= cacheData[57]= {
	"stat": {
		"mtime": "2014-11-23T21:51:58.000Z",
		"mtimeMs": 1416779518000,
		"atime": "2019-05-18T07:17:58.978Z",
		"atimeMs": 1558163878978.4575,
		"isfile": true
	},
	"filename": "node_modules/pend/package.json",
	"content": "{\n  \"name\": \"pend\",\n  \"version\": \"1.2.0\",\n  \"description\": \"dead-simple optimistic async helper\",\n  \"main\": \"index.js\",\n  \"scripts\": {\n    \"test\": \"node test.js\"\n  },\n  \"author\": \"Andrew Kelley <superjoe30@gmail.com>\",\n  \"license\": \"MIT\",\n  \"repository\": {\n    \"type\": \"git\",\n    \"url\": \"git://github.com/andrewrk/node-pend.git\"\n  },\n  \"bugs\": {\n    \"url\": \"https://github.com/andrewrk/node-pend/issues\"\n  }\n}\n",
	"transpiled": true
}; item.content= context.Buffer.from(item.content,'binary'); } return item; })
	fileData.push(function(){ var item= cacheData[58]; if(!item){ item= cacheData[58]= {
	"stat": {
		"mtime": "2014-11-23T21:50:31.000Z",
		"mtimeMs": 1416779431000,
		"atime": "2019-05-18T07:17:58.983Z",
		"atimeMs": 1558163878983,
		"isfile": true
	},
	"filename": "node_modules/pend/test.js",
	"content": "var assert = require('assert');\nvar Pend = require('./');\n\nvar tests = [\n  {\n    name: \"basic\",\n    fn: testBasic,\n  },\n  {\n    name: \"max\",\n    fn: testWithMax,\n  },\n  {\n    name: \"callback twice\",\n    fn: testCallbackTwice,\n  },\n  {\n    name: \"calling wait twice\",\n    fn: testCallingWaitTwice,\n  },\n  {\n    name: \"hold()\",\n    fn: testHoldFn,\n  },\n];\nvar testCount = tests.length;\n\ndoOneTest();\n\nfunction doOneTest() {\n  var test = tests.shift();\n  if (!test) {\n    console.log(testCount + \" tests passed.\");\n    return;\n  }\n  process.stdout.write(test.name + \"...\");\n  test.fn(function() {\n    process.stdout.write(\"OK\\n\");\n    doOneTest();\n  });\n}\n\nfunction testBasic(cb) {\n  var pend = new Pend();\n  var results = [];\n  pend.go(function(cb) {\n    results.push(1);\n    setTimeout(function() {\n      results.push(3);\n      cb();\n    }, 500);\n  });\n  pend.go(function(cb) {\n    results.push(2);\n    setTimeout(function() {\n      results.push(4);\n      cb();\n    }, 1000);\n  });\n  pend.wait(function(err) {\n    assert.deepEqual(results, [1,2,3,4]);\n    cb();\n  });\n  assert.deepEqual(results, [1, 2]);\n}\n\nfunction testWithMax(cb) {\n  var pend = new Pend();\n  var results = [];\n  pend.max = 2;\n  pend.go(function(cb) {\n    results.push('a');\n    setTimeout(function() {\n      results.push(1);\n      cb();\n    }, 500);\n  });\n  pend.go(function(cb) {\n    results.push('b');\n    setTimeout(function() {\n      results.push(1);\n      cb();\n    }, 500);\n  });\n  pend.go(function(cb) {\n    results.push('c');\n    setTimeout(function() {\n      results.push(2);\n      cb();\n    }, 100);\n  });\n  pend.wait(function(err) {\n    assert.deepEqual(results, ['a', 'b', 1, 'c', 1, 2]);\n    cb();\n  });\n  assert.deepEqual(results, ['a', 'b']);\n}\n\nfunction testCallbackTwice(cb) {\n  var pend = new Pend();\n  pend.go(function(cb) {\n    setTimeout(cb, 100);\n  });\n  pend.go(function(cb) {\n    cb();\n    assert.throws(cb, /callback called twice/);\n  });\n  pend.wait(cb);\n}\n\nfunction testCallingWaitTwice(cb) {\n  var pend = new Pend();\n  pend.go(function(cb) {\n    setTimeout(cb, 100);\n  });\n  pend.wait(function() {\n    pend.go(function(cb) {\n      setTimeout(cb, 50);\n    });\n    pend.go(function(cb) {\n      setTimeout(cb, 10);\n    });\n    pend.go(function(cb) {\n      setTimeout(cb, 20);\n    });\n    pend.wait(cb);\n  });\n}\n\nfunction testHoldFn(cb) {\n  var pend = new Pend();\n  setTimeout(pend.hold(), 100);\n  pend.go(function(cb) {\n    cb();\n  });\n  pend.wait(cb);\n}\n",
	"transpiled": true
}; item.content= context.Buffer.from(item.content,'binary'); } return item; })
	fileData.push(function(){return {
	"stat": {
		"mtime": "2019-05-18T07:17:58.762Z",
		"mtimeMs": 1558163878762.4539,
		"atime": "2019-05-18T07:17:58.762Z",
		"atimeMs": 1558163878762.4539,
		"isdirectory": true
	},
	"filename": "node_modules/process-nextick-args"
}})
	fileData.push(function(){ var item= cacheData[60]; if(!item){ item= cacheData[60]= {
	"stat": {
		"mtime": "2017-12-11T21:19:17.000Z",
		"mtimeMs": 1513027157000,
		"atime": "2019-05-18T07:17:58.767Z",
		"atimeMs": 1558163878767,
		"isfile": true
	},
	"filename": "node_modules/process-nextick-args/index.js",
	"content": "'use strict';\n\nif (!process.version ||\n    process.version.indexOf('v0.') === 0 ||\n    process.version.indexOf('v1.') === 0 && process.version.indexOf('v1.8.') !== 0) {\n  module.exports = { nextTick: nextTick };\n} else {\n  module.exports = process\n}\n\nfunction nextTick(fn, arg1, arg2, arg3) {\n  if (typeof fn !== 'function') {\n    throw new TypeError('\"callback\" argument must be a function');\n  }\n  var len = arguments.length;\n  var args, i;\n  switch (len) {\n  case 0:\n  case 1:\n    return process.nextTick(fn);\n  case 2:\n    return process.nextTick(function afterTickOne() {\n      fn.call(null, arg1);\n    });\n  case 3:\n    return process.nextTick(function afterTickTwo() {\n      fn.call(null, arg1, arg2);\n    });\n  case 4:\n    return process.nextTick(function afterTickThree() {\n      fn.call(null, arg1, arg2, arg3);\n    });\n  default:\n    args = new Array(len - 1);\n    i = 0;\n    while (i < args.length) {\n      args[i++] = arguments[i];\n    }\n    return process.nextTick(function afterTick() {\n      fn.apply(null, args);\n    });\n  }\n}\n\n",
	"transpiled": true
}; item.content= context.Buffer.from(item.content,'binary'); } return item; })
	fileData.push(function(){ var item= cacheData[61]; if(!item){ item= cacheData[61]= {
	"stat": {
		"mtime": "2017-12-11T21:19:34.000Z",
		"mtimeMs": 1513027174000,
		"atime": "2019-05-18T07:17:58.762Z",
		"atimeMs": 1558163878762.4539,
		"isfile": true
	},
	"filename": "node_modules/process-nextick-args/package.json",
	"content": "{\n  \"name\": \"process-nextick-args\",\n  \"version\": \"2.0.0\",\n  \"description\": \"process.nextTick but always with args\",\n  \"main\": \"index.js\",\n  \"files\": [\n    \"index.js\"\n  ],\n  \"scripts\": {\n    \"test\": \"node test.js\"\n  },\n  \"repository\": {\n    \"type\": \"git\",\n    \"url\": \"https://github.com/calvinmetcalf/process-nextick-args.git\"\n  },\n  \"author\": \"\",\n  \"license\": \"MIT\",\n  \"bugs\": {\n    \"url\": \"https://github.com/calvinmetcalf/process-nextick-args/issues\"\n  },\n  \"homepage\": \"https://github.com/calvinmetcalf/process-nextick-args\",\n  \"devDependencies\": {\n    \"tap\": \"~0.2.6\"\n  }\n}\n",
	"transpiled": true
}; item.content= context.Buffer.from(item.content,'binary'); } return item; })
	fileData.push(function(){return {
	"stat": {
		"mtime": "2019-05-18T07:17:58.666Z",
		"mtimeMs": 1558163878666.4521,
		"atime": "2019-05-18T07:17:58.654Z",
		"atimeMs": 1558163878654.452,
		"isdirectory": true
	},
	"filename": "node_modules/readable-stream"
}})
	fileData.push(function(){return {
	"stat": {
		"mtime": "2019-05-18T07:17:58.666Z",
		"mtimeMs": 1558163878666.4521,
		"atime": "2019-05-18T07:17:58.666Z",
		"atimeMs": 1558163878666.4521,
		"isdirectory": true
	},
	"filename": "node_modules/readable-stream/doc"
}})
	fileData.push(function(){return {
	"stat": {
		"mtime": "2019-05-18T07:17:58.666Z",
		"mtimeMs": 1558163878666.4521,
		"atime": "2019-05-18T07:17:58.666Z",
		"atimeMs": 1558163878666.4521,
		"isdirectory": true
	},
	"filename": "node_modules/readable-stream/doc/wg-meetings"
}})
	fileData.push(function(){ var item= cacheData[65]; if(!item){ item= cacheData[65]= {
	"stat": {
		"mtime": "1985-10-26T08:15:00.000Z",
		"mtimeMs": 499162500000,
		"atime": "2019-05-18T07:17:58.668Z",
		"atimeMs": 1558163878668,
		"isfile": true
	},
	"filename": "node_modules/readable-stream/duplex-browser.js",
	"content": "module.exports = require('./lib/_stream_duplex.js');\n",
	"transpiled": true
}; item.content= context.Buffer.from(item.content,'binary'); } return item; })
	fileData.push(function(){ var item= cacheData[66]; if(!item){ item= cacheData[66]= {
	"stat": {
		"mtime": "1985-10-26T08:15:00.000Z",
		"mtimeMs": 499162500000,
		"atime": "2019-05-18T07:17:58.668Z",
		"atimeMs": 1558163878668,
		"isfile": true
	},
	"filename": "node_modules/readable-stream/duplex.js",
	"content": "module.exports = require('./readable').Duplex\n",
	"transpiled": true
}; item.content= context.Buffer.from(item.content,'binary'); } return item; })
	fileData.push(function(){return {
	"stat": {
		"mtime": "2019-05-18T07:17:58.666Z",
		"mtimeMs": 1558163878666.4521,
		"atime": "2019-05-18T07:17:58.666Z",
		"atimeMs": 1558163878666.4521,
		"isdirectory": true
	},
	"filename": "node_modules/readable-stream/lib"
}})
	fileData.push(function(){ var item= cacheData[68]; if(!item){ item= cacheData[68]= {
	"stat": {
		"mtime": "1985-10-26T08:15:00.000Z",
		"mtimeMs": 499162500000,
		"atime": "2019-05-18T07:17:58.670Z",
		"atimeMs": 1558163878670,
		"isfile": true
	},
	"filename": "node_modules/readable-stream/lib/_stream_duplex.js",
	"content": "// Copyright Joyent, Inc. and other Node contributors.\n//\n// Permission is hereby granted, free of charge, to any person obtaining a\n// copy of this software and associated documentation files (the\n// \"Software\"), to deal in the Software without restriction, including\n// without limitation the rights to use, copy, modify, merge, publish,\n// distribute, sublicense, and/or sell copies of the Software, and to permit\n// persons to whom the Software is furnished to do so, subject to the\n// following conditions:\n//\n// The above copyright notice and this permission notice shall be included\n// in all copies or substantial portions of the Software.\n//\n// THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS\n// OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF\n// MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN\n// NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM,\n// DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR\n// OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE\n// USE OR OTHER DEALINGS IN THE SOFTWARE.\n\n// a duplex stream is just a stream that is both readable and writable.\n// Since JS doesn't have multiple prototypal inheritance, this class\n// prototypally inherits from Readable, and then parasitically from\n// Writable.\n\n'use strict';\n\n/*<replacement>*/\n\nvar pna = require('process-nextick-args');\n/*</replacement>*/\n\n/*<replacement>*/\nvar objectKeys = Object.keys || function (obj) {\n  var keys = [];\n  for (var key in obj) {\n    keys.push(key);\n  }return keys;\n};\n/*</replacement>*/\n\nmodule.exports = Duplex;\n\n/*<replacement>*/\nvar util = require('core-util-is');\nutil.inherits = require('inherits');\n/*</replacement>*/\n\nvar Readable = require('./_stream_readable');\nvar Writable = require('./_stream_writable');\n\nutil.inherits(Duplex, Readable);\n\n{\n  // avoid scope creep, the keys array can then be collected\n  var keys = objectKeys(Writable.prototype);\n  for (var v = 0; v < keys.length; v++) {\n    var method = keys[v];\n    if (!Duplex.prototype[method]) Duplex.prototype[method] = Writable.prototype[method];\n  }\n}\n\nfunction Duplex(options) {\n  if (!(this instanceof Duplex)) return new Duplex(options);\n\n  Readable.call(this, options);\n  Writable.call(this, options);\n\n  if (options && options.readable === false) this.readable = false;\n\n  if (options && options.writable === false) this.writable = false;\n\n  this.allowHalfOpen = true;\n  if (options && options.allowHalfOpen === false) this.allowHalfOpen = false;\n\n  this.once('end', onend);\n}\n\nObject.defineProperty(Duplex.prototype, 'writableHighWaterMark', {\n  // making it explicit this property is not enumerable\n  // because otherwise some prototype manipulation in\n  // userland will fail\n  enumerable: false,\n  get: function () {\n    return this._writableState.highWaterMark;\n  }\n});\n\n// the no-half-open enforcer\nfunction onend() {\n  // if we allow half-open state, or if the writable side ended,\n  // then we're ok.\n  if (this.allowHalfOpen || this._writableState.ended) return;\n\n  // no more data can be written.\n  // But allow more writes to happen in this tick.\n  pna.nextTick(onEndNT, this);\n}\n\nfunction onEndNT(self) {\n  self.end();\n}\n\nObject.defineProperty(Duplex.prototype, 'destroyed', {\n  get: function () {\n    if (this._readableState === undefined || this._writableState === undefined) {\n      return false;\n    }\n    return this._readableState.destroyed && this._writableState.destroyed;\n  },\n  set: function (value) {\n    // we ignore the value if the stream\n    // has not been initialized yet\n    if (this._readableState === undefined || this._writableState === undefined) {\n      return;\n    }\n\n    // backward compatibility, the user is explicitly\n    // managing destroyed\n    this._readableState.destroyed = value;\n    this._writableState.destroyed = value;\n  }\n});\n\nDuplex.prototype._destroy = function (err, cb) {\n  this.push(null);\n  this.end();\n\n  pna.nextTick(cb, err);\n};",
	"transpiled": true
}; item.content= context.Buffer.from(item.content,'binary'); } return item; })
	fileData.push(function(){ var item= cacheData[69]; if(!item){ item= cacheData[69]= {
	"stat": {
		"mtime": "1985-10-26T08:15:00.000Z",
		"mtimeMs": 499162500000,
		"atime": "2019-05-18T07:17:58.670Z",
		"atimeMs": 1558163878670,
		"isfile": true
	},
	"filename": "node_modules/readable-stream/lib/_stream_passthrough.js",
	"content": "// Copyright Joyent, Inc. and other Node contributors.\n//\n// Permission is hereby granted, free of charge, to any person obtaining a\n// copy of this software and associated documentation files (the\n// \"Software\"), to deal in the Software without restriction, including\n// without limitation the rights to use, copy, modify, merge, publish,\n// distribute, sublicense, and/or sell copies of the Software, and to permit\n// persons to whom the Software is furnished to do so, subject to the\n// following conditions:\n//\n// The above copyright notice and this permission notice shall be included\n// in all copies or substantial portions of the Software.\n//\n// THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS\n// OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF\n// MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN\n// NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM,\n// DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR\n// OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE\n// USE OR OTHER DEALINGS IN THE SOFTWARE.\n\n// a passthrough stream.\n// basically just the most minimal sort of Transform stream.\n// Every written chunk gets output as-is.\n\n'use strict';\n\nmodule.exports = PassThrough;\n\nvar Transform = require('./_stream_transform');\n\n/*<replacement>*/\nvar util = require('core-util-is');\nutil.inherits = require('inherits');\n/*</replacement>*/\n\nutil.inherits(PassThrough, Transform);\n\nfunction PassThrough(options) {\n  if (!(this instanceof PassThrough)) return new PassThrough(options);\n\n  Transform.call(this, options);\n}\n\nPassThrough.prototype._transform = function (chunk, encoding, cb) {\n  cb(null, chunk);\n};",
	"transpiled": true
}; item.content= context.Buffer.from(item.content,'binary'); } return item; })
	fileData.push(function(){ var item= cacheData[70]; if(!item){ item= cacheData[70]= {
	"stat": {
		"mtime": "1985-10-26T08:15:00.000Z",
		"mtimeMs": 499162500000,
		"atime": "2019-05-18T07:17:58.671Z",
		"atimeMs": 1558163878671,
		"isfile": true
	},
	"filename": "node_modules/readable-stream/lib/_stream_readable.js",
	"content": "// Copyright Joyent, Inc. and other Node contributors.\n//\n// Permission is hereby granted, free of charge, to any person obtaining a\n// copy of this software and associated documentation files (the\n// \"Software\"), to deal in the Software without restriction, including\n// without limitation the rights to use, copy, modify, merge, publish,\n// distribute, sublicense, and/or sell copies of the Software, and to permit\n// persons to whom the Software is furnished to do so, subject to the\n// following conditions:\n//\n// The above copyright notice and this permission notice shall be included\n// in all copies or substantial portions of the Software.\n//\n// THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS\n// OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF\n// MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN\n// NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM,\n// DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR\n// OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE\n// USE OR OTHER DEALINGS IN THE SOFTWARE.\n\n'use strict';\n\n/*<replacement>*/\n\nvar pna = require('process-nextick-args');\n/*</replacement>*/\n\nmodule.exports = Readable;\n\n/*<replacement>*/\nvar isArray = require('isarray');\n/*</replacement>*/\n\n/*<replacement>*/\nvar Duplex;\n/*</replacement>*/\n\nReadable.ReadableState = ReadableState;\n\n/*<replacement>*/\nvar EE = require('events').EventEmitter;\n\nvar EElistenerCount = function (emitter, type) {\n  return emitter.listeners(type).length;\n};\n/*</replacement>*/\n\n/*<replacement>*/\nvar Stream = require('./internal/streams/stream');\n/*</replacement>*/\n\n/*<replacement>*/\n\nvar Buffer = require('safe-buffer').Buffer;\nvar OurUint8Array = global.Uint8Array || function () {};\nfunction _uint8ArrayToBuffer(chunk) {\n  return Buffer.from(chunk);\n}\nfunction _isUint8Array(obj) {\n  return Buffer.isBuffer(obj) || obj instanceof OurUint8Array;\n}\n\n/*</replacement>*/\n\n/*<replacement>*/\nvar util = require('core-util-is');\nutil.inherits = require('inherits');\n/*</replacement>*/\n\n/*<replacement>*/\nvar debugUtil = require('util');\nvar debug = void 0;\nif (debugUtil && debugUtil.debuglog) {\n  debug = debugUtil.debuglog('stream');\n} else {\n  debug = function () {};\n}\n/*</replacement>*/\n\nvar BufferList = require('./internal/streams/BufferList');\nvar destroyImpl = require('./internal/streams/destroy');\nvar StringDecoder;\n\nutil.inherits(Readable, Stream);\n\nvar kProxyEvents = ['error', 'close', 'destroy', 'pause', 'resume'];\n\nfunction prependListener(emitter, event, fn) {\n  // Sadly this is not cacheable as some libraries bundle their own\n  // event emitter implementation with them.\n  if (typeof emitter.prependListener === 'function') return emitter.prependListener(event, fn);\n\n  // This is a hack to make sure that our error handler is attached before any\n  // userland ones.  NEVER DO THIS. This is here only because this code needs\n  // to continue to work with older versions of Node.js that do not include\n  // the prependListener() method. The goal is to eventually remove this hack.\n  if (!emitter._events || !emitter._events[event]) emitter.on(event, fn);else if (isArray(emitter._events[event])) emitter._events[event].unshift(fn);else emitter._events[event] = [fn, emitter._events[event]];\n}\n\nfunction ReadableState(options, stream) {\n  Duplex = Duplex || require('./_stream_duplex');\n\n  options = options || {};\n\n  // Duplex streams are both readable and writable, but share\n  // the same options object.\n  // However, some cases require setting options to different\n  // values for the readable and the writable sides of the duplex stream.\n  // These options can be provided separately as readableXXX and writableXXX.\n  var isDuplex = stream instanceof Duplex;\n\n  // object stream flag. Used to make read(n) ignore n and to\n  // make all the buffer merging and length checks go away\n  this.objectMode = !!options.objectMode;\n\n  if (isDuplex) this.objectMode = this.objectMode || !!options.readableObjectMode;\n\n  // the point at which it stops calling _read() to fill the buffer\n  // Note: 0 is a valid value, means \"don't call _read preemptively ever\"\n  var hwm = options.highWaterMark;\n  var readableHwm = options.readableHighWaterMark;\n  var defaultHwm = this.objectMode ? 16 : 16 * 1024;\n\n  if (hwm || hwm === 0) this.highWaterMark = hwm;else if (isDuplex && (readableHwm || readableHwm === 0)) this.highWaterMark = readableHwm;else this.highWaterMark = defaultHwm;\n\n  // cast to ints.\n  this.highWaterMark = Math.floor(this.highWaterMark);\n\n  // A linked list is used to store data chunks instead of an array because the\n  // linked list can remove elements from the beginning faster than\n  // array.shift()\n  this.buffer = new BufferList();\n  this.length = 0;\n  this.pipes = null;\n  this.pipesCount = 0;\n  this.flowing = null;\n  this.ended = false;\n  this.endEmitted = false;\n  this.reading = false;\n\n  // a flag to be able to tell if the event 'readable'/'data' is emitted\n  // immediately, or on a later tick.  We set this to true at first, because\n  // any actions that shouldn't happen until \"later\" should generally also\n  // not happen before the first read call.\n  this.sync = true;\n\n  // whenever we return null, then we set a flag to say\n  // that we're awaiting a 'readable' event emission.\n  this.needReadable = false;\n  this.emittedReadable = false;\n  this.readableListening = false;\n  this.resumeScheduled = false;\n\n  // has it been destroyed\n  this.destroyed = false;\n\n  // Crypto is kind of old and crusty.  Historically, its default string\n  // encoding is 'binary' so we have to make this configurable.\n  // Everything else in the universe uses 'utf8', though.\n  this.defaultEncoding = options.defaultEncoding || 'utf8';\n\n  // the number of writers that are awaiting a drain event in .pipe()s\n  this.awaitDrain = 0;\n\n  // if true, a maybeReadMore has been scheduled\n  this.readingMore = false;\n\n  this.decoder = null;\n  this.encoding = null;\n  if (options.encoding) {\n    if (!StringDecoder) StringDecoder = require('string_decoder/').StringDecoder;\n    this.decoder = new StringDecoder(options.encoding);\n    this.encoding = options.encoding;\n  }\n}\n\nfunction Readable(options) {\n  Duplex = Duplex || require('./_stream_duplex');\n\n  if (!(this instanceof Readable)) return new Readable(options);\n\n  this._readableState = new ReadableState(options, this);\n\n  // legacy\n  this.readable = true;\n\n  if (options) {\n    if (typeof options.read === 'function') this._read = options.read;\n\n    if (typeof options.destroy === 'function') this._destroy = options.destroy;\n  }\n\n  Stream.call(this);\n}\n\nObject.defineProperty(Readable.prototype, 'destroyed', {\n  get: function () {\n    if (this._readableState === undefined) {\n      return false;\n    }\n    return this._readableState.destroyed;\n  },\n  set: function (value) {\n    // we ignore the value if the stream\n    // has not been initialized yet\n    if (!this._readableState) {\n      return;\n    }\n\n    // backward compatibility, the user is explicitly\n    // managing destroyed\n    this._readableState.destroyed = value;\n  }\n});\n\nReadable.prototype.destroy = destroyImpl.destroy;\nReadable.prototype._undestroy = destroyImpl.undestroy;\nReadable.prototype._destroy = function (err, cb) {\n  this.push(null);\n  cb(err);\n};\n\n// Manually shove something into the read() buffer.\n// This returns true if the highWaterMark has not been hit yet,\n// similar to how Writable.write() returns true if you should\n// write() some more.\nReadable.prototype.push = function (chunk, encoding) {\n  var state = this._readableState;\n  var skipChunkCheck;\n\n  if (!state.objectMode) {\n    if (typeof chunk === 'string') {\n      encoding = encoding || state.defaultEncoding;\n      if (encoding !== state.encoding) {\n        chunk = Buffer.from(chunk, encoding);\n        encoding = '';\n      }\n      skipChunkCheck = true;\n    }\n  } else {\n    skipChunkCheck = true;\n  }\n\n  return readableAddChunk(this, chunk, encoding, false, skipChunkCheck);\n};\n\n// Unshift should *always* be something directly out of read()\nReadable.prototype.unshift = function (chunk) {\n  return readableAddChunk(this, chunk, null, true, false);\n};\n\nfunction readableAddChunk(stream, chunk, encoding, addToFront, skipChunkCheck) {\n  var state = stream._readableState;\n  if (chunk === null) {\n    state.reading = false;\n    onEofChunk(stream, state);\n  } else {\n    var er;\n    if (!skipChunkCheck) er = chunkInvalid(state, chunk);\n    if (er) {\n      stream.emit('error', er);\n    } else if (state.objectMode || chunk && chunk.length > 0) {\n      if (typeof chunk !== 'string' && !state.objectMode && Object.getPrototypeOf(chunk) !== Buffer.prototype) {\n        chunk = _uint8ArrayToBuffer(chunk);\n      }\n\n      if (addToFront) {\n        if (state.endEmitted) stream.emit('error', new Error('stream.unshift() after end event'));else addChunk(stream, state, chunk, true);\n      } else if (state.ended) {\n        stream.emit('error', new Error('stream.push() after EOF'));\n      } else {\n        state.reading = false;\n        if (state.decoder && !encoding) {\n          chunk = state.decoder.write(chunk);\n          if (state.objectMode || chunk.length !== 0) addChunk(stream, state, chunk, false);else maybeReadMore(stream, state);\n        } else {\n          addChunk(stream, state, chunk, false);\n        }\n      }\n    } else if (!addToFront) {\n      state.reading = false;\n    }\n  }\n\n  return needMoreData(state);\n}\n\nfunction addChunk(stream, state, chunk, addToFront) {\n  if (state.flowing && state.length === 0 && !state.sync) {\n    stream.emit('data', chunk);\n    stream.read(0);\n  } else {\n    // update the buffer info.\n    state.length += state.objectMode ? 1 : chunk.length;\n    if (addToFront) state.buffer.unshift(chunk);else state.buffer.push(chunk);\n\n    if (state.needReadable) emitReadable(stream);\n  }\n  maybeReadMore(stream, state);\n}\n\nfunction chunkInvalid(state, chunk) {\n  var er;\n  if (!_isUint8Array(chunk) && typeof chunk !== 'string' && chunk !== undefined && !state.objectMode) {\n    er = new TypeError('Invalid non-string/buffer chunk');\n  }\n  return er;\n}\n\n// if it's past the high water mark, we can push in some more.\n// Also, if we have no data yet, we can stand some\n// more bytes.  This is to work around cases where hwm=0,\n// such as the repl.  Also, if the push() triggered a\n// readable event, and the user called read(largeNumber) such that\n// needReadable was set, then we ought to push more, so that another\n// 'readable' event will be triggered.\nfunction needMoreData(state) {\n  return !state.ended && (state.needReadable || state.length < state.highWaterMark || state.length === 0);\n}\n\nReadable.prototype.isPaused = function () {\n  return this._readableState.flowing === false;\n};\n\n// backwards compatibility.\nReadable.prototype.setEncoding = function (enc) {\n  if (!StringDecoder) StringDecoder = require('string_decoder/').StringDecoder;\n  this._readableState.decoder = new StringDecoder(enc);\n  this._readableState.encoding = enc;\n  return this;\n};\n\n// Don't raise the hwm > 8MB\nvar MAX_HWM = 0x800000;\nfunction computeNewHighWaterMark(n) {\n  if (n >= MAX_HWM) {\n    n = MAX_HWM;\n  } else {\n    // Get the next highest power of 2 to prevent increasing hwm excessively in\n    // tiny amounts\n    n--;\n    n |= n >>> 1;\n    n |= n >>> 2;\n    n |= n >>> 4;\n    n |= n >>> 8;\n    n |= n >>> 16;\n    n++;\n  }\n  return n;\n}\n\n// This function is designed to be inlinable, so please take care when making\n// changes to the function body.\nfunction howMuchToRead(n, state) {\n  if (n <= 0 || state.length === 0 && state.ended) return 0;\n  if (state.objectMode) return 1;\n  if (n !== n) {\n    // Only flow one buffer at a time\n    if (state.flowing && state.length) return state.buffer.head.data.length;else return state.length;\n  }\n  // If we're asking for more than the current hwm, then raise the hwm.\n  if (n > state.highWaterMark) state.highWaterMark = computeNewHighWaterMark(n);\n  if (n <= state.length) return n;\n  // Don't have enough\n  if (!state.ended) {\n    state.needReadable = true;\n    return 0;\n  }\n  return state.length;\n}\n\n// you can override either this method, or the async _read(n) below.\nReadable.prototype.read = function (n) {\n  debug('read', n);\n  n = parseInt(n, 10);\n  var state = this._readableState;\n  var nOrig = n;\n\n  if (n !== 0) state.emittedReadable = false;\n\n  // if we're doing read(0) to trigger a readable event, but we\n  // already have a bunch of data in the buffer, then just trigger\n  // the 'readable' event and move on.\n  if (n === 0 && state.needReadable && (state.length >= state.highWaterMark || state.ended)) {\n    debug('read: emitReadable', state.length, state.ended);\n    if (state.length === 0 && state.ended) endReadable(this);else emitReadable(this);\n    return null;\n  }\n\n  n = howMuchToRead(n, state);\n\n  // if we've ended, and we're now clear, then finish it up.\n  if (n === 0 && state.ended) {\n    if (state.length === 0) endReadable(this);\n    return null;\n  }\n\n  // All the actual chunk generation logic needs to be\n  // *below* the call to _read.  The reason is that in certain\n  // synthetic stream cases, such as passthrough streams, _read\n  // may be a completely synchronous operation which may change\n  // the state of the read buffer, providing enough data when\n  // before there was *not* enough.\n  //\n  // So, the steps are:\n  // 1. Figure out what the state of things will be after we do\n  // a read from the buffer.\n  //\n  // 2. If that resulting state will trigger a _read, then call _read.\n  // Note that this may be asynchronous, or synchronous.  Yes, it is\n  // deeply ugly to write APIs this way, but that still doesn't mean\n  // that the Readable class should behave improperly, as streams are\n  // designed to be sync/async agnostic.\n  // Take note if the _read call is sync or async (ie, if the read call\n  // has returned yet), so that we know whether or not it's safe to emit\n  // 'readable' etc.\n  //\n  // 3. Actually pull the requested chunks out of the buffer and return.\n\n  // if we need a readable event, then we need to do some reading.\n  var doRead = state.needReadable;\n  debug('need readable', doRead);\n\n  // if we currently have less than the highWaterMark, then also read some\n  if (state.length === 0 || state.length - n < state.highWaterMark) {\n    doRead = true;\n    debug('length less than watermark', doRead);\n  }\n\n  // however, if we've ended, then there's no point, and if we're already\n  // reading, then it's unnecessary.\n  if (state.ended || state.reading) {\n    doRead = false;\n    debug('reading or ended', doRead);\n  } else if (doRead) {\n    debug('do read');\n    state.reading = true;\n    state.sync = true;\n    // if the length is currently zero, then we *need* a readable event.\n    if (state.length === 0) state.needReadable = true;\n    // call internal read method\n    this._read(state.highWaterMark);\n    state.sync = false;\n    // If _read pushed data synchronously, then `reading` will be false,\n    // and we need to re-evaluate how much data we can return to the user.\n    if (!state.reading) n = howMuchToRead(nOrig, state);\n  }\n\n  var ret;\n  if (n > 0) ret = fromList(n, state);else ret = null;\n\n  if (ret === null) {\n    state.needReadable = true;\n    n = 0;\n  } else {\n    state.length -= n;\n  }\n\n  if (state.length === 0) {\n    // If we have nothing in the buffer, then we want to know\n    // as soon as we *do* get something into the buffer.\n    if (!state.ended) state.needReadable = true;\n\n    // If we tried to read() past the EOF, then emit end on the next tick.\n    if (nOrig !== n && state.ended) endReadable(this);\n  }\n\n  if (ret !== null) this.emit('data', ret);\n\n  return ret;\n};\n\nfunction onEofChunk(stream, state) {\n  if (state.ended) return;\n  if (state.decoder) {\n    var chunk = state.decoder.end();\n    if (chunk && chunk.length) {\n      state.buffer.push(chunk);\n      state.length += state.objectMode ? 1 : chunk.length;\n    }\n  }\n  state.ended = true;\n\n  // emit 'readable' now to make sure it gets picked up.\n  emitReadable(stream);\n}\n\n// Don't emit readable right away in sync mode, because this can trigger\n// another read() call => stack overflow.  This way, it might trigger\n// a nextTick recursion warning, but that's not so bad.\nfunction emitReadable(stream) {\n  var state = stream._readableState;\n  state.needReadable = false;\n  if (!state.emittedReadable) {\n    debug('emitReadable', state.flowing);\n    state.emittedReadable = true;\n    if (state.sync) pna.nextTick(emitReadable_, stream);else emitReadable_(stream);\n  }\n}\n\nfunction emitReadable_(stream) {\n  debug('emit readable');\n  stream.emit('readable');\n  flow(stream);\n}\n\n// at this point, the user has presumably seen the 'readable' event,\n// and called read() to consume some data.  that may have triggered\n// in turn another _read(n) call, in which case reading = true if\n// it's in progress.\n// However, if we're not ended, or reading, and the length < hwm,\n// then go ahead and try to read some more preemptively.\nfunction maybeReadMore(stream, state) {\n  if (!state.readingMore) {\n    state.readingMore = true;\n    pna.nextTick(maybeReadMore_, stream, state);\n  }\n}\n\nfunction maybeReadMore_(stream, state) {\n  var len = state.length;\n  while (!state.reading && !state.flowing && !state.ended && state.length < state.highWaterMark) {\n    debug('maybeReadMore read 0');\n    stream.read(0);\n    if (len === state.length)\n      // didn't get any data, stop spinning.\n      break;else len = state.length;\n  }\n  state.readingMore = false;\n}\n\n// abstract method.  to be overridden in specific implementation classes.\n// call cb(er, data) where data is <= n in length.\n// for virtual (non-string, non-buffer) streams, \"length\" is somewhat\n// arbitrary, and perhaps not very meaningful.\nReadable.prototype._read = function (n) {\n  this.emit('error', new Error('_read() is not implemented'));\n};\n\nReadable.prototype.pipe = function (dest, pipeOpts) {\n  var src = this;\n  var state = this._readableState;\n\n  switch (state.pipesCount) {\n    case 0:\n      state.pipes = dest;\n      break;\n    case 1:\n      state.pipes = [state.pipes, dest];\n      break;\n    default:\n      state.pipes.push(dest);\n      break;\n  }\n  state.pipesCount += 1;\n  debug('pipe count=%d opts=%j', state.pipesCount, pipeOpts);\n\n  var doEnd = (!pipeOpts || pipeOpts.end !== false) && dest !== process.stdout && dest !== process.stderr;\n\n  var endFn = doEnd ? onend : unpipe;\n  if (state.endEmitted) pna.nextTick(endFn);else src.once('end', endFn);\n\n  dest.on('unpipe', onunpipe);\n  function onunpipe(readable, unpipeInfo) {\n    debug('onunpipe');\n    if (readable === src) {\n      if (unpipeInfo && unpipeInfo.hasUnpiped === false) {\n        unpipeInfo.hasUnpiped = true;\n        cleanup();\n      }\n    }\n  }\n\n  function onend() {\n    debug('onend');\n    dest.end();\n  }\n\n  // when the dest drains, it reduces the awaitDrain counter\n  // on the source.  This would be more elegant with a .once()\n  // handler in flow(), but adding and removing repeatedly is\n  // too slow.\n  var ondrain = pipeOnDrain(src);\n  dest.on('drain', ondrain);\n\n  var cleanedUp = false;\n  function cleanup() {\n    debug('cleanup');\n    // cleanup event handlers once the pipe is broken\n    dest.removeListener('close', onclose);\n    dest.removeListener('finish', onfinish);\n    dest.removeListener('drain', ondrain);\n    dest.removeListener('error', onerror);\n    dest.removeListener('unpipe', onunpipe);\n    src.removeListener('end', onend);\n    src.removeListener('end', unpipe);\n    src.removeListener('data', ondata);\n\n    cleanedUp = true;\n\n    // if the reader is waiting for a drain event from this\n    // specific writer, then it would cause it to never start\n    // flowing again.\n    // So, if this is awaiting a drain, then we just call it now.\n    // If we don't know, then assume that we are waiting for one.\n    if (state.awaitDrain && (!dest._writableState || dest._writableState.needDrain)) ondrain();\n  }\n\n  // If the user pushes more data while we're writing to dest then we'll end up\n  // in ondata again. However, we only want to increase awaitDrain once because\n  // dest will only emit one 'drain' event for the multiple writes.\n  // => Introduce a guard on increasing awaitDrain.\n  var increasedAwaitDrain = false;\n  src.on('data', ondata);\n  function ondata(chunk) {\n    debug('ondata');\n    increasedAwaitDrain = false;\n    var ret = dest.write(chunk);\n    if (false === ret && !increasedAwaitDrain) {\n      // If the user unpiped during `dest.write()`, it is possible\n      // to get stuck in a permanently paused state if that write\n      // also returned false.\n      // => Check whether `dest` is still a piping destination.\n      if ((state.pipesCount === 1 && state.pipes === dest || state.pipesCount > 1 && indexOf(state.pipes, dest) !== -1) && !cleanedUp) {\n        debug('false write response, pause', src._readableState.awaitDrain);\n        src._readableState.awaitDrain++;\n        increasedAwaitDrain = true;\n      }\n      src.pause();\n    }\n  }\n\n  // if the dest has an error, then stop piping into it.\n  // however, don't suppress the throwing behavior for this.\n  function onerror(er) {\n    debug('onerror', er);\n    unpipe();\n    dest.removeListener('error', onerror);\n    if (EElistenerCount(dest, 'error') === 0) dest.emit('error', er);\n  }\n\n  // Make sure our error handler is attached before userland ones.\n  prependListener(dest, 'error', onerror);\n\n  // Both close and finish should trigger unpipe, but only once.\n  function onclose() {\n    dest.removeListener('finish', onfinish);\n    unpipe();\n  }\n  dest.once('close', onclose);\n  function onfinish() {\n    debug('onfinish');\n    dest.removeListener('close', onclose);\n    unpipe();\n  }\n  dest.once('finish', onfinish);\n\n  function unpipe() {\n    debug('unpipe');\n    src.unpipe(dest);\n  }\n\n  // tell the dest that it's being piped to\n  dest.emit('pipe', src);\n\n  // start the flow if it hasn't been started already.\n  if (!state.flowing) {\n    debug('pipe resume');\n    src.resume();\n  }\n\n  return dest;\n};\n\nfunction pipeOnDrain(src) {\n  return function () {\n    var state = src._readableState;\n    debug('pipeOnDrain', state.awaitDrain);\n    if (state.awaitDrain) state.awaitDrain--;\n    if (state.awaitDrain === 0 && EElistenerCount(src, 'data')) {\n      state.flowing = true;\n      flow(src);\n    }\n  };\n}\n\nReadable.prototype.unpipe = function (dest) {\n  var state = this._readableState;\n  var unpipeInfo = { hasUnpiped: false };\n\n  // if we're not piping anywhere, then do nothing.\n  if (state.pipesCount === 0) return this;\n\n  // just one destination.  most common case.\n  if (state.pipesCount === 1) {\n    // passed in one, but it's not the right one.\n    if (dest && dest !== state.pipes) return this;\n\n    if (!dest) dest = state.pipes;\n\n    // got a match.\n    state.pipes = null;\n    state.pipesCount = 0;\n    state.flowing = false;\n    if (dest) dest.emit('unpipe', this, unpipeInfo);\n    return this;\n  }\n\n  // slow case. multiple pipe destinations.\n\n  if (!dest) {\n    // remove all.\n    var dests = state.pipes;\n    var len = state.pipesCount;\n    state.pipes = null;\n    state.pipesCount = 0;\n    state.flowing = false;\n\n    for (var i = 0; i < len; i++) {\n      dests[i].emit('unpipe', this, unpipeInfo);\n    }return this;\n  }\n\n  // try to find the right one.\n  var index = indexOf(state.pipes, dest);\n  if (index === -1) return this;\n\n  state.pipes.splice(index, 1);\n  state.pipesCount -= 1;\n  if (state.pipesCount === 1) state.pipes = state.pipes[0];\n\n  dest.emit('unpipe', this, unpipeInfo);\n\n  return this;\n};\n\n// set up data events if they are asked for\n// Ensure readable listeners eventually get something\nReadable.prototype.on = function (ev, fn) {\n  var res = Stream.prototype.on.call(this, ev, fn);\n\n  if (ev === 'data') {\n    // Start flowing on next tick if stream isn't explicitly paused\n    if (this._readableState.flowing !== false) this.resume();\n  } else if (ev === 'readable') {\n    var state = this._readableState;\n    if (!state.endEmitted && !state.readableListening) {\n      state.readableListening = state.needReadable = true;\n      state.emittedReadable = false;\n      if (!state.reading) {\n        pna.nextTick(nReadingNextTick, this);\n      } else if (state.length) {\n        emitReadable(this);\n      }\n    }\n  }\n\n  return res;\n};\nReadable.prototype.addListener = Readable.prototype.on;\n\nfunction nReadingNextTick(self) {\n  debug('readable nexttick read 0');\n  self.read(0);\n}\n\n// pause() and resume() are remnants of the legacy readable stream API\n// If the user uses them, then switch into old mode.\nReadable.prototype.resume = function () {\n  var state = this._readableState;\n  if (!state.flowing) {\n    debug('resume');\n    state.flowing = true;\n    resume(this, state);\n  }\n  return this;\n};\n\nfunction resume(stream, state) {\n  if (!state.resumeScheduled) {\n    state.resumeScheduled = true;\n    pna.nextTick(resume_, stream, state);\n  }\n}\n\nfunction resume_(stream, state) {\n  if (!state.reading) {\n    debug('resume read 0');\n    stream.read(0);\n  }\n\n  state.resumeScheduled = false;\n  state.awaitDrain = 0;\n  stream.emit('resume');\n  flow(stream);\n  if (state.flowing && !state.reading) stream.read(0);\n}\n\nReadable.prototype.pause = function () {\n  debug('call pause flowing=%j', this._readableState.flowing);\n  if (false !== this._readableState.flowing) {\n    debug('pause');\n    this._readableState.flowing = false;\n    this.emit('pause');\n  }\n  return this;\n};\n\nfunction flow(stream) {\n  var state = stream._readableState;\n  debug('flow', state.flowing);\n  while (state.flowing && stream.read() !== null) {}\n}\n\n// wrap an old-style stream as the async data source.\n// This is *not* part of the readable stream interface.\n// It is an ugly unfortunate mess of history.\nReadable.prototype.wrap = function (stream) {\n  var _this = this;\n\n  var state = this._readableState;\n  var paused = false;\n\n  stream.on('end', function () {\n    debug('wrapped end');\n    if (state.decoder && !state.ended) {\n      var chunk = state.decoder.end();\n      if (chunk && chunk.length) _this.push(chunk);\n    }\n\n    _this.push(null);\n  });\n\n  stream.on('data', function (chunk) {\n    debug('wrapped data');\n    if (state.decoder) chunk = state.decoder.write(chunk);\n\n    // don't skip over falsy values in objectMode\n    if (state.objectMode && (chunk === null || chunk === undefined)) return;else if (!state.objectMode && (!chunk || !chunk.length)) return;\n\n    var ret = _this.push(chunk);\n    if (!ret) {\n      paused = true;\n      stream.pause();\n    }\n  });\n\n  // proxy all the other methods.\n  // important when wrapping filters and duplexes.\n  for (var i in stream) {\n    if (this[i] === undefined && typeof stream[i] === 'function') {\n      this[i] = function (method) {\n        return function () {\n          return stream[method].apply(stream, arguments);\n        };\n      }(i);\n    }\n  }\n\n  // proxy certain important events.\n  for (var n = 0; n < kProxyEvents.length; n++) {\n    stream.on(kProxyEvents[n], this.emit.bind(this, kProxyEvents[n]));\n  }\n\n  // when we try to consume some more bytes, simply unpause the\n  // underlying stream.\n  this._read = function (n) {\n    debug('wrapped _read', n);\n    if (paused) {\n      paused = false;\n      stream.resume();\n    }\n  };\n\n  return this;\n};\n\nObject.defineProperty(Readable.prototype, 'readableHighWaterMark', {\n  // making it explicit this property is not enumerable\n  // because otherwise some prototype manipulation in\n  // userland will fail\n  enumerable: false,\n  get: function () {\n    return this._readableState.highWaterMark;\n  }\n});\n\n// exposed for testing purposes only.\nReadable._fromList = fromList;\n\n// Pluck off n bytes from an array of buffers.\n// Length is the combined lengths of all the buffers in the list.\n// This function is designed to be inlinable, so please take care when making\n// changes to the function body.\nfunction fromList(n, state) {\n  // nothing buffered\n  if (state.length === 0) return null;\n\n  var ret;\n  if (state.objectMode) ret = state.buffer.shift();else if (!n || n >= state.length) {\n    // read it all, truncate the list\n    if (state.decoder) ret = state.buffer.join('');else if (state.buffer.length === 1) ret = state.buffer.head.data;else ret = state.buffer.concat(state.length);\n    state.buffer.clear();\n  } else {\n    // read part of list\n    ret = fromListPartial(n, state.buffer, state.decoder);\n  }\n\n  return ret;\n}\n\n// Extracts only enough buffered data to satisfy the amount requested.\n// This function is designed to be inlinable, so please take care when making\n// changes to the function body.\nfunction fromListPartial(n, list, hasStrings) {\n  var ret;\n  if (n < list.head.data.length) {\n    // slice is the same for buffers and strings\n    ret = list.head.data.slice(0, n);\n    list.head.data = list.head.data.slice(n);\n  } else if (n === list.head.data.length) {\n    // first chunk is a perfect match\n    ret = list.shift();\n  } else {\n    // result spans more than one buffer\n    ret = hasStrings ? copyFromBufferString(n, list) : copyFromBuffer(n, list);\n  }\n  return ret;\n}\n\n// Copies a specified amount of characters from the list of buffered data\n// chunks.\n// This function is designed to be inlinable, so please take care when making\n// changes to the function body.\nfunction copyFromBufferString(n, list) {\n  var p = list.head;\n  var c = 1;\n  var ret = p.data;\n  n -= ret.length;\n  while (p = p.next) {\n    var str = p.data;\n    var nb = n > str.length ? str.length : n;\n    if (nb === str.length) ret += str;else ret += str.slice(0, n);\n    n -= nb;\n    if (n === 0) {\n      if (nb === str.length) {\n        ++c;\n        if (p.next) list.head = p.next;else list.head = list.tail = null;\n      } else {\n        list.head = p;\n        p.data = str.slice(nb);\n      }\n      break;\n    }\n    ++c;\n  }\n  list.length -= c;\n  return ret;\n}\n\n// Copies a specified amount of bytes from the list of buffered data chunks.\n// This function is designed to be inlinable, so please take care when making\n// changes to the function body.\nfunction copyFromBuffer(n, list) {\n  var ret = Buffer.allocUnsafe(n);\n  var p = list.head;\n  var c = 1;\n  p.data.copy(ret);\n  n -= p.data.length;\n  while (p = p.next) {\n    var buf = p.data;\n    var nb = n > buf.length ? buf.length : n;\n    buf.copy(ret, ret.length - n, 0, nb);\n    n -= nb;\n    if (n === 0) {\n      if (nb === buf.length) {\n        ++c;\n        if (p.next) list.head = p.next;else list.head = list.tail = null;\n      } else {\n        list.head = p;\n        p.data = buf.slice(nb);\n      }\n      break;\n    }\n    ++c;\n  }\n  list.length -= c;\n  return ret;\n}\n\nfunction endReadable(stream) {\n  var state = stream._readableState;\n\n  // If we get here before consuming all the bytes, then that is a\n  // bug in node.  Should never happen.\n  if (state.length > 0) throw new Error('\"endReadable()\" called on non-empty stream');\n\n  if (!state.endEmitted) {\n    state.ended = true;\n    pna.nextTick(endReadableNT, state, stream);\n  }\n}\n\nfunction endReadableNT(state, stream) {\n  // Check that we didn't get one last unshift.\n  if (!state.endEmitted && state.length === 0) {\n    state.endEmitted = true;\n    stream.readable = false;\n    stream.emit('end');\n  }\n}\n\nfunction indexOf(xs, x) {\n  for (var i = 0, l = xs.length; i < l; i++) {\n    if (xs[i] === x) return i;\n  }\n  return -1;\n}",
	"transpiled": true
}; item.content= context.Buffer.from(item.content,'binary'); } return item; })
	fileData.push(function(){ var item= cacheData[71]; if(!item){ item= cacheData[71]= {
	"stat": {
		"mtime": "1985-10-26T08:15:00.000Z",
		"mtimeMs": 499162500000,
		"atime": "2019-05-18T07:17:58.671Z",
		"atimeMs": 1558163878671,
		"isfile": true
	},
	"filename": "node_modules/readable-stream/lib/_stream_transform.js",
	"content": "// Copyright Joyent, Inc. and other Node contributors.\n//\n// Permission is hereby granted, free of charge, to any person obtaining a\n// copy of this software and associated documentation files (the\n// \"Software\"), to deal in the Software without restriction, including\n// without limitation the rights to use, copy, modify, merge, publish,\n// distribute, sublicense, and/or sell copies of the Software, and to permit\n// persons to whom the Software is furnished to do so, subject to the\n// following conditions:\n//\n// The above copyright notice and this permission notice shall be included\n// in all copies or substantial portions of the Software.\n//\n// THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS\n// OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF\n// MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN\n// NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM,\n// DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR\n// OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE\n// USE OR OTHER DEALINGS IN THE SOFTWARE.\n\n// a transform stream is a readable/writable stream where you do\n// something with the data.  Sometimes it's called a \"filter\",\n// but that's not a great name for it, since that implies a thing where\n// some bits pass through, and others are simply ignored.  (That would\n// be a valid example of a transform, of course.)\n//\n// While the output is causally related to the input, it's not a\n// necessarily symmetric or synchronous transformation.  For example,\n// a zlib stream might take multiple plain-text writes(), and then\n// emit a single compressed chunk some time in the future.\n//\n// Here's how this works:\n//\n// The Transform stream has all the aspects of the readable and writable\n// stream classes.  When you write(chunk), that calls _write(chunk,cb)\n// internally, and returns false if there's a lot of pending writes\n// buffered up.  When you call read(), that calls _read(n) until\n// there's enough pending readable data buffered up.\n//\n// In a transform stream, the written data is placed in a buffer.  When\n// _read(n) is called, it transforms the queued up data, calling the\n// buffered _write cb's as it consumes chunks.  If consuming a single\n// written chunk would result in multiple output chunks, then the first\n// outputted bit calls the readcb, and subsequent chunks just go into\n// the read buffer, and will cause it to emit 'readable' if necessary.\n//\n// This way, back-pressure is actually determined by the reading side,\n// since _read has to be called to start processing a new chunk.  However,\n// a pathological inflate type of transform can cause excessive buffering\n// here.  For example, imagine a stream where every byte of input is\n// interpreted as an integer from 0-255, and then results in that many\n// bytes of output.  Writing the 4 bytes {ff,ff,ff,ff} would result in\n// 1kb of data being output.  In this case, you could write a very small\n// amount of input, and end up with a very large amount of output.  In\n// such a pathological inflating mechanism, there'd be no way to tell\n// the system to stop doing the transform.  A single 4MB write could\n// cause the system to run out of memory.\n//\n// However, even in such a pathological case, only a single written chunk\n// would be consumed, and then the rest would wait (un-transformed) until\n// the results of the previous transformed chunk were consumed.\n\n'use strict';\n\nmodule.exports = Transform;\n\nvar Duplex = require('./_stream_duplex');\n\n/*<replacement>*/\nvar util = require('core-util-is');\nutil.inherits = require('inherits');\n/*</replacement>*/\n\nutil.inherits(Transform, Duplex);\n\nfunction afterTransform(er, data) {\n  var ts = this._transformState;\n  ts.transforming = false;\n\n  var cb = ts.writecb;\n\n  if (!cb) {\n    return this.emit('error', new Error('write callback called multiple times'));\n  }\n\n  ts.writechunk = null;\n  ts.writecb = null;\n\n  if (data != null) // single equals check for both `null` and `undefined`\n    this.push(data);\n\n  cb(er);\n\n  var rs = this._readableState;\n  rs.reading = false;\n  if (rs.needReadable || rs.length < rs.highWaterMark) {\n    this._read(rs.highWaterMark);\n  }\n}\n\nfunction Transform(options) {\n  if (!(this instanceof Transform)) return new Transform(options);\n\n  Duplex.call(this, options);\n\n  this._transformState = {\n    afterTransform: afterTransform.bind(this),\n    needTransform: false,\n    transforming: false,\n    writecb: null,\n    writechunk: null,\n    writeencoding: null\n  };\n\n  // start out asking for a readable event once data is transformed.\n  this._readableState.needReadable = true;\n\n  // we have implemented the _read method, and done the other things\n  // that Readable wants before the first _read call, so unset the\n  // sync guard flag.\n  this._readableState.sync = false;\n\n  if (options) {\n    if (typeof options.transform === 'function') this._transform = options.transform;\n\n    if (typeof options.flush === 'function') this._flush = options.flush;\n  }\n\n  // When the writable side finishes, then flush out anything remaining.\n  this.on('prefinish', prefinish);\n}\n\nfunction prefinish() {\n  var _this = this;\n\n  if (typeof this._flush === 'function') {\n    this._flush(function (er, data) {\n      done(_this, er, data);\n    });\n  } else {\n    done(this, null, null);\n  }\n}\n\nTransform.prototype.push = function (chunk, encoding) {\n  this._transformState.needTransform = false;\n  return Duplex.prototype.push.call(this, chunk, encoding);\n};\n\n// This is the part where you do stuff!\n// override this function in implementation classes.\n// 'chunk' is an input chunk.\n//\n// Call `push(newChunk)` to pass along transformed output\n// to the readable side.  You may call 'push' zero or more times.\n//\n// Call `cb(err)` when you are done with this chunk.  If you pass\n// an error, then that'll put the hurt on the whole operation.  If you\n// never call cb(), then you'll never get another chunk.\nTransform.prototype._transform = function (chunk, encoding, cb) {\n  throw new Error('_transform() is not implemented');\n};\n\nTransform.prototype._write = function (chunk, encoding, cb) {\n  var ts = this._transformState;\n  ts.writecb = cb;\n  ts.writechunk = chunk;\n  ts.writeencoding = encoding;\n  if (!ts.transforming) {\n    var rs = this._readableState;\n    if (ts.needTransform || rs.needReadable || rs.length < rs.highWaterMark) this._read(rs.highWaterMark);\n  }\n};\n\n// Doesn't matter what the args are here.\n// _transform does all the work.\n// That we got here means that the readable side wants more data.\nTransform.prototype._read = function (n) {\n  var ts = this._transformState;\n\n  if (ts.writechunk !== null && ts.writecb && !ts.transforming) {\n    ts.transforming = true;\n    this._transform(ts.writechunk, ts.writeencoding, ts.afterTransform);\n  } else {\n    // mark that we need a transform, so that any data that comes in\n    // will get processed, now that we've asked for it.\n    ts.needTransform = true;\n  }\n};\n\nTransform.prototype._destroy = function (err, cb) {\n  var _this2 = this;\n\n  Duplex.prototype._destroy.call(this, err, function (err2) {\n    cb(err2);\n    _this2.emit('close');\n  });\n};\n\nfunction done(stream, er, data) {\n  if (er) return stream.emit('error', er);\n\n  if (data != null) // single equals check for both `null` and `undefined`\n    stream.push(data);\n\n  // if there's nothing in the write buffer, then that means\n  // that nothing more will ever be provided\n  if (stream._writableState.length) throw new Error('Calling transform done when ws.length != 0');\n\n  if (stream._transformState.transforming) throw new Error('Calling transform done when still transforming');\n\n  return stream.push(null);\n}",
	"transpiled": true
}; item.content= context.Buffer.from(item.content,'binary'); } return item; })
	fileData.push(function(){ var item= cacheData[72]; if(!item){ item= cacheData[72]= {
	"stat": {
		"mtime": "1985-10-26T08:15:00.000Z",
		"mtimeMs": 499162500000,
		"atime": "2019-05-18T07:17:58.671Z",
		"atimeMs": 1558163878671,
		"isfile": true
	},
	"filename": "node_modules/readable-stream/lib/_stream_writable.js",
	"content": "// Copyright Joyent, Inc. and other Node contributors.\n//\n// Permission is hereby granted, free of charge, to any person obtaining a\n// copy of this software and associated documentation files (the\n// \"Software\"), to deal in the Software without restriction, including\n// without limitation the rights to use, copy, modify, merge, publish,\n// distribute, sublicense, and/or sell copies of the Software, and to permit\n// persons to whom the Software is furnished to do so, subject to the\n// following conditions:\n//\n// The above copyright notice and this permission notice shall be included\n// in all copies or substantial portions of the Software.\n//\n// THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS\n// OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF\n// MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN\n// NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM,\n// DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR\n// OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE\n// USE OR OTHER DEALINGS IN THE SOFTWARE.\n\n// A bit simpler than readable streams.\n// Implement an async ._write(chunk, encoding, cb), and it'll handle all\n// the drain event emission and buffering.\n\n'use strict';\n\n/*<replacement>*/\n\nvar pna = require('process-nextick-args');\n/*</replacement>*/\n\nmodule.exports = Writable;\n\n/* <replacement> */\nfunction WriteReq(chunk, encoding, cb) {\n  this.chunk = chunk;\n  this.encoding = encoding;\n  this.callback = cb;\n  this.next = null;\n}\n\n// It seems a linked list but it is not\n// there will be only 2 of these for each stream\nfunction CorkedRequest(state) {\n  var _this = this;\n\n  this.next = null;\n  this.entry = null;\n  this.finish = function () {\n    onCorkedFinish(_this, state);\n  };\n}\n/* </replacement> */\n\n/*<replacement>*/\nvar asyncWrite = !process.browser && ['v0.10', 'v0.9.'].indexOf(process.version.slice(0, 5)) > -1 ? setImmediate : pna.nextTick;\n/*</replacement>*/\n\n/*<replacement>*/\nvar Duplex;\n/*</replacement>*/\n\nWritable.WritableState = WritableState;\n\n/*<replacement>*/\nvar util = require('core-util-is');\nutil.inherits = require('inherits');\n/*</replacement>*/\n\n/*<replacement>*/\nvar internalUtil = {\n  deprecate: require('util-deprecate')\n};\n/*</replacement>*/\n\n/*<replacement>*/\nvar Stream = require('./internal/streams/stream');\n/*</replacement>*/\n\n/*<replacement>*/\n\nvar Buffer = require('safe-buffer').Buffer;\nvar OurUint8Array = global.Uint8Array || function () {};\nfunction _uint8ArrayToBuffer(chunk) {\n  return Buffer.from(chunk);\n}\nfunction _isUint8Array(obj) {\n  return Buffer.isBuffer(obj) || obj instanceof OurUint8Array;\n}\n\n/*</replacement>*/\n\nvar destroyImpl = require('./internal/streams/destroy');\n\nutil.inherits(Writable, Stream);\n\nfunction nop() {}\n\nfunction WritableState(options, stream) {\n  Duplex = Duplex || require('./_stream_duplex');\n\n  options = options || {};\n\n  // Duplex streams are both readable and writable, but share\n  // the same options object.\n  // However, some cases require setting options to different\n  // values for the readable and the writable sides of the duplex stream.\n  // These options can be provided separately as readableXXX and writableXXX.\n  var isDuplex = stream instanceof Duplex;\n\n  // object stream flag to indicate whether or not this stream\n  // contains buffers or objects.\n  this.objectMode = !!options.objectMode;\n\n  if (isDuplex) this.objectMode = this.objectMode || !!options.writableObjectMode;\n\n  // the point at which write() starts returning false\n  // Note: 0 is a valid value, means that we always return false if\n  // the entire buffer is not flushed immediately on write()\n  var hwm = options.highWaterMark;\n  var writableHwm = options.writableHighWaterMark;\n  var defaultHwm = this.objectMode ? 16 : 16 * 1024;\n\n  if (hwm || hwm === 0) this.highWaterMark = hwm;else if (isDuplex && (writableHwm || writableHwm === 0)) this.highWaterMark = writableHwm;else this.highWaterMark = defaultHwm;\n\n  // cast to ints.\n  this.highWaterMark = Math.floor(this.highWaterMark);\n\n  // if _final has been called\n  this.finalCalled = false;\n\n  // drain event flag.\n  this.needDrain = false;\n  // at the start of calling end()\n  this.ending = false;\n  // when end() has been called, and returned\n  this.ended = false;\n  // when 'finish' is emitted\n  this.finished = false;\n\n  // has it been destroyed\n  this.destroyed = false;\n\n  // should we decode strings into buffers before passing to _write?\n  // this is here so that some node-core streams can optimize string\n  // handling at a lower level.\n  var noDecode = options.decodeStrings === false;\n  this.decodeStrings = !noDecode;\n\n  // Crypto is kind of old and crusty.  Historically, its default string\n  // encoding is 'binary' so we have to make this configurable.\n  // Everything else in the universe uses 'utf8', though.\n  this.defaultEncoding = options.defaultEncoding || 'utf8';\n\n  // not an actual buffer we keep track of, but a measurement\n  // of how much we're waiting to get pushed to some underlying\n  // socket or file.\n  this.length = 0;\n\n  // a flag to see when we're in the middle of a write.\n  this.writing = false;\n\n  // when true all writes will be buffered until .uncork() call\n  this.corked = 0;\n\n  // a flag to be able to tell if the onwrite cb is called immediately,\n  // or on a later tick.  We set this to true at first, because any\n  // actions that shouldn't happen until \"later\" should generally also\n  // not happen before the first write call.\n  this.sync = true;\n\n  // a flag to know if we're processing previously buffered items, which\n  // may call the _write() callback in the same tick, so that we don't\n  // end up in an overlapped onwrite situation.\n  this.bufferProcessing = false;\n\n  // the callback that's passed to _write(chunk,cb)\n  this.onwrite = function (er) {\n    onwrite(stream, er);\n  };\n\n  // the callback that the user supplies to write(chunk,encoding,cb)\n  this.writecb = null;\n\n  // the amount that is being written when _write is called.\n  this.writelen = 0;\n\n  this.bufferedRequest = null;\n  this.lastBufferedRequest = null;\n\n  // number of pending user-supplied write callbacks\n  // this must be 0 before 'finish' can be emitted\n  this.pendingcb = 0;\n\n  // emit prefinish if the only thing we're waiting for is _write cbs\n  // This is relevant for synchronous Transform streams\n  this.prefinished = false;\n\n  // True if the error was already emitted and should not be thrown again\n  this.errorEmitted = false;\n\n  // count buffered requests\n  this.bufferedRequestCount = 0;\n\n  // allocate the first CorkedRequest, there is always\n  // one allocated and free to use, and we maintain at most two\n  this.corkedRequestsFree = new CorkedRequest(this);\n}\n\nWritableState.prototype.getBuffer = function getBuffer() {\n  var current = this.bufferedRequest;\n  var out = [];\n  while (current) {\n    out.push(current);\n    current = current.next;\n  }\n  return out;\n};\n\n(function () {\n  try {\n    Object.defineProperty(WritableState.prototype, 'buffer', {\n      get: internalUtil.deprecate(function () {\n        return this.getBuffer();\n      }, '_writableState.buffer is deprecated. Use _writableState.getBuffer ' + 'instead.', 'DEP0003')\n    });\n  } catch (_) {}\n})();\n\n// Test _writableState for inheritance to account for Duplex streams,\n// whose prototype chain only points to Readable.\nvar realHasInstance;\nif (typeof Symbol === 'function' && Symbol.hasInstance && typeof Function.prototype[Symbol.hasInstance] === 'function') {\n  realHasInstance = Function.prototype[Symbol.hasInstance];\n  Object.defineProperty(Writable, Symbol.hasInstance, {\n    value: function (object) {\n      if (realHasInstance.call(this, object)) return true;\n      if (this !== Writable) return false;\n\n      return object && object._writableState instanceof WritableState;\n    }\n  });\n} else {\n  realHasInstance = function (object) {\n    return object instanceof this;\n  };\n}\n\nfunction Writable(options) {\n  Duplex = Duplex || require('./_stream_duplex');\n\n  // Writable ctor is applied to Duplexes, too.\n  // `realHasInstance` is necessary because using plain `instanceof`\n  // would return false, as no `_writableState` property is attached.\n\n  // Trying to use the custom `instanceof` for Writable here will also break the\n  // Node.js LazyTransform implementation, which has a non-trivial getter for\n  // `_writableState` that would lead to infinite recursion.\n  if (!realHasInstance.call(Writable, this) && !(this instanceof Duplex)) {\n    return new Writable(options);\n  }\n\n  this._writableState = new WritableState(options, this);\n\n  // legacy.\n  this.writable = true;\n\n  if (options) {\n    if (typeof options.write === 'function') this._write = options.write;\n\n    if (typeof options.writev === 'function') this._writev = options.writev;\n\n    if (typeof options.destroy === 'function') this._destroy = options.destroy;\n\n    if (typeof options.final === 'function') this._final = options.final;\n  }\n\n  Stream.call(this);\n}\n\n// Otherwise people can pipe Writable streams, which is just wrong.\nWritable.prototype.pipe = function () {\n  this.emit('error', new Error('Cannot pipe, not readable'));\n};\n\nfunction writeAfterEnd(stream, cb) {\n  var er = new Error('write after end');\n  // TODO: defer error events consistently everywhere, not just the cb\n  stream.emit('error', er);\n  pna.nextTick(cb, er);\n}\n\n// Checks that a user-supplied chunk is valid, especially for the particular\n// mode the stream is in. Currently this means that `null` is never accepted\n// and undefined/non-string values are only allowed in object mode.\nfunction validChunk(stream, state, chunk, cb) {\n  var valid = true;\n  var er = false;\n\n  if (chunk === null) {\n    er = new TypeError('May not write null values to stream');\n  } else if (typeof chunk !== 'string' && chunk !== undefined && !state.objectMode) {\n    er = new TypeError('Invalid non-string/buffer chunk');\n  }\n  if (er) {\n    stream.emit('error', er);\n    pna.nextTick(cb, er);\n    valid = false;\n  }\n  return valid;\n}\n\nWritable.prototype.write = function (chunk, encoding, cb) {\n  var state = this._writableState;\n  var ret = false;\n  var isBuf = !state.objectMode && _isUint8Array(chunk);\n\n  if (isBuf && !Buffer.isBuffer(chunk)) {\n    chunk = _uint8ArrayToBuffer(chunk);\n  }\n\n  if (typeof encoding === 'function') {\n    cb = encoding;\n    encoding = null;\n  }\n\n  if (isBuf) encoding = 'buffer';else if (!encoding) encoding = state.defaultEncoding;\n\n  if (typeof cb !== 'function') cb = nop;\n\n  if (state.ended) writeAfterEnd(this, cb);else if (isBuf || validChunk(this, state, chunk, cb)) {\n    state.pendingcb++;\n    ret = writeOrBuffer(this, state, isBuf, chunk, encoding, cb);\n  }\n\n  return ret;\n};\n\nWritable.prototype.cork = function () {\n  var state = this._writableState;\n\n  state.corked++;\n};\n\nWritable.prototype.uncork = function () {\n  var state = this._writableState;\n\n  if (state.corked) {\n    state.corked--;\n\n    if (!state.writing && !state.corked && !state.finished && !state.bufferProcessing && state.bufferedRequest) clearBuffer(this, state);\n  }\n};\n\nWritable.prototype.setDefaultEncoding = function setDefaultEncoding(encoding) {\n  // node::ParseEncoding() requires lower case.\n  if (typeof encoding === 'string') encoding = encoding.toLowerCase();\n  if (!(['hex', 'utf8', 'utf-8', 'ascii', 'binary', 'base64', 'ucs2', 'ucs-2', 'utf16le', 'utf-16le', 'raw'].indexOf((encoding + '').toLowerCase()) > -1)) throw new TypeError('Unknown encoding: ' + encoding);\n  this._writableState.defaultEncoding = encoding;\n  return this;\n};\n\nfunction decodeChunk(state, chunk, encoding) {\n  if (!state.objectMode && state.decodeStrings !== false && typeof chunk === 'string') {\n    chunk = Buffer.from(chunk, encoding);\n  }\n  return chunk;\n}\n\nObject.defineProperty(Writable.prototype, 'writableHighWaterMark', {\n  // making it explicit this property is not enumerable\n  // because otherwise some prototype manipulation in\n  // userland will fail\n  enumerable: false,\n  get: function () {\n    return this._writableState.highWaterMark;\n  }\n});\n\n// if we're already writing something, then just put this\n// in the queue, and wait our turn.  Otherwise, call _write\n// If we return false, then we need a drain event, so set that flag.\nfunction writeOrBuffer(stream, state, isBuf, chunk, encoding, cb) {\n  if (!isBuf) {\n    var newChunk = decodeChunk(state, chunk, encoding);\n    if (chunk !== newChunk) {\n      isBuf = true;\n      encoding = 'buffer';\n      chunk = newChunk;\n    }\n  }\n  var len = state.objectMode ? 1 : chunk.length;\n\n  state.length += len;\n\n  var ret = state.length < state.highWaterMark;\n  // we must ensure that previous needDrain will not be reset to false.\n  if (!ret) state.needDrain = true;\n\n  if (state.writing || state.corked) {\n    var last = state.lastBufferedRequest;\n    state.lastBufferedRequest = {\n      chunk: chunk,\n      encoding: encoding,\n      isBuf: isBuf,\n      callback: cb,\n      next: null\n    };\n    if (last) {\n      last.next = state.lastBufferedRequest;\n    } else {\n      state.bufferedRequest = state.lastBufferedRequest;\n    }\n    state.bufferedRequestCount += 1;\n  } else {\n    doWrite(stream, state, false, len, chunk, encoding, cb);\n  }\n\n  return ret;\n}\n\nfunction doWrite(stream, state, writev, len, chunk, encoding, cb) {\n  state.writelen = len;\n  state.writecb = cb;\n  state.writing = true;\n  state.sync = true;\n  if (writev) stream._writev(chunk, state.onwrite);else stream._write(chunk, encoding, state.onwrite);\n  state.sync = false;\n}\n\nfunction onwriteError(stream, state, sync, er, cb) {\n  --state.pendingcb;\n\n  if (sync) {\n    // defer the callback if we are being called synchronously\n    // to avoid piling up things on the stack\n    pna.nextTick(cb, er);\n    // this can emit finish, and it will always happen\n    // after error\n    pna.nextTick(finishMaybe, stream, state);\n    stream._writableState.errorEmitted = true;\n    stream.emit('error', er);\n  } else {\n    // the caller expect this to happen before if\n    // it is async\n    cb(er);\n    stream._writableState.errorEmitted = true;\n    stream.emit('error', er);\n    // this can emit finish, but finish must\n    // always follow error\n    finishMaybe(stream, state);\n  }\n}\n\nfunction onwriteStateUpdate(state) {\n  state.writing = false;\n  state.writecb = null;\n  state.length -= state.writelen;\n  state.writelen = 0;\n}\n\nfunction onwrite(stream, er) {\n  var state = stream._writableState;\n  var sync = state.sync;\n  var cb = state.writecb;\n\n  onwriteStateUpdate(state);\n\n  if (er) onwriteError(stream, state, sync, er, cb);else {\n    // Check if we're actually ready to finish, but don't emit yet\n    var finished = needFinish(state);\n\n    if (!finished && !state.corked && !state.bufferProcessing && state.bufferedRequest) {\n      clearBuffer(stream, state);\n    }\n\n    if (sync) {\n      /*<replacement>*/\n      asyncWrite(afterWrite, stream, state, finished, cb);\n      /*</replacement>*/\n    } else {\n      afterWrite(stream, state, finished, cb);\n    }\n  }\n}\n\nfunction afterWrite(stream, state, finished, cb) {\n  if (!finished) onwriteDrain(stream, state);\n  state.pendingcb--;\n  cb();\n  finishMaybe(stream, state);\n}\n\n// Must force callback to be called on nextTick, so that we don't\n// emit 'drain' before the write() consumer gets the 'false' return\n// value, and has a chance to attach a 'drain' listener.\nfunction onwriteDrain(stream, state) {\n  if (state.length === 0 && state.needDrain) {\n    state.needDrain = false;\n    stream.emit('drain');\n  }\n}\n\n// if there's something in the buffer waiting, then process it\nfunction clearBuffer(stream, state) {\n  state.bufferProcessing = true;\n  var entry = state.bufferedRequest;\n\n  if (stream._writev && entry && entry.next) {\n    // Fast case, write everything using _writev()\n    var l = state.bufferedRequestCount;\n    var buffer = new Array(l);\n    var holder = state.corkedRequestsFree;\n    holder.entry = entry;\n\n    var count = 0;\n    var allBuffers = true;\n    while (entry) {\n      buffer[count] = entry;\n      if (!entry.isBuf) allBuffers = false;\n      entry = entry.next;\n      count += 1;\n    }\n    buffer.allBuffers = allBuffers;\n\n    doWrite(stream, state, true, state.length, buffer, '', holder.finish);\n\n    // doWrite is almost always async, defer these to save a bit of time\n    // as the hot path ends with doWrite\n    state.pendingcb++;\n    state.lastBufferedRequest = null;\n    if (holder.next) {\n      state.corkedRequestsFree = holder.next;\n      holder.next = null;\n    } else {\n      state.corkedRequestsFree = new CorkedRequest(state);\n    }\n    state.bufferedRequestCount = 0;\n  } else {\n    // Slow case, write chunks one-by-one\n    while (entry) {\n      var chunk = entry.chunk;\n      var encoding = entry.encoding;\n      var cb = entry.callback;\n      var len = state.objectMode ? 1 : chunk.length;\n\n      doWrite(stream, state, false, len, chunk, encoding, cb);\n      entry = entry.next;\n      state.bufferedRequestCount--;\n      // if we didn't call the onwrite immediately, then\n      // it means that we need to wait until it does.\n      // also, that means that the chunk and cb are currently\n      // being processed, so move the buffer counter past them.\n      if (state.writing) {\n        break;\n      }\n    }\n\n    if (entry === null) state.lastBufferedRequest = null;\n  }\n\n  state.bufferedRequest = entry;\n  state.bufferProcessing = false;\n}\n\nWritable.prototype._write = function (chunk, encoding, cb) {\n  cb(new Error('_write() is not implemented'));\n};\n\nWritable.prototype._writev = null;\n\nWritable.prototype.end = function (chunk, encoding, cb) {\n  var state = this._writableState;\n\n  if (typeof chunk === 'function') {\n    cb = chunk;\n    chunk = null;\n    encoding = null;\n  } else if (typeof encoding === 'function') {\n    cb = encoding;\n    encoding = null;\n  }\n\n  if (chunk !== null && chunk !== undefined) this.write(chunk, encoding);\n\n  // .end() fully uncorks\n  if (state.corked) {\n    state.corked = 1;\n    this.uncork();\n  }\n\n  // ignore unnecessary end() calls.\n  if (!state.ending && !state.finished) endWritable(this, state, cb);\n};\n\nfunction needFinish(state) {\n  return state.ending && state.length === 0 && state.bufferedRequest === null && !state.finished && !state.writing;\n}\nfunction callFinal(stream, state) {\n  stream._final(function (err) {\n    state.pendingcb--;\n    if (err) {\n      stream.emit('error', err);\n    }\n    state.prefinished = true;\n    stream.emit('prefinish');\n    finishMaybe(stream, state);\n  });\n}\nfunction prefinish(stream, state) {\n  if (!state.prefinished && !state.finalCalled) {\n    if (typeof stream._final === 'function') {\n      state.pendingcb++;\n      state.finalCalled = true;\n      pna.nextTick(callFinal, stream, state);\n    } else {\n      state.prefinished = true;\n      stream.emit('prefinish');\n    }\n  }\n}\n\nfunction finishMaybe(stream, state) {\n  var need = needFinish(state);\n  if (need) {\n    prefinish(stream, state);\n    if (state.pendingcb === 0) {\n      state.finished = true;\n      stream.emit('finish');\n    }\n  }\n  return need;\n}\n\nfunction endWritable(stream, state, cb) {\n  state.ending = true;\n  finishMaybe(stream, state);\n  if (cb) {\n    if (state.finished) pna.nextTick(cb);else stream.once('finish', cb);\n  }\n  state.ended = true;\n  stream.writable = false;\n}\n\nfunction onCorkedFinish(corkReq, state, err) {\n  var entry = corkReq.entry;\n  corkReq.entry = null;\n  while (entry) {\n    var cb = entry.callback;\n    state.pendingcb--;\n    cb(err);\n    entry = entry.next;\n  }\n  if (state.corkedRequestsFree) {\n    state.corkedRequestsFree.next = corkReq;\n  } else {\n    state.corkedRequestsFree = corkReq;\n  }\n}\n\nObject.defineProperty(Writable.prototype, 'destroyed', {\n  get: function () {\n    if (this._writableState === undefined) {\n      return false;\n    }\n    return this._writableState.destroyed;\n  },\n  set: function (value) {\n    // we ignore the value if the stream\n    // has not been initialized yet\n    if (!this._writableState) {\n      return;\n    }\n\n    // backward compatibility, the user is explicitly\n    // managing destroyed\n    this._writableState.destroyed = value;\n  }\n});\n\nWritable.prototype.destroy = destroyImpl.destroy;\nWritable.prototype._undestroy = destroyImpl.undestroy;\nWritable.prototype._destroy = function (err, cb) {\n  this.end();\n  cb(err);\n};",
	"transpiled": true
}; item.content= context.Buffer.from(item.content,'binary'); } return item; })
	fileData.push(function(){return {
	"stat": {
		"mtime": "2019-05-18T07:17:58.666Z",
		"mtimeMs": 1558163878666.4521,
		"atime": "2019-05-18T07:17:58.666Z",
		"atimeMs": 1558163878666.4521,
		"isdirectory": true
	},
	"filename": "node_modules/readable-stream/lib/internal"
}})
	fileData.push(function(){return {
	"stat": {
		"mtime": "2019-05-18T07:17:58.666Z",
		"mtimeMs": 1558163878666.4521,
		"atime": "2019-05-18T07:17:58.666Z",
		"atimeMs": 1558163878666.4521,
		"isdirectory": true
	},
	"filename": "node_modules/readable-stream/lib/internal/streams"
}})
	fileData.push(function(){ var item= cacheData[75]; if(!item){ item= cacheData[75]= {
	"stat": {
		"mtime": "1985-10-26T08:15:00.000Z",
		"mtimeMs": 499162500000,
		"atime": "2019-05-18T07:17:58.671Z",
		"atimeMs": 1558163878671,
		"isfile": true
	},
	"filename": "node_modules/readable-stream/lib/internal/streams/BufferList.js",
	"content": "'use strict';\n\nfunction _classCallCheck(instance, Constructor) { if (!(instance instanceof Constructor)) { throw new TypeError(\"Cannot call a class as a function\"); } }\n\nvar Buffer = require('safe-buffer').Buffer;\nvar util = require('util');\n\nfunction copyBuffer(src, target, offset) {\n  src.copy(target, offset);\n}\n\nmodule.exports = function () {\n  function BufferList() {\n    _classCallCheck(this, BufferList);\n\n    this.head = null;\n    this.tail = null;\n    this.length = 0;\n  }\n\n  BufferList.prototype.push = function push(v) {\n    var entry = { data: v, next: null };\n    if (this.length > 0) this.tail.next = entry;else this.head = entry;\n    this.tail = entry;\n    ++this.length;\n  };\n\n  BufferList.prototype.unshift = function unshift(v) {\n    var entry = { data: v, next: this.head };\n    if (this.length === 0) this.tail = entry;\n    this.head = entry;\n    ++this.length;\n  };\n\n  BufferList.prototype.shift = function shift() {\n    if (this.length === 0) return;\n    var ret = this.head.data;\n    if (this.length === 1) this.head = this.tail = null;else this.head = this.head.next;\n    --this.length;\n    return ret;\n  };\n\n  BufferList.prototype.clear = function clear() {\n    this.head = this.tail = null;\n    this.length = 0;\n  };\n\n  BufferList.prototype.join = function join(s) {\n    if (this.length === 0) return '';\n    var p = this.head;\n    var ret = '' + p.data;\n    while (p = p.next) {\n      ret += s + p.data;\n    }return ret;\n  };\n\n  BufferList.prototype.concat = function concat(n) {\n    if (this.length === 0) return Buffer.alloc(0);\n    if (this.length === 1) return this.head.data;\n    var ret = Buffer.allocUnsafe(n >>> 0);\n    var p = this.head;\n    var i = 0;\n    while (p) {\n      copyBuffer(p.data, ret, i);\n      i += p.data.length;\n      p = p.next;\n    }\n    return ret;\n  };\n\n  return BufferList;\n}();\n\nif (util && util.inspect && util.inspect.custom) {\n  module.exports.prototype[util.inspect.custom] = function () {\n    var obj = util.inspect({ length: this.length });\n    return this.constructor.name + ' ' + obj;\n  };\n}",
	"transpiled": true
}; item.content= context.Buffer.from(item.content,'binary'); } return item; })
	fileData.push(function(){ var item= cacheData[76]; if(!item){ item= cacheData[76]= {
	"stat": {
		"mtime": "1985-10-26T08:15:00.000Z",
		"mtimeMs": 499162500000,
		"atime": "2019-05-18T07:17:58.671Z",
		"atimeMs": 1558163878671,
		"isfile": true
	},
	"filename": "node_modules/readable-stream/lib/internal/streams/destroy.js",
	"content": "'use strict';\n\n/*<replacement>*/\n\nvar pna = require('process-nextick-args');\n/*</replacement>*/\n\n// undocumented cb() API, needed for core, not for public API\nfunction destroy(err, cb) {\n  var _this = this;\n\n  var readableDestroyed = this._readableState && this._readableState.destroyed;\n  var writableDestroyed = this._writableState && this._writableState.destroyed;\n\n  if (readableDestroyed || writableDestroyed) {\n    if (cb) {\n      cb(err);\n    } else if (err && (!this._writableState || !this._writableState.errorEmitted)) {\n      pna.nextTick(emitErrorNT, this, err);\n    }\n    return this;\n  }\n\n  // we set destroyed to true before firing error callbacks in order\n  // to make it re-entrance safe in case destroy() is called within callbacks\n\n  if (this._readableState) {\n    this._readableState.destroyed = true;\n  }\n\n  // if this is a duplex stream mark the writable part as destroyed as well\n  if (this._writableState) {\n    this._writableState.destroyed = true;\n  }\n\n  this._destroy(err || null, function (err) {\n    if (!cb && err) {\n      pna.nextTick(emitErrorNT, _this, err);\n      if (_this._writableState) {\n        _this._writableState.errorEmitted = true;\n      }\n    } else if (cb) {\n      cb(err);\n    }\n  });\n\n  return this;\n}\n\nfunction undestroy() {\n  if (this._readableState) {\n    this._readableState.destroyed = false;\n    this._readableState.reading = false;\n    this._readableState.ended = false;\n    this._readableState.endEmitted = false;\n  }\n\n  if (this._writableState) {\n    this._writableState.destroyed = false;\n    this._writableState.ended = false;\n    this._writableState.ending = false;\n    this._writableState.finished = false;\n    this._writableState.errorEmitted = false;\n  }\n}\n\nfunction emitErrorNT(self, err) {\n  self.emit('error', err);\n}\n\nmodule.exports = {\n  destroy: destroy,\n  undestroy: undestroy\n};",
	"transpiled": true
}; item.content= context.Buffer.from(item.content,'binary'); } return item; })
	fileData.push(function(){ var item= cacheData[77]; if(!item){ item= cacheData[77]= {
	"stat": {
		"mtime": "1985-10-26T08:15:00.000Z",
		"mtimeMs": 499162500000,
		"atime": "2019-05-18T07:17:58.671Z",
		"atimeMs": 1558163878671,
		"isfile": true
	},
	"filename": "node_modules/readable-stream/lib/internal/streams/stream-browser.js",
	"content": "module.exports = require('events').EventEmitter;\n",
	"transpiled": true
}; item.content= context.Buffer.from(item.content,'binary'); } return item; })
	fileData.push(function(){ var item= cacheData[78]; if(!item){ item= cacheData[78]= {
	"stat": {
		"mtime": "1985-10-26T08:15:00.000Z",
		"mtimeMs": 499162500000,
		"atime": "2019-05-18T07:17:58.671Z",
		"atimeMs": 1558163878671,
		"isfile": true
	},
	"filename": "node_modules/readable-stream/lib/internal/streams/stream.js",
	"content": "module.exports = require('stream');\n",
	"transpiled": true
}; item.content= context.Buffer.from(item.content,'binary'); } return item; })
	fileData.push(function(){ var item= cacheData[79]; if(!item){ item= cacheData[79]= {
	"stat": {
		"mtime": "1985-10-26T08:15:00.000Z",
		"mtimeMs": 499162500000,
		"atime": "2019-05-18T07:17:58.666Z",
		"atimeMs": 1558163878666.4521,
		"isfile": true
	},
	"filename": "node_modules/readable-stream/package.json",
	"content": "{\n  \"name\": \"readable-stream\",\n  \"version\": \"2.3.6\",\n  \"description\": \"Streams3, a user-land copy of the stream library from Node.js\",\n  \"main\": \"readable.js\",\n  \"dependencies\": {\n    \"core-util-is\": \"~1.0.0\",\n    \"inherits\": \"~2.0.3\",\n    \"isarray\": \"~1.0.0\",\n    \"process-nextick-args\": \"~2.0.0\",\n    \"safe-buffer\": \"~5.1.1\",\n    \"string_decoder\": \"~1.1.1\",\n    \"util-deprecate\": \"~1.0.1\"\n  },\n  \"devDependencies\": {\n    \"assert\": \"^1.4.0\",\n    \"babel-polyfill\": \"^6.9.1\",\n    \"buffer\": \"^4.9.0\",\n    \"lolex\": \"^2.3.2\",\n    \"nyc\": \"^6.4.0\",\n    \"tap\": \"^0.7.0\",\n    \"tape\": \"^4.8.0\"\n  },\n  \"scripts\": {\n    \"test\": \"tap test/parallel/*.js test/ours/*.js && node test/verify-dependencies.js\",\n    \"ci\": \"tap test/parallel/*.js test/ours/*.js --tap | tee test.tap && node test/verify-dependencies.js\",\n    \"cover\": \"nyc npm test\",\n    \"report\": \"nyc report --reporter=lcov\"\n  },\n  \"repository\": {\n    \"type\": \"git\",\n    \"url\": \"git://github.com/nodejs/readable-stream\"\n  },\n  \"keywords\": [\n    \"readable\",\n    \"stream\",\n    \"pipe\"\n  ],\n  \"browser\": {\n    \"util\": false,\n    \"./readable.js\": \"./readable-browser.js\",\n    \"./writable.js\": \"./writable-browser.js\",\n    \"./duplex.js\": \"./duplex-browser.js\",\n    \"./lib/internal/streams/stream.js\": \"./lib/internal/streams/stream-browser.js\"\n  },\n  \"nyc\": {\n    \"include\": [\n      \"lib/**.js\"\n    ]\n  },\n  \"license\": \"MIT\"\n}\n",
	"transpiled": true
}; item.content= context.Buffer.from(item.content,'binary'); } return item; })
	fileData.push(function(){ var item= cacheData[80]; if(!item){ item= cacheData[80]= {
	"stat": {
		"mtime": "1985-10-26T08:15:00.000Z",
		"mtimeMs": 499162500000,
		"atime": "2019-05-18T07:17:58.669Z",
		"atimeMs": 1558163878669,
		"isfile": true
	},
	"filename": "node_modules/readable-stream/passthrough.js",
	"content": "module.exports = require('./readable').PassThrough\n",
	"transpiled": true
}; item.content= context.Buffer.from(item.content,'binary'); } return item; })
	fileData.push(function(){ var item= cacheData[81]; if(!item){ item= cacheData[81]= {
	"stat": {
		"mtime": "1985-10-26T08:15:00.000Z",
		"mtimeMs": 499162500000,
		"atime": "2019-05-18T07:17:58.669Z",
		"atimeMs": 1558163878669,
		"isfile": true
	},
	"filename": "node_modules/readable-stream/readable-browser.js",
	"content": "exports = module.exports = require('./lib/_stream_readable.js');\nexports.Stream = exports;\nexports.Readable = exports;\nexports.Writable = require('./lib/_stream_writable.js');\nexports.Duplex = require('./lib/_stream_duplex.js');\nexports.Transform = require('./lib/_stream_transform.js');\nexports.PassThrough = require('./lib/_stream_passthrough.js');\n",
	"transpiled": true
}; item.content= context.Buffer.from(item.content,'binary'); } return item; })
	fileData.push(function(){ var item= cacheData[82]; if(!item){ item= cacheData[82]= {
	"stat": {
		"mtime": "1985-10-26T08:15:00.000Z",
		"mtimeMs": 499162500000,
		"atime": "2019-05-18T07:17:58.669Z",
		"atimeMs": 1558163878669,
		"isfile": true
	},
	"filename": "node_modules/readable-stream/readable.js",
	"content": "var Stream = require('stream');\nif (process.env.READABLE_STREAM === 'disable' && Stream) {\n  module.exports = Stream;\n  exports = module.exports = Stream.Readable;\n  exports.Readable = Stream.Readable;\n  exports.Writable = Stream.Writable;\n  exports.Duplex = Stream.Duplex;\n  exports.Transform = Stream.Transform;\n  exports.PassThrough = Stream.PassThrough;\n  exports.Stream = Stream;\n} else {\n  exports = module.exports = require('./lib/_stream_readable.js');\n  exports.Stream = Stream || exports;\n  exports.Readable = exports;\n  exports.Writable = require('./lib/_stream_writable.js');\n  exports.Duplex = require('./lib/_stream_duplex.js');\n  exports.Transform = require('./lib/_stream_transform.js');\n  exports.PassThrough = require('./lib/_stream_passthrough.js');\n}\n",
	"transpiled": true
}; item.content= context.Buffer.from(item.content,'binary'); } return item; })
	fileData.push(function(){ var item= cacheData[83]; if(!item){ item= cacheData[83]= {
	"stat": {
		"mtime": "1985-10-26T08:15:00.000Z",
		"mtimeMs": 499162500000,
		"atime": "2019-05-18T07:17:58.669Z",
		"atimeMs": 1558163878669,
		"isfile": true
	},
	"filename": "node_modules/readable-stream/transform.js",
	"content": "module.exports = require('./readable').Transform\n",
	"transpiled": true
}; item.content= context.Buffer.from(item.content,'binary'); } return item; })
	fileData.push(function(){ var item= cacheData[84]; if(!item){ item= cacheData[84]= {
	"stat": {
		"mtime": "1985-10-26T08:15:00.000Z",
		"mtimeMs": 499162500000,
		"atime": "2019-05-18T07:17:58.669Z",
		"atimeMs": 1558163878669,
		"isfile": true
	},
	"filename": "node_modules/readable-stream/writable-browser.js",
	"content": "module.exports = require('./lib/_stream_writable.js');\n",
	"transpiled": true
}; item.content= context.Buffer.from(item.content,'binary'); } return item; })
	fileData.push(function(){ var item= cacheData[85]; if(!item){ item= cacheData[85]= {
	"stat": {
		"mtime": "1985-10-26T08:15:00.000Z",
		"mtimeMs": 499162500000,
		"atime": "2019-05-18T07:17:58.669Z",
		"atimeMs": 1558163878669,
		"isfile": true
	},
	"filename": "node_modules/readable-stream/writable.js",
	"content": "var Stream = require(\"stream\")\nvar Writable = require(\"./lib/_stream_writable.js\")\n\nif (process.env.READABLE_STREAM === 'disable') {\n  module.exports = Stream && Stream.Writable || Writable\n} else {\n  module.exports = Writable\n}\n",
	"transpiled": true
}; item.content= context.Buffer.from(item.content,'binary'); } return item; })
	fileData.push(function(){return {
	"stat": {
		"mtime": "2019-05-18T07:17:58.790Z",
		"mtimeMs": 1558163878790.4543,
		"atime": "2019-05-18T07:17:58.790Z",
		"atimeMs": 1558163878790.4543,
		"isdirectory": true
	},
	"filename": "node_modules/safe-buffer"
}})
	fileData.push(function(){ var item= cacheData[87]; if(!item){ item= cacheData[87]= {
	"stat": {
		"mtime": "1985-10-26T08:15:00.000Z",
		"mtimeMs": 499162500000,
		"atime": "2019-05-18T07:17:58.793Z",
		"atimeMs": 1558163878793,
		"isfile": true
	},
	"filename": "node_modules/safe-buffer/index.d.ts",
	"content": "declare module \"safe-buffer\" {\n  export class Buffer {\n    length: number\n    write(string: string, offset?: number, length?: number, encoding?: string): number;\n    toString(encoding?: string, start?: number, end?: number): string;\n    toJSON(): { type: 'Buffer', data: any[] };\n    equals(otherBuffer: Buffer): boolean;\n    compare(otherBuffer: Buffer, targetStart?: number, targetEnd?: number, sourceStart?: number, sourceEnd?: number): number;\n    copy(targetBuffer: Buffer, targetStart?: number, sourceStart?: number, sourceEnd?: number): number;\n    slice(start?: number, end?: number): Buffer;\n    writeUIntLE(value: number, offset: number, byteLength: number, noAssert?: boolean): number;\n    writeUIntBE(value: number, offset: number, byteLength: number, noAssert?: boolean): number;\n    writeIntLE(value: number, offset: number, byteLength: number, noAssert?: boolean): number;\n    writeIntBE(value: number, offset: number, byteLength: number, noAssert?: boolean): number;\n    readUIntLE(offset: number, byteLength: number, noAssert?: boolean): number;\n    readUIntBE(offset: number, byteLength: number, noAssert?: boolean): number;\n    readIntLE(offset: number, byteLength: number, noAssert?: boolean): number;\n    readIntBE(offset: number, byteLength: number, noAssert?: boolean): number;\n    readUInt8(offset: number, noAssert?: boolean): number;\n    readUInt16LE(offset: number, noAssert?: boolean): number;\n    readUInt16BE(offset: number, noAssert?: boolean): number;\n    readUInt32LE(offset: number, noAssert?: boolean): number;\n    readUInt32BE(offset: number, noAssert?: boolean): number;\n    readInt8(offset: number, noAssert?: boolean): number;\n    readInt16LE(offset: number, noAssert?: boolean): number;\n    readInt16BE(offset: number, noAssert?: boolean): number;\n    readInt32LE(offset: number, noAssert?: boolean): number;\n    readInt32BE(offset: number, noAssert?: boolean): number;\n    readFloatLE(offset: number, noAssert?: boolean): number;\n    readFloatBE(offset: number, noAssert?: boolean): number;\n    readDoubleLE(offset: number, noAssert?: boolean): number;\n    readDoubleBE(offset: number, noAssert?: boolean): number;\n    swap16(): Buffer;\n    swap32(): Buffer;\n    swap64(): Buffer;\n    writeUInt8(value: number, offset: number, noAssert?: boolean): number;\n    writeUInt16LE(value: number, offset: number, noAssert?: boolean): number;\n    writeUInt16BE(value: number, offset: number, noAssert?: boolean): number;\n    writeUInt32LE(value: number, offset: number, noAssert?: boolean): number;\n    writeUInt32BE(value: number, offset: number, noAssert?: boolean): number;\n    writeInt8(value: number, offset: number, noAssert?: boolean): number;\n    writeInt16LE(value: number, offset: number, noAssert?: boolean): number;\n    writeInt16BE(value: number, offset: number, noAssert?: boolean): number;\n    writeInt32LE(value: number, offset: number, noAssert?: boolean): number;\n    writeInt32BE(value: number, offset: number, noAssert?: boolean): number;\n    writeFloatLE(value: number, offset: number, noAssert?: boolean): number;\n    writeFloatBE(value: number, offset: number, noAssert?: boolean): number;\n    writeDoubleLE(value: number, offset: number, noAssert?: boolean): number;\n    writeDoubleBE(value: number, offset: number, noAssert?: boolean): number;\n    fill(value: any, offset?: number, end?: number): this;\n    indexOf(value: string | number | Buffer, byteOffset?: number, encoding?: string): number;\n    lastIndexOf(value: string | number | Buffer, byteOffset?: number, encoding?: string): number;\n    includes(value: string | number | Buffer, byteOffset?: number, encoding?: string): boolean;\n\n    /**\n     * Allocates a new buffer containing the given {str}.\n     *\n     * @param str String to store in buffer.\n     * @param encoding encoding to use, optional.  Default is 'utf8'\n     */\n     constructor (str: string, encoding?: string);\n    /**\n     * Allocates a new buffer of {size} octets.\n     *\n     * @param size count of octets to allocate.\n     */\n    constructor (size: number);\n    /**\n     * Allocates a new buffer containing the given {array} of octets.\n     *\n     * @param array The octets to store.\n     */\n    constructor (array: Uint8Array);\n    /**\n     * Produces a Buffer backed by the same allocated memory as\n     * the given {ArrayBuffer}.\n     *\n     *\n     * @param arrayBuffer The ArrayBuffer with which to share memory.\n     */\n    constructor (arrayBuffer: ArrayBuffer);\n    /**\n     * Allocates a new buffer containing the given {array} of octets.\n     *\n     * @param array The octets to store.\n     */\n    constructor (array: any[]);\n    /**\n     * Copies the passed {buffer} data onto a new {Buffer} instance.\n     *\n     * @param buffer The buffer to copy.\n     */\n    constructor (buffer: Buffer);\n    prototype: Buffer;\n    /**\n     * Allocates a new Buffer using an {array} of octets.\n     *\n     * @param array\n     */\n    static from(array: any[]): Buffer;\n    /**\n     * When passed a reference to the .buffer property of a TypedArray instance,\n     * the newly created Buffer will share the same allocated memory as the TypedArray.\n     * The optional {byteOffset} and {length} arguments specify a memory range\n     * within the {arrayBuffer} that will be shared by the Buffer.\n     *\n     * @param arrayBuffer The .buffer property of a TypedArray or a new ArrayBuffer()\n     * @param byteOffset\n     * @param length\n     */\n    static from(arrayBuffer: ArrayBuffer, byteOffset?: number, length?: number): Buffer;\n    /**\n     * Copies the passed {buffer} data onto a new Buffer instance.\n     *\n     * @param buffer\n     */\n    static from(buffer: Buffer): Buffer;\n    /**\n     * Creates a new Buffer containing the given JavaScript string {str}.\n     * If provided, the {encoding} parameter identifies the character encoding.\n     * If not provided, {encoding} defaults to 'utf8'.\n     *\n     * @param str\n     */\n    static from(str: string, encoding?: string): Buffer;\n    /**\n     * Returns true if {obj} is a Buffer\n     *\n     * @param obj object to test.\n     */\n    static isBuffer(obj: any): obj is Buffer;\n    /**\n     * Returns true if {encoding} is a valid encoding argument.\n     * Valid string encodings in Node 0.12: 'ascii'|'utf8'|'utf16le'|'ucs2'(alias of 'utf16le')|'base64'|'binary'(deprecated)|'hex'\n     *\n     * @param encoding string to test.\n     */\n    static isEncoding(encoding: string): boolean;\n    /**\n     * Gives the actual byte length of a string. encoding defaults to 'utf8'.\n     * This is not the same as String.prototype.length since that returns the number of characters in a string.\n     *\n     * @param string string to test.\n     * @param encoding encoding used to evaluate (defaults to 'utf8')\n     */\n    static byteLength(string: string, encoding?: string): number;\n    /**\n     * Returns a buffer which is the result of concatenating all the buffers in the list together.\n     *\n     * If the list has no items, or if the totalLength is 0, then it returns a zero-length buffer.\n     * If the list has exactly one item, then the first item of the list is returned.\n     * If the list has more than one item, then a new Buffer is created.\n     *\n     * @param list An array of Buffer objects to concatenate\n     * @param totalLength Total length of the buffers when concatenated.\n     *   If totalLength is not provided, it is read from the buffers in the list. However, this adds an additional loop to the function, so it is faster to provide the length explicitly.\n     */\n    static concat(list: Buffer[], totalLength?: number): Buffer;\n    /**\n     * The same as buf1.compare(buf2).\n     */\n    static compare(buf1: Buffer, buf2: Buffer): number;\n    /**\n     * Allocates a new buffer of {size} octets.\n     *\n     * @param size count of octets to allocate.\n     * @param fill if specified, buffer will be initialized by calling buf.fill(fill).\n     *    If parameter is omitted, buffer will be filled with zeros.\n     * @param encoding encoding used for call to buf.fill while initalizing\n     */\n    static alloc(size: number, fill?: string | Buffer | number, encoding?: string): Buffer;\n    /**\n     * Allocates a new buffer of {size} octets, leaving memory not initialized, so the contents\n     * of the newly created Buffer are unknown and may contain sensitive data.\n     *\n     * @param size count of octets to allocate\n     */\n    static allocUnsafe(size: number): Buffer;\n    /**\n     * Allocates a new non-pooled buffer of {size} octets, leaving memory not initialized, so the contents\n     * of the newly created Buffer are unknown and may contain sensitive data.\n     *\n     * @param size count of octets to allocate\n     */\n    static allocUnsafeSlow(size: number): Buffer;\n  }\n}",
	"transpiled": true
}; item.content= context.Buffer.from(item.content,'binary'); } return item; })
	fileData.push(function(){ var item= cacheData[88]; if(!item){ item= cacheData[88]= {
	"stat": {
		"mtime": "1985-10-26T08:15:00.000Z",
		"mtimeMs": 499162500000,
		"atime": "2019-05-18T07:17:58.793Z",
		"atimeMs": 1558163878793,
		"isfile": true
	},
	"filename": "node_modules/safe-buffer/index.js",
	"content": "/* eslint-disable node/no-deprecated-api */\nvar buffer = require('buffer')\nvar Buffer = buffer.Buffer\n\n// alternative to using Object.keys for old browsers\nfunction copyProps (src, dst) {\n  for (var key in src) {\n    dst[key] = src[key]\n  }\n}\nif (Buffer.from && Buffer.alloc && Buffer.allocUnsafe && Buffer.allocUnsafeSlow) {\n  module.exports = buffer\n} else {\n  // Copy properties from require('buffer')\n  copyProps(buffer, exports)\n  exports.Buffer = SafeBuffer\n}\n\nfunction SafeBuffer (arg, encodingOrOffset, length) {\n  return Buffer(arg, encodingOrOffset, length)\n}\n\n// Copy static methods from Buffer\ncopyProps(Buffer, SafeBuffer)\n\nSafeBuffer.from = function (arg, encodingOrOffset, length) {\n  if (typeof arg === 'number') {\n    throw new TypeError('Argument must not be a number')\n  }\n  return Buffer(arg, encodingOrOffset, length)\n}\n\nSafeBuffer.alloc = function (size, fill, encoding) {\n  if (typeof size !== 'number') {\n    throw new TypeError('Argument must be a number')\n  }\n  var buf = Buffer(size)\n  if (fill !== undefined) {\n    if (typeof encoding === 'string') {\n      buf.fill(fill, encoding)\n    } else {\n      buf.fill(fill)\n    }\n  } else {\n    buf.fill(0)\n  }\n  return buf\n}\n\nSafeBuffer.allocUnsafe = function (size) {\n  if (typeof size !== 'number') {\n    throw new TypeError('Argument must be a number')\n  }\n  return Buffer(size)\n}\n\nSafeBuffer.allocUnsafeSlow = function (size) {\n  if (typeof size !== 'number') {\n    throw new TypeError('Argument must be a number')\n  }\n  return buffer.SlowBuffer(size)\n}\n",
	"transpiled": true
}; item.content= context.Buffer.from(item.content,'binary'); } return item; })
	fileData.push(function(){ var item= cacheData[89]; if(!item){ item= cacheData[89]= {
	"stat": {
		"mtime": "1985-10-26T08:15:00.000Z",
		"mtimeMs": 499162500000,
		"atime": "2019-05-18T07:17:58.838Z",
		"atimeMs": 1558163878838.455,
		"isfile": true
	},
	"filename": "node_modules/safe-buffer/package.json",
	"content": "{\n  \"name\": \"safe-buffer\",\n  \"description\": \"Safer Node.js Buffer API\",\n  \"version\": \"5.1.2\",\n  \"author\": {\n    \"name\": \"Feross Aboukhadijeh\",\n    \"email\": \"feross@feross.org\",\n    \"url\": \"http://feross.org\"\n  },\n  \"bugs\": {\n    \"url\": \"https://github.com/feross/safe-buffer/issues\"\n  },\n  \"devDependencies\": {\n    \"standard\": \"*\",\n    \"tape\": \"^4.0.0\"\n  },\n  \"homepage\": \"https://github.com/feross/safe-buffer\",\n  \"keywords\": [\n    \"buffer\",\n    \"buffer allocate\",\n    \"node security\",\n    \"safe\",\n    \"safe-buffer\",\n    \"security\",\n    \"uninitialized\"\n  ],\n  \"license\": \"MIT\",\n  \"main\": \"index.js\",\n  \"types\": \"index.d.ts\",\n  \"repository\": {\n    \"type\": \"git\",\n    \"url\": \"git://github.com/feross/safe-buffer.git\"\n  },\n  \"scripts\": {\n    \"test\": \"standard && tape test/*.js\"\n  }\n}\n",
	"transpiled": true
}; item.content= context.Buffer.from(item.content,'binary'); } return item; })
	fileData.push(function(){return {
	"stat": {
		"mtime": "2019-05-18T07:17:58.814Z",
		"mtimeMs": 1558163878814.4548,
		"atime": "2019-05-18T07:17:58.814Z",
		"atimeMs": 1558163878814.4548,
		"isdirectory": true
	},
	"filename": "node_modules/string_decoder"
}})
	fileData.push(function(){return {
	"stat": {
		"mtime": "2019-05-18T07:17:58.814Z",
		"mtimeMs": 1558163878814.4548,
		"atime": "2019-05-18T07:17:58.814Z",
		"atimeMs": 1558163878814.4548,
		"isdirectory": true
	},
	"filename": "node_modules/string_decoder/lib"
}})
	fileData.push(function(){ var item= cacheData[92]; if(!item){ item= cacheData[92]= {
	"stat": {
		"mtime": "1985-10-26T08:15:00.000Z",
		"mtimeMs": 499162500000,
		"atime": "2019-05-18T07:17:58.820Z",
		"atimeMs": 1558163878820,
		"isfile": true
	},
	"filename": "node_modules/string_decoder/lib/string_decoder.js",
	"content": "// Copyright Joyent, Inc. and other Node contributors.\n//\n// Permission is hereby granted, free of charge, to any person obtaining a\n// copy of this software and associated documentation files (the\n// \"Software\"), to deal in the Software without restriction, including\n// without limitation the rights to use, copy, modify, merge, publish,\n// distribute, sublicense, and/or sell copies of the Software, and to permit\n// persons to whom the Software is furnished to do so, subject to the\n// following conditions:\n//\n// The above copyright notice and this permission notice shall be included\n// in all copies or substantial portions of the Software.\n//\n// THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS\n// OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF\n// MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN\n// NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM,\n// DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR\n// OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE\n// USE OR OTHER DEALINGS IN THE SOFTWARE.\n\n'use strict';\n\n/*<replacement>*/\n\nvar Buffer = require('safe-buffer').Buffer;\n/*</replacement>*/\n\nvar isEncoding = Buffer.isEncoding || function (encoding) {\n  encoding = '' + encoding;\n  switch (encoding && encoding.toLowerCase()) {\n    case 'hex':case 'utf8':case 'utf-8':case 'ascii':case 'binary':case 'base64':case 'ucs2':case 'ucs-2':case 'utf16le':case 'utf-16le':case 'raw':\n      return true;\n    default:\n      return false;\n  }\n};\n\nfunction _normalizeEncoding(enc) {\n  if (!enc) return 'utf8';\n  var retried;\n  while (true) {\n    switch (enc) {\n      case 'utf8':\n      case 'utf-8':\n        return 'utf8';\n      case 'ucs2':\n      case 'ucs-2':\n      case 'utf16le':\n      case 'utf-16le':\n        return 'utf16le';\n      case 'latin1':\n      case 'binary':\n        return 'latin1';\n      case 'base64':\n      case 'ascii':\n      case 'hex':\n        return enc;\n      default:\n        if (retried) return; // undefined\n        enc = ('' + enc).toLowerCase();\n        retried = true;\n    }\n  }\n};\n\n// Do not cache `Buffer.isEncoding` when checking encoding names as some\n// modules monkey-patch it to support additional encodings\nfunction normalizeEncoding(enc) {\n  var nenc = _normalizeEncoding(enc);\n  if (typeof nenc !== 'string' && (Buffer.isEncoding === isEncoding || !isEncoding(enc))) throw new Error('Unknown encoding: ' + enc);\n  return nenc || enc;\n}\n\n// StringDecoder provides an interface for efficiently splitting a series of\n// buffers into a series of JS strings without breaking apart multi-byte\n// characters.\nexports.StringDecoder = StringDecoder;\nfunction StringDecoder(encoding) {\n  this.encoding = normalizeEncoding(encoding);\n  var nb;\n  switch (this.encoding) {\n    case 'utf16le':\n      this.text = utf16Text;\n      this.end = utf16End;\n      nb = 4;\n      break;\n    case 'utf8':\n      this.fillLast = utf8FillLast;\n      nb = 4;\n      break;\n    case 'base64':\n      this.text = base64Text;\n      this.end = base64End;\n      nb = 3;\n      break;\n    default:\n      this.write = simpleWrite;\n      this.end = simpleEnd;\n      return;\n  }\n  this.lastNeed = 0;\n  this.lastTotal = 0;\n  this.lastChar = Buffer.allocUnsafe(nb);\n}\n\nStringDecoder.prototype.write = function (buf) {\n  if (buf.length === 0) return '';\n  var r;\n  var i;\n  if (this.lastNeed) {\n    r = this.fillLast(buf);\n    if (r === undefined) return '';\n    i = this.lastNeed;\n    this.lastNeed = 0;\n  } else {\n    i = 0;\n  }\n  if (i < buf.length) return r ? r + this.text(buf, i) : this.text(buf, i);\n  return r || '';\n};\n\nStringDecoder.prototype.end = utf8End;\n\n// Returns only complete characters in a Buffer\nStringDecoder.prototype.text = utf8Text;\n\n// Attempts to complete a partial non-UTF-8 character using bytes from a Buffer\nStringDecoder.prototype.fillLast = function (buf) {\n  if (this.lastNeed <= buf.length) {\n    buf.copy(this.lastChar, this.lastTotal - this.lastNeed, 0, this.lastNeed);\n    return this.lastChar.toString(this.encoding, 0, this.lastTotal);\n  }\n  buf.copy(this.lastChar, this.lastTotal - this.lastNeed, 0, buf.length);\n  this.lastNeed -= buf.length;\n};\n\n// Checks the type of a UTF-8 byte, whether it's ASCII, a leading byte, or a\n// continuation byte. If an invalid byte is detected, -2 is returned.\nfunction utf8CheckByte(byte) {\n  if (byte <= 0x7F) return 0;else if (byte >> 5 === 0x06) return 2;else if (byte >> 4 === 0x0E) return 3;else if (byte >> 3 === 0x1E) return 4;\n  return byte >> 6 === 0x02 ? -1 : -2;\n}\n\n// Checks at most 3 bytes at the end of a Buffer in order to detect an\n// incomplete multi-byte UTF-8 character. The total number of bytes (2, 3, or 4)\n// needed to complete the UTF-8 character (if applicable) are returned.\nfunction utf8CheckIncomplete(self, buf, i) {\n  var j = buf.length - 1;\n  if (j < i) return 0;\n  var nb = utf8CheckByte(buf[j]);\n  if (nb >= 0) {\n    if (nb > 0) self.lastNeed = nb - 1;\n    return nb;\n  }\n  if (--j < i || nb === -2) return 0;\n  nb = utf8CheckByte(buf[j]);\n  if (nb >= 0) {\n    if (nb > 0) self.lastNeed = nb - 2;\n    return nb;\n  }\n  if (--j < i || nb === -2) return 0;\n  nb = utf8CheckByte(buf[j]);\n  if (nb >= 0) {\n    if (nb > 0) {\n      if (nb === 2) nb = 0;else self.lastNeed = nb - 3;\n    }\n    return nb;\n  }\n  return 0;\n}\n\n// Validates as many continuation bytes for a multi-byte UTF-8 character as\n// needed or are available. If we see a non-continuation byte where we expect\n// one, we \"replace\" the validated continuation bytes we've seen so far with\n// a single UTF-8 replacement character ('\\ufffd'), to match v8's UTF-8 decoding\n// behavior. The continuation byte check is included three times in the case\n// where all of the continuation bytes for a character exist in the same buffer.\n// It is also done this way as a slight performance increase instead of using a\n// loop.\nfunction utf8CheckExtraBytes(self, buf, p) {\n  if ((buf[0] & 0xC0) !== 0x80) {\n    self.lastNeed = 0;\n    return '\\ufffd';\n  }\n  if (self.lastNeed > 1 && buf.length > 1) {\n    if ((buf[1] & 0xC0) !== 0x80) {\n      self.lastNeed = 1;\n      return '\\ufffd';\n    }\n    if (self.lastNeed > 2 && buf.length > 2) {\n      if ((buf[2] & 0xC0) !== 0x80) {\n        self.lastNeed = 2;\n        return '\\ufffd';\n      }\n    }\n  }\n}\n\n// Attempts to complete a multi-byte UTF-8 character using bytes from a Buffer.\nfunction utf8FillLast(buf) {\n  var p = this.lastTotal - this.lastNeed;\n  var r = utf8CheckExtraBytes(this, buf, p);\n  if (r !== undefined) return r;\n  if (this.lastNeed <= buf.length) {\n    buf.copy(this.lastChar, p, 0, this.lastNeed);\n    return this.lastChar.toString(this.encoding, 0, this.lastTotal);\n  }\n  buf.copy(this.lastChar, p, 0, buf.length);\n  this.lastNeed -= buf.length;\n}\n\n// Returns all complete UTF-8 characters in a Buffer. If the Buffer ended on a\n// partial character, the character's bytes are buffered until the required\n// number of bytes are available.\nfunction utf8Text(buf, i) {\n  var total = utf8CheckIncomplete(this, buf, i);\n  if (!this.lastNeed) return buf.toString('utf8', i);\n  this.lastTotal = total;\n  var end = buf.length - (total - this.lastNeed);\n  buf.copy(this.lastChar, 0, end);\n  return buf.toString('utf8', i, end);\n}\n\n// For UTF-8, a replacement character is added when ending on a partial\n// character.\nfunction utf8End(buf) {\n  var r = buf && buf.length ? this.write(buf) : '';\n  if (this.lastNeed) return r + '\\ufffd';\n  return r;\n}\n\n// UTF-16LE typically needs two bytes per character, but even if we have an even\n// number of bytes available, we need to check if we end on a leading/high\n// surrogate. In that case, we need to wait for the next two bytes in order to\n// decode the last character properly.\nfunction utf16Text(buf, i) {\n  if ((buf.length - i) % 2 === 0) {\n    var r = buf.toString('utf16le', i);\n    if (r) {\n      var c = r.charCodeAt(r.length - 1);\n      if (c >= 0xD800 && c <= 0xDBFF) {\n        this.lastNeed = 2;\n        this.lastTotal = 4;\n        this.lastChar[0] = buf[buf.length - 2];\n        this.lastChar[1] = buf[buf.length - 1];\n        return r.slice(0, -1);\n      }\n    }\n    return r;\n  }\n  this.lastNeed = 1;\n  this.lastTotal = 2;\n  this.lastChar[0] = buf[buf.length - 1];\n  return buf.toString('utf16le', i, buf.length - 1);\n}\n\n// For UTF-16LE we do not explicitly append special replacement characters if we\n// end on a partial character, we simply let v8 handle that.\nfunction utf16End(buf) {\n  var r = buf && buf.length ? this.write(buf) : '';\n  if (this.lastNeed) {\n    var end = this.lastTotal - this.lastNeed;\n    return r + this.lastChar.toString('utf16le', 0, end);\n  }\n  return r;\n}\n\nfunction base64Text(buf, i) {\n  var n = (buf.length - i) % 3;\n  if (n === 0) return buf.toString('base64', i);\n  this.lastNeed = 3 - n;\n  this.lastTotal = 3;\n  if (n === 1) {\n    this.lastChar[0] = buf[buf.length - 1];\n  } else {\n    this.lastChar[0] = buf[buf.length - 2];\n    this.lastChar[1] = buf[buf.length - 1];\n  }\n  return buf.toString('base64', i, buf.length - n);\n}\n\nfunction base64End(buf) {\n  var r = buf && buf.length ? this.write(buf) : '';\n  if (this.lastNeed) return r + this.lastChar.toString('base64', 0, 3 - this.lastNeed);\n  return r;\n}\n\n// Pass bytes on through for single-byte encodings (e.g. ascii, latin1, hex)\nfunction simpleWrite(buf) {\n  return buf.toString(this.encoding);\n}\n\nfunction simpleEnd(buf) {\n  return buf && buf.length ? this.write(buf) : '';\n}",
	"transpiled": true
}; item.content= context.Buffer.from(item.content,'binary'); } return item; })
	fileData.push(function(){ var item= cacheData[93]; if(!item){ item= cacheData[93]= {
	"stat": {
		"mtime": "1985-10-26T08:15:00.000Z",
		"mtimeMs": 499162500000,
		"atime": "2019-05-18T07:17:58.814Z",
		"atimeMs": 1558163878814.4548,
		"isfile": true
	},
	"filename": "node_modules/string_decoder/package.json",
	"content": "{\n  \"name\": \"string_decoder\",\n  \"version\": \"1.1.1\",\n  \"description\": \"The string_decoder module from Node core\",\n  \"main\": \"lib/string_decoder.js\",\n  \"dependencies\": {\n    \"safe-buffer\": \"~5.1.0\"\n  },\n  \"devDependencies\": {\n    \"babel-polyfill\": \"^6.23.0\",\n    \"core-util-is\": \"^1.0.2\",\n    \"inherits\": \"^2.0.3\",\n    \"tap\": \"~0.4.8\"\n  },\n  \"scripts\": {\n    \"test\": \"tap test/parallel/*.js && node test/verify-dependencies\",\n    \"ci\": \"tap test/parallel/*.js test/ours/*.js --tap | tee test.tap && node test/verify-dependencies.js\"\n  },\n  \"repository\": {\n    \"type\": \"git\",\n    \"url\": \"git://github.com/nodejs/string_decoder.git\"\n  },\n  \"homepage\": \"https://github.com/nodejs/string_decoder\",\n  \"keywords\": [\n    \"string\",\n    \"decoder\",\n    \"browser\",\n    \"browserify\"\n  ],\n  \"license\": \"MIT\"\n}\n",
	"transpiled": true
}; item.content= context.Buffer.from(item.content,'binary'); } return item; })
	fileData.push(function(){return {
	"stat": {
		"mtime": "2019-05-18T07:17:58.898Z",
		"mtimeMs": 1558163878898.4563,
		"atime": "2019-05-18T07:17:58.894Z",
		"atimeMs": 1558163878894.456,
		"isdirectory": true
	},
	"filename": "node_modules/typedarray"
}})
	fileData.push(function(){ var item= cacheData[95]; if(!item){ item= cacheData[95]= {
	"stat": {
		"mtime": "2013-12-12T23:47:39.000Z",
		"mtimeMs": 1386892059000,
		"atime": "2019-05-18T07:17:58.901Z",
		"atimeMs": 1558163878901,
		"isfile": true
	},
	"filename": "node_modules/typedarray/index.js",
	"content": "var undefined = (void 0); // Paranoia\n\n// Beyond this value, index getters/setters (i.e. array[0], array[1]) are so slow to\n// create, and consume so much memory, that the browser appears frozen.\nvar MAX_ARRAY_LENGTH = 1e5;\n\n// Approximations of internal ECMAScript conversion functions\nvar ECMAScript = (function() {\n  // Stash a copy in case other scripts modify these\n  var opts = Object.prototype.toString,\n      ophop = Object.prototype.hasOwnProperty;\n\n  return {\n    // Class returns internal [[Class]] property, used to avoid cross-frame instanceof issues:\n    Class: function(v) { return opts.call(v).replace(/^\\[object *|\\]$/g, ''); },\n    HasProperty: function(o, p) { return p in o; },\n    HasOwnProperty: function(o, p) { return ophop.call(o, p); },\n    IsCallable: function(o) { return typeof o === 'function'; },\n    ToInt32: function(v) { return v >> 0; },\n    ToUint32: function(v) { return v >>> 0; }\n  };\n}());\n\n// Snapshot intrinsics\nvar LN2 = Math.LN2,\n    abs = Math.abs,\n    floor = Math.floor,\n    log = Math.log,\n    min = Math.min,\n    pow = Math.pow,\n    round = Math.round;\n\n// ES5: lock down object properties\nfunction configureProperties(obj) {\n  if (getOwnPropNames && defineProp) {\n    var props = getOwnPropNames(obj), i;\n    for (i = 0; i < props.length; i += 1) {\n      defineProp(obj, props[i], {\n        value: obj[props[i]],\n        writable: false,\n        enumerable: false,\n        configurable: false\n      });\n    }\n  }\n}\n\n// emulate ES5 getter/setter API using legacy APIs\n// http://blogs.msdn.com/b/ie/archive/2010/09/07/transitioning-existing-code-to-the-es5-getter-setter-apis.aspx\n// (second clause tests for Object.defineProperty() in IE<9 that only supports extending DOM prototypes, but\n// note that IE<9 does not support __defineGetter__ or __defineSetter__ so it just renders the method harmless)\nvar defineProp\nif (Object.defineProperty && (function() {\n      try {\n        Object.defineProperty({}, 'x', {});\n        return true;\n      } catch (e) {\n        return false;\n      }\n    })()) {\n  defineProp = Object.defineProperty;\n} else {\n  defineProp = function(o, p, desc) {\n    if (!o === Object(o)) throw new TypeError(\"Object.defineProperty called on non-object\");\n    if (ECMAScript.HasProperty(desc, 'get') && Object.prototype.__defineGetter__) { Object.prototype.__defineGetter__.call(o, p, desc.get); }\n    if (ECMAScript.HasProperty(desc, 'set') && Object.prototype.__defineSetter__) { Object.prototype.__defineSetter__.call(o, p, desc.set); }\n    if (ECMAScript.HasProperty(desc, 'value')) { o[p] = desc.value; }\n    return o;\n  };\n}\n\nvar getOwnPropNames = Object.getOwnPropertyNames || function (o) {\n  if (o !== Object(o)) throw new TypeError(\"Object.getOwnPropertyNames called on non-object\");\n  var props = [], p;\n  for (p in o) {\n    if (ECMAScript.HasOwnProperty(o, p)) {\n      props.push(p);\n    }\n  }\n  return props;\n};\n\n// ES5: Make obj[index] an alias for obj._getter(index)/obj._setter(index, value)\n// for index in 0 ... obj.length\nfunction makeArrayAccessors(obj) {\n  if (!defineProp) { return; }\n\n  if (obj.length > MAX_ARRAY_LENGTH) throw new RangeError(\"Array too large for polyfill\");\n\n  function makeArrayAccessor(index) {\n    defineProp(obj, index, {\n      'get': function() { return obj._getter(index); },\n      'set': function(v) { obj._setter(index, v); },\n      enumerable: true,\n      configurable: false\n    });\n  }\n\n  var i;\n  for (i = 0; i < obj.length; i += 1) {\n    makeArrayAccessor(i);\n  }\n}\n\n// Internal conversion functions:\n//    pack<Type>()   - take a number (interpreted as Type), output a byte array\n//    unpack<Type>() - take a byte array, output a Type-like number\n\nfunction as_signed(value, bits) { var s = 32 - bits; return (value << s) >> s; }\nfunction as_unsigned(value, bits) { var s = 32 - bits; return (value << s) >>> s; }\n\nfunction packI8(n) { return [n & 0xff]; }\nfunction unpackI8(bytes) { return as_signed(bytes[0], 8); }\n\nfunction packU8(n) { return [n & 0xff]; }\nfunction unpackU8(bytes) { return as_unsigned(bytes[0], 8); }\n\nfunction packU8Clamped(n) { n = round(Number(n)); return [n < 0 ? 0 : n > 0xff ? 0xff : n & 0xff]; }\n\nfunction packI16(n) { return [(n >> 8) & 0xff, n & 0xff]; }\nfunction unpackI16(bytes) { return as_signed(bytes[0] << 8 | bytes[1], 16); }\n\nfunction packU16(n) { return [(n >> 8) & 0xff, n & 0xff]; }\nfunction unpackU16(bytes) { return as_unsigned(bytes[0] << 8 | bytes[1], 16); }\n\nfunction packI32(n) { return [(n >> 24) & 0xff, (n >> 16) & 0xff, (n >> 8) & 0xff, n & 0xff]; }\nfunction unpackI32(bytes) { return as_signed(bytes[0] << 24 | bytes[1] << 16 | bytes[2] << 8 | bytes[3], 32); }\n\nfunction packU32(n) { return [(n >> 24) & 0xff, (n >> 16) & 0xff, (n >> 8) & 0xff, n & 0xff]; }\nfunction unpackU32(bytes) { return as_unsigned(bytes[0] << 24 | bytes[1] << 16 | bytes[2] << 8 | bytes[3], 32); }\n\nfunction packIEEE754(v, ebits, fbits) {\n\n  var bias = (1 << (ebits - 1)) - 1,\n      s, e, f, ln,\n      i, bits, str, bytes;\n\n  function roundToEven(n) {\n    var w = floor(n), f = n - w;\n    if (f < 0.5)\n      return w;\n    if (f > 0.5)\n      return w + 1;\n    return w % 2 ? w + 1 : w;\n  }\n\n  // Compute sign, exponent, fraction\n  if (v !== v) {\n    // NaN\n    // http://dev.w3.org/2006/webapi/WebIDL/#es-type-mapping\n    e = (1 << ebits) - 1; f = pow(2, fbits - 1); s = 0;\n  } else if (v === Infinity || v === -Infinity) {\n    e = (1 << ebits) - 1; f = 0; s = (v < 0) ? 1 : 0;\n  } else if (v === 0) {\n    e = 0; f = 0; s = (1 / v === -Infinity) ? 1 : 0;\n  } else {\n    s = v < 0;\n    v = abs(v);\n\n    if (v >= pow(2, 1 - bias)) {\n      e = min(floor(log(v) / LN2), 1023);\n      f = roundToEven(v / pow(2, e) * pow(2, fbits));\n      if (f / pow(2, fbits) >= 2) {\n        e = e + 1;\n        f = 1;\n      }\n      if (e > bias) {\n        // Overflow\n        e = (1 << ebits) - 1;\n        f = 0;\n      } else {\n        // Normalized\n        e = e + bias;\n        f = f - pow(2, fbits);\n      }\n    } else {\n      // Denormalized\n      e = 0;\n      f = roundToEven(v / pow(2, 1 - bias - fbits));\n    }\n  }\n\n  // Pack sign, exponent, fraction\n  bits = [];\n  for (i = fbits; i; i -= 1) { bits.push(f % 2 ? 1 : 0); f = floor(f / 2); }\n  for (i = ebits; i; i -= 1) { bits.push(e % 2 ? 1 : 0); e = floor(e / 2); }\n  bits.push(s ? 1 : 0);\n  bits.reverse();\n  str = bits.join('');\n\n  // Bits to bytes\n  bytes = [];\n  while (str.length) {\n    bytes.push(parseInt(str.substring(0, 8), 2));\n    str = str.substring(8);\n  }\n  return bytes;\n}\n\nfunction unpackIEEE754(bytes, ebits, fbits) {\n\n  // Bytes to bits\n  var bits = [], i, j, b, str,\n      bias, s, e, f;\n\n  for (i = bytes.length; i; i -= 1) {\n    b = bytes[i - 1];\n    for (j = 8; j; j -= 1) {\n      bits.push(b % 2 ? 1 : 0); b = b >> 1;\n    }\n  }\n  bits.reverse();\n  str = bits.join('');\n\n  // Unpack sign, exponent, fraction\n  bias = (1 << (ebits - 1)) - 1;\n  s = parseInt(str.substring(0, 1), 2) ? -1 : 1;\n  e = parseInt(str.substring(1, 1 + ebits), 2);\n  f = parseInt(str.substring(1 + ebits), 2);\n\n  // Produce number\n  if (e === (1 << ebits) - 1) {\n    return f !== 0 ? NaN : s * Infinity;\n  } else if (e > 0) {\n    // Normalized\n    return s * pow(2, e - bias) * (1 + f / pow(2, fbits));\n  } else if (f !== 0) {\n    // Denormalized\n    return s * pow(2, -(bias - 1)) * (f / pow(2, fbits));\n  } else {\n    return s < 0 ? -0 : 0;\n  }\n}\n\nfunction unpackF64(b) { return unpackIEEE754(b, 11, 52); }\nfunction packF64(v) { return packIEEE754(v, 11, 52); }\nfunction unpackF32(b) { return unpackIEEE754(b, 8, 23); }\nfunction packF32(v) { return packIEEE754(v, 8, 23); }\n\n\n//\n// 3 The ArrayBuffer Type\n//\n\n(function() {\n\n  /** @constructor */\n  var ArrayBuffer = function ArrayBuffer(length) {\n    length = ECMAScript.ToInt32(length);\n    if (length < 0) throw new RangeError('ArrayBuffer size is not a small enough positive integer');\n\n    this.byteLength = length;\n    this._bytes = [];\n    this._bytes.length = length;\n\n    var i;\n    for (i = 0; i < this.byteLength; i += 1) {\n      this._bytes[i] = 0;\n    }\n\n    configureProperties(this);\n  };\n\n  exports.ArrayBuffer = exports.ArrayBuffer || ArrayBuffer;\n\n  //\n  // 4 The ArrayBufferView Type\n  //\n\n  // NOTE: this constructor is not exported\n  /** @constructor */\n  var ArrayBufferView = function ArrayBufferView() {\n    //this.buffer = null;\n    //this.byteOffset = 0;\n    //this.byteLength = 0;\n  };\n\n  //\n  // 5 The Typed Array View Types\n  //\n\n  function makeConstructor(bytesPerElement, pack, unpack) {\n    // Each TypedArray type requires a distinct constructor instance with\n    // identical logic, which this produces.\n\n    var ctor;\n    ctor = function(buffer, byteOffset, length) {\n      var array, sequence, i, s;\n\n      if (!arguments.length || typeof arguments[0] === 'number') {\n        // Constructor(unsigned long length)\n        this.length = ECMAScript.ToInt32(arguments[0]);\n        if (length < 0) throw new RangeError('ArrayBufferView size is not a small enough positive integer');\n\n        this.byteLength = this.length * this.BYTES_PER_ELEMENT;\n        this.buffer = new ArrayBuffer(this.byteLength);\n        this.byteOffset = 0;\n      } else if (typeof arguments[0] === 'object' && arguments[0].constructor === ctor) {\n        // Constructor(TypedArray array)\n        array = arguments[0];\n\n        this.length = array.length;\n        this.byteLength = this.length * this.BYTES_PER_ELEMENT;\n        this.buffer = new ArrayBuffer(this.byteLength);\n        this.byteOffset = 0;\n\n        for (i = 0; i < this.length; i += 1) {\n          this._setter(i, array._getter(i));\n        }\n      } else if (typeof arguments[0] === 'object' &&\n                 !(arguments[0] instanceof ArrayBuffer || ECMAScript.Class(arguments[0]) === 'ArrayBuffer')) {\n        // Constructor(sequence<type> array)\n        sequence = arguments[0];\n\n        this.length = ECMAScript.ToUint32(sequence.length);\n        this.byteLength = this.length * this.BYTES_PER_ELEMENT;\n        this.buffer = new ArrayBuffer(this.byteLength);\n        this.byteOffset = 0;\n\n        for (i = 0; i < this.length; i += 1) {\n          s = sequence[i];\n          this._setter(i, Number(s));\n        }\n      } else if (typeof arguments[0] === 'object' &&\n                 (arguments[0] instanceof ArrayBuffer || ECMAScript.Class(arguments[0]) === 'ArrayBuffer')) {\n        // Constructor(ArrayBuffer buffer,\n        //             optional unsigned long byteOffset, optional unsigned long length)\n        this.buffer = buffer;\n\n        this.byteOffset = ECMAScript.ToUint32(byteOffset);\n        if (this.byteOffset > this.buffer.byteLength) {\n          throw new RangeError(\"byteOffset out of range\");\n        }\n\n        if (this.byteOffset % this.BYTES_PER_ELEMENT) {\n          // The given byteOffset must be a multiple of the element\n          // size of the specific type, otherwise an exception is raised.\n          throw new RangeError(\"ArrayBuffer length minus the byteOffset is not a multiple of the element size.\");\n        }\n\n        if (arguments.length < 3) {\n          this.byteLength = this.buffer.byteLength - this.byteOffset;\n\n          if (this.byteLength % this.BYTES_PER_ELEMENT) {\n            throw new RangeError(\"length of buffer minus byteOffset not a multiple of the element size\");\n          }\n          this.length = this.byteLength / this.BYTES_PER_ELEMENT;\n        } else {\n          this.length = ECMAScript.ToUint32(length);\n          this.byteLength = this.length * this.BYTES_PER_ELEMENT;\n        }\n\n        if ((this.byteOffset + this.byteLength) > this.buffer.byteLength) {\n          throw new RangeError(\"byteOffset and length reference an area beyond the end of the buffer\");\n        }\n      } else {\n        throw new TypeError(\"Unexpected argument type(s)\");\n      }\n\n      this.constructor = ctor;\n\n      configureProperties(this);\n      makeArrayAccessors(this);\n    };\n\n    ctor.prototype = new ArrayBufferView();\n    ctor.prototype.BYTES_PER_ELEMENT = bytesPerElement;\n    ctor.prototype._pack = pack;\n    ctor.prototype._unpack = unpack;\n    ctor.BYTES_PER_ELEMENT = bytesPerElement;\n\n    // getter type (unsigned long index);\n    ctor.prototype._getter = function(index) {\n      if (arguments.length < 1) throw new SyntaxError(\"Not enough arguments\");\n\n      index = ECMAScript.ToUint32(index);\n      if (index >= this.length) {\n        return undefined;\n      }\n\n      var bytes = [], i, o;\n      for (i = 0, o = this.byteOffset + index * this.BYTES_PER_ELEMENT;\n           i < this.BYTES_PER_ELEMENT;\n           i += 1, o += 1) {\n        bytes.push(this.buffer._bytes[o]);\n      }\n      return this._unpack(bytes);\n    };\n\n    // NONSTANDARD: convenience alias for getter: type get(unsigned long index);\n    ctor.prototype.get = ctor.prototype._getter;\n\n    // setter void (unsigned long index, type value);\n    ctor.prototype._setter = function(index, value) {\n      if (arguments.length < 2) throw new SyntaxError(\"Not enough arguments\");\n\n      index = ECMAScript.ToUint32(index);\n      if (index >= this.length) {\n        return undefined;\n      }\n\n      var bytes = this._pack(value), i, o;\n      for (i = 0, o = this.byteOffset + index * this.BYTES_PER_ELEMENT;\n           i < this.BYTES_PER_ELEMENT;\n           i += 1, o += 1) {\n        this.buffer._bytes[o] = bytes[i];\n      }\n    };\n\n    // void set(TypedArray array, optional unsigned long offset);\n    // void set(sequence<type> array, optional unsigned long offset);\n    ctor.prototype.set = function(index, value) {\n      if (arguments.length < 1) throw new SyntaxError(\"Not enough arguments\");\n      var array, sequence, offset, len,\n          i, s, d,\n          byteOffset, byteLength, tmp;\n\n      if (typeof arguments[0] === 'object' && arguments[0].constructor === this.constructor) {\n        // void set(TypedArray array, optional unsigned long offset);\n        array = arguments[0];\n        offset = ECMAScript.ToUint32(arguments[1]);\n\n        if (offset + array.length > this.length) {\n          throw new RangeError(\"Offset plus length of array is out of range\");\n        }\n\n        byteOffset = this.byteOffset + offset * this.BYTES_PER_ELEMENT;\n        byteLength = array.length * this.BYTES_PER_ELEMENT;\n\n        if (array.buffer === this.buffer) {\n          tmp = [];\n          for (i = 0, s = array.byteOffset; i < byteLength; i += 1, s += 1) {\n            tmp[i] = array.buffer._bytes[s];\n          }\n          for (i = 0, d = byteOffset; i < byteLength; i += 1, d += 1) {\n            this.buffer._bytes[d] = tmp[i];\n          }\n        } else {\n          for (i = 0, s = array.byteOffset, d = byteOffset;\n               i < byteLength; i += 1, s += 1, d += 1) {\n            this.buffer._bytes[d] = array.buffer._bytes[s];\n          }\n        }\n      } else if (typeof arguments[0] === 'object' && typeof arguments[0].length !== 'undefined') {\n        // void set(sequence<type> array, optional unsigned long offset);\n        sequence = arguments[0];\n        len = ECMAScript.ToUint32(sequence.length);\n        offset = ECMAScript.ToUint32(arguments[1]);\n\n        if (offset + len > this.length) {\n          throw new RangeError(\"Offset plus length of array is out of range\");\n        }\n\n        for (i = 0; i < len; i += 1) {\n          s = sequence[i];\n          this._setter(offset + i, Number(s));\n        }\n      } else {\n        throw new TypeError(\"Unexpected argument type(s)\");\n      }\n    };\n\n    // TypedArray subarray(long begin, optional long end);\n    ctor.prototype.subarray = function(start, end) {\n      function clamp(v, min, max) { return v < min ? min : v > max ? max : v; }\n\n      start = ECMAScript.ToInt32(start);\n      end = ECMAScript.ToInt32(end);\n\n      if (arguments.length < 1) { start = 0; }\n      if (arguments.length < 2) { end = this.length; }\n\n      if (start < 0) { start = this.length + start; }\n      if (end < 0) { end = this.length + end; }\n\n      start = clamp(start, 0, this.length);\n      end = clamp(end, 0, this.length);\n\n      var len = end - start;\n      if (len < 0) {\n        len = 0;\n      }\n\n      return new this.constructor(\n        this.buffer, this.byteOffset + start * this.BYTES_PER_ELEMENT, len);\n    };\n\n    return ctor;\n  }\n\n  var Int8Array = makeConstructor(1, packI8, unpackI8);\n  var Uint8Array = makeConstructor(1, packU8, unpackU8);\n  var Uint8ClampedArray = makeConstructor(1, packU8Clamped, unpackU8);\n  var Int16Array = makeConstructor(2, packI16, unpackI16);\n  var Uint16Array = makeConstructor(2, packU16, unpackU16);\n  var Int32Array = makeConstructor(4, packI32, unpackI32);\n  var Uint32Array = makeConstructor(4, packU32, unpackU32);\n  var Float32Array = makeConstructor(4, packF32, unpackF32);\n  var Float64Array = makeConstructor(8, packF64, unpackF64);\n\n  exports.Int8Array = exports.Int8Array || Int8Array;\n  exports.Uint8Array = exports.Uint8Array || Uint8Array;\n  exports.Uint8ClampedArray = exports.Uint8ClampedArray || Uint8ClampedArray;\n  exports.Int16Array = exports.Int16Array || Int16Array;\n  exports.Uint16Array = exports.Uint16Array || Uint16Array;\n  exports.Int32Array = exports.Int32Array || Int32Array;\n  exports.Uint32Array = exports.Uint32Array || Uint32Array;\n  exports.Float32Array = exports.Float32Array || Float32Array;\n  exports.Float64Array = exports.Float64Array || Float64Array;\n}());\n\n//\n// 6 The DataView View Type\n//\n\n(function() {\n  function r(array, index) {\n    return ECMAScript.IsCallable(array.get) ? array.get(index) : array[index];\n  }\n\n  var IS_BIG_ENDIAN = (function() {\n    var u16array = new(exports.Uint16Array)([0x1234]),\n        u8array = new(exports.Uint8Array)(u16array.buffer);\n    return r(u8array, 0) === 0x12;\n  }());\n\n  // Constructor(ArrayBuffer buffer,\n  //             optional unsigned long byteOffset,\n  //             optional unsigned long byteLength)\n  /** @constructor */\n  var DataView = function DataView(buffer, byteOffset, byteLength) {\n    if (arguments.length === 0) {\n      buffer = new exports.ArrayBuffer(0);\n    } else if (!(buffer instanceof exports.ArrayBuffer || ECMAScript.Class(buffer) === 'ArrayBuffer')) {\n      throw new TypeError(\"TypeError\");\n    }\n\n    this.buffer = buffer || new exports.ArrayBuffer(0);\n\n    this.byteOffset = ECMAScript.ToUint32(byteOffset);\n    if (this.byteOffset > this.buffer.byteLength) {\n      throw new RangeError(\"byteOffset out of range\");\n    }\n\n    if (arguments.length < 3) {\n      this.byteLength = this.buffer.byteLength - this.byteOffset;\n    } else {\n      this.byteLength = ECMAScript.ToUint32(byteLength);\n    }\n\n    if ((this.byteOffset + this.byteLength) > this.buffer.byteLength) {\n      throw new RangeError(\"byteOffset and length reference an area beyond the end of the buffer\");\n    }\n\n    configureProperties(this);\n  };\n\n  function makeGetter(arrayType) {\n    return function(byteOffset, littleEndian) {\n\n      byteOffset = ECMAScript.ToUint32(byteOffset);\n\n      if (byteOffset + arrayType.BYTES_PER_ELEMENT > this.byteLength) {\n        throw new RangeError(\"Array index out of range\");\n      }\n      byteOffset += this.byteOffset;\n\n      var uint8Array = new exports.Uint8Array(this.buffer, byteOffset, arrayType.BYTES_PER_ELEMENT),\n          bytes = [], i;\n      for (i = 0; i < arrayType.BYTES_PER_ELEMENT; i += 1) {\n        bytes.push(r(uint8Array, i));\n      }\n\n      if (Boolean(littleEndian) === Boolean(IS_BIG_ENDIAN)) {\n        bytes.reverse();\n      }\n\n      return r(new arrayType(new exports.Uint8Array(bytes).buffer), 0);\n    };\n  }\n\n  DataView.prototype.getUint8 = makeGetter(exports.Uint8Array);\n  DataView.prototype.getInt8 = makeGetter(exports.Int8Array);\n  DataView.prototype.getUint16 = makeGetter(exports.Uint16Array);\n  DataView.prototype.getInt16 = makeGetter(exports.Int16Array);\n  DataView.prototype.getUint32 = makeGetter(exports.Uint32Array);\n  DataView.prototype.getInt32 = makeGetter(exports.Int32Array);\n  DataView.prototype.getFloat32 = makeGetter(exports.Float32Array);\n  DataView.prototype.getFloat64 = makeGetter(exports.Float64Array);\n\n  function makeSetter(arrayType) {\n    return function(byteOffset, value, littleEndian) {\n\n      byteOffset = ECMAScript.ToUint32(byteOffset);\n      if (byteOffset + arrayType.BYTES_PER_ELEMENT > this.byteLength) {\n        throw new RangeError(\"Array index out of range\");\n      }\n\n      // Get bytes\n      var typeArray = new arrayType([value]),\n          byteArray = new exports.Uint8Array(typeArray.buffer),\n          bytes = [], i, byteView;\n\n      for (i = 0; i < arrayType.BYTES_PER_ELEMENT; i += 1) {\n        bytes.push(r(byteArray, i));\n      }\n\n      // Flip if necessary\n      if (Boolean(littleEndian) === Boolean(IS_BIG_ENDIAN)) {\n        bytes.reverse();\n      }\n\n      // Write them\n      byteView = new exports.Uint8Array(this.buffer, byteOffset, arrayType.BYTES_PER_ELEMENT);\n      byteView.set(bytes);\n    };\n  }\n\n  DataView.prototype.setUint8 = makeSetter(exports.Uint8Array);\n  DataView.prototype.setInt8 = makeSetter(exports.Int8Array);\n  DataView.prototype.setUint16 = makeSetter(exports.Uint16Array);\n  DataView.prototype.setInt16 = makeSetter(exports.Int16Array);\n  DataView.prototype.setUint32 = makeSetter(exports.Uint32Array);\n  DataView.prototype.setInt32 = makeSetter(exports.Int32Array);\n  DataView.prototype.setFloat32 = makeSetter(exports.Float32Array);\n  DataView.prototype.setFloat64 = makeSetter(exports.Float64Array);\n\n  exports.DataView = exports.DataView || DataView;\n\n}());\n",
	"transpiled": true
}; item.content= context.Buffer.from(item.content,'binary'); } return item; })
	fileData.push(function(){ var item= cacheData[96]; if(!item){ item= cacheData[96]= {
	"stat": {
		"mtime": "2014-05-17T02:52:37.000Z",
		"mtimeMs": 1400295157000,
		"atime": "2019-05-18T07:17:58.898Z",
		"atimeMs": 1558163878898.4563,
		"isfile": true
	},
	"filename": "node_modules/typedarray/package.json",
	"content": "{\n  \"name\": \"typedarray\",\n  \"version\": \"0.0.6\",\n  \"description\": \"TypedArray polyfill for old browsers\",\n  \"main\": \"index.js\",\n  \"devDependencies\": {\n    \"tape\": \"~2.3.2\"\n  },\n  \"scripts\": {\n    \"test\": \"tape test/*.js test/server/*.js\"\n  },\n  \"repository\": {\n    \"type\": \"git\",\n    \"url\": \"git://github.com/substack/typedarray.git\"\n  },\n  \"homepage\": \"https://github.com/substack/typedarray\",\n  \"keywords\": [\n    \"ArrayBuffer\",\n    \"DataView\",\n    \"Float32Array\",\n    \"Float64Array\",\n    \"Int8Array\",\n    \"Int16Array\",\n    \"Int32Array\",\n    \"Uint8Array\",\n    \"Uint8ClampedArray\",\n    \"Uint16Array\",\n    \"Uint32Array\",\n    \"typed\",\n    \"array\",\n    \"polyfill\"\n  ],\n  \"author\": {\n    \"name\": \"James Halliday\",\n    \"email\": \"mail@substack.net\",\n    \"url\": \"http://substack.net\"\n  },\n  \"license\": \"MIT\",\n  \"testling\": {\n    \"files\": \"test/*.js\",\n    \"browsers\": [\n      \"ie/6..latest\",\n      \"firefox/16..latest\",\n      \"firefox/nightly\",\n      \"chrome/22..latest\",\n      \"chrome/canary\",\n      \"opera/12..latest\",\n      \"opera/next\",\n      \"safari/5.1..latest\",\n      \"ipad/6.0..latest\",\n      \"iphone/6.0..latest\",\n      \"android-browser/4.2..latest\"\n    ]\n  }\n}\n",
	"transpiled": true
}; item.content= context.Buffer.from(item.content,'binary'); } return item; })
	fileData.push(function(){ var item= cacheData[97]; if(!item){ item= cacheData[97]= {
	"stat": {
		"mtime": "2014-05-17T02:52:18.000Z",
		"mtimeMs": 1400295138000,
		"atime": "2019-05-18T07:17:58.901Z",
		"atimeMs": 1558163878901,
		"isfile": true
	},
	"filename": "node_modules/typedarray/readme.markdown",
	"content": "# typedarray\n\nTypedArray polyfill ripped from [this\nmodule](https://raw.github.com/inexorabletash/polyfill).\n\n[![build status](https://secure.travis-ci.org/substack/typedarray.png)](http://travis-ci.org/substack/typedarray)\n\n[![testling badge](https://ci.testling.com/substack/typedarray.png)](https://ci.testling.com/substack/typedarray)\n\n# example\n\n``` js\nvar Uint8Array = require('typedarray').Uint8Array;\nvar ua = new Uint8Array(5);\nua[1] = 256 + 55;\nconsole.log(ua[1]);\n```\n\noutput:\n\n```\n55\n```\n\n# methods\n\n``` js\nvar TA = require('typedarray')\n```\n\nThe `TA` object has the following constructors:\n\n* TA.ArrayBuffer\n* TA.DataView\n* TA.Float32Array\n* TA.Float64Array\n* TA.Int8Array\n* TA.Int16Array\n* TA.Int32Array\n* TA.Uint8Array\n* TA.Uint8ClampedArray\n* TA.Uint16Array\n* TA.Uint32Array\n\n# install\n\nWith [npm](https://npmjs.org) do:\n\n```\nnpm install typedarray\n```\n\nTo use this module in the browser, compile with\n[browserify](http://browserify.org)\nor download a UMD build from browserify CDN:\n\nhttp://wzrd.in/standalone/typedarray@latest\n\n# license\n\nMIT\n",
	"transpiled": true
}; item.content= context.Buffer.from(item.content,'binary'); } return item; })
	fileData.push(function(){return {
	"stat": {
		"mtime": "2019-05-18T07:17:58.866Z",
		"mtimeMs": 1558163878866.4556,
		"atime": "2019-05-18T07:17:58.866Z",
		"atimeMs": 1558163878866.4556,
		"isdirectory": true
	},
	"filename": "node_modules/util-deprecate"
}})
	fileData.push(function(){ var item= cacheData[99]; if(!item){ item= cacheData[99]= {
	"stat": {
		"mtime": "2015-10-07T18:36:10.000Z",
		"mtimeMs": 1444242970000,
		"atime": "2019-05-18T07:17:58.872Z",
		"atimeMs": 1558163878872,
		"isfile": true
	},
	"filename": "node_modules/util-deprecate/browser.js",
	"content": "\n/**\n * Module exports.\n */\n\nmodule.exports = deprecate;\n\n/**\n * Mark that a method should not be used.\n * Returns a modified function which warns once by default.\n *\n * If `localStorage.noDeprecation = true` is set, then it is a no-op.\n *\n * If `localStorage.throwDeprecation = true` is set, then deprecated functions\n * will throw an Error when invoked.\n *\n * If `localStorage.traceDeprecation = true` is set, then deprecated functions\n * will invoke `console.trace()` instead of `console.error()`.\n *\n * @param {Function} fn - the function to deprecate\n * @param {String} msg - the string to print to the console when `fn` is invoked\n * @returns {Function} a new \"deprecated\" version of `fn`\n * @api public\n */\n\nfunction deprecate (fn, msg) {\n  if (config('noDeprecation')) {\n    return fn;\n  }\n\n  var warned = false;\n  function deprecated() {\n    if (!warned) {\n      if (config('throwDeprecation')) {\n        throw new Error(msg);\n      } else if (config('traceDeprecation')) {\n        console.trace(msg);\n      } else {\n        console.warn(msg);\n      }\n      warned = true;\n    }\n    return fn.apply(this, arguments);\n  }\n\n  return deprecated;\n}\n\n/**\n * Checks `localStorage` for boolean values for the given `name`.\n *\n * @param {String} name\n * @returns {Boolean}\n * @api private\n */\n\nfunction config (name) {\n  // accessing global.localStorage can trigger a DOMException in sandboxed iframes\n  try {\n    if (!global.localStorage) return false;\n  } catch (_) {\n    return false;\n  }\n  var val = global.localStorage[name];\n  if (null == val) return false;\n  return String(val).toLowerCase() === 'true';\n}\n",
	"transpiled": true
}; item.content= context.Buffer.from(item.content,'binary'); } return item; })
	fileData.push(function(){ var item= cacheData[100]; if(!item){ item= cacheData[100]= {
	"stat": {
		"mtime": "2014-11-25T20:05:41.000Z",
		"mtimeMs": 1416945941000,
		"atime": "2019-05-18T07:17:58.872Z",
		"atimeMs": 1558163878872,
		"isfile": true
	},
	"filename": "node_modules/util-deprecate/node.js",
	"content": "\n/**\n * For Node.js, simply re-export the core `util.deprecate` function.\n */\n\nmodule.exports = require('util').deprecate;\n",
	"transpiled": true
}; item.content= context.Buffer.from(item.content,'binary'); } return item; })
	fileData.push(function(){ var item= cacheData[101]; if(!item){ item= cacheData[101]= {
	"stat": {
		"mtime": "2015-10-07T18:37:28.000Z",
		"mtimeMs": 1444243048000,
		"atime": "2019-05-18T07:17:58.870Z",
		"atimeMs": 1558163878870.4558,
		"isfile": true
	},
	"filename": "node_modules/util-deprecate/package.json",
	"content": "{\n  \"name\": \"util-deprecate\",\n  \"version\": \"1.0.2\",\n  \"description\": \"The Node.js `util.deprecate()` function with browser support\",\n  \"main\": \"node.js\",\n  \"browser\": \"browser.js\",\n  \"scripts\": {\n    \"test\": \"echo \\\"Error: no test specified\\\" && exit 1\"\n  },\n  \"repository\": {\n    \"type\": \"git\",\n    \"url\": \"git://github.com/TooTallNate/util-deprecate.git\"\n  },\n  \"keywords\": [\n    \"util\",\n    \"deprecate\",\n    \"browserify\",\n    \"browser\",\n    \"node\"\n  ],\n  \"author\": \"Nathan Rajlich <nathan@tootallnate.net> (http://n8.io/)\",\n  \"license\": \"MIT\",\n  \"bugs\": {\n    \"url\": \"https://github.com/TooTallNate/util-deprecate/issues\"\n  },\n  \"homepage\": \"https://github.com/TooTallNate/util-deprecate\"\n}\n",
	"transpiled": true
}; item.content= context.Buffer.from(item.content,'binary'); } return item; })
	fileData.push(function(){return {
	"stat": {
		"mtime": "2019-05-18T07:17:58.934Z",
		"mtimeMs": 1558163878934.4568,
		"atime": "2019-05-18T07:17:58.930Z",
		"atimeMs": 1558163878930.4568,
		"isdirectory": true
	},
	"filename": "node_modules/yauzl"
}})
	fileData.push(function(){ var item= cacheData[103]; if(!item){ item= cacheData[103]= {
	"stat": {
		"mtime": "2015-12-31T19:57:55.000Z",
		"mtimeMs": 1451591875000,
		"atime": "2019-05-18T07:17:58.937Z",
		"atimeMs": 1558163878937,
		"isfile": true
	},
	"filename": "node_modules/yauzl/index.js",
	"content": "var fs = require(\"fs\");\nvar zlib = require(\"zlib\");\nvar fd_slicer = require(\"fd-slicer\");\nvar util = require(\"util\");\nvar EventEmitter = require(\"events\").EventEmitter;\nvar Transform = require(\"stream\").Transform;\nvar PassThrough = require(\"stream\").PassThrough;\nvar Writable = require(\"stream\").Writable;\n\nexports.open = open;\nexports.fromFd = fromFd;\nexports.fromBuffer = fromBuffer;\nexports.fromRandomAccessReader = fromRandomAccessReader;\nexports.dosDateTimeToDate = dosDateTimeToDate;\nexports.ZipFile = ZipFile;\nexports.Entry = Entry;\nexports.RandomAccessReader = RandomAccessReader;\n\nfunction open(path, options, callback) {\n  if (typeof options === \"function\") {\n    callback = options;\n    options = null;\n  }\n  if (options == null) options = {};\n  if (options.autoClose == null) options.autoClose = true;\n  if (options.lazyEntries == null) options.lazyEntries = false;\n  if (callback == null) callback = defaultCallback;\n  fs.open(path, \"r\", function(err, fd) {\n    if (err) return callback(err);\n    fromFd(fd, options, function(err, zipfile) {\n      if (err) fs.close(fd, defaultCallback);\n      callback(err, zipfile);\n    });\n  });\n}\n\nfunction fromFd(fd, options, callback) {\n  if (typeof options === \"function\") {\n    callback = options;\n    options = null;\n  }\n  if (options == null) options = {};\n  if (options.autoClose == null) options.autoClose = false;\n  if (options.lazyEntries == null) options.lazyEntries = false;\n  if (callback == null) callback = defaultCallback;\n  fs.fstat(fd, function(err, stats) {\n    if (err) return callback(err);\n    var reader = fd_slicer.createFromFd(fd, {autoClose: true});\n    fromRandomAccessReader(reader, stats.size, options, callback);\n  });\n}\n\nfunction fromBuffer(buffer, options, callback) {\n  if (typeof options === \"function\") {\n    callback = options;\n    options = null;\n  }\n  if (options == null) options = {};\n  options.autoClose = false;\n  if (options.lazyEntries == null) options.lazyEntries = false;\n  // i got your open file right here.\n  var reader = fd_slicer.createFromBuffer(buffer);\n  fromRandomAccessReader(reader, buffer.length, options, callback);\n}\n\nfunction fromRandomAccessReader(reader, totalSize, options, callback) {\n  if (typeof options === \"function\") {\n    callback = options;\n    options = null;\n  }\n  if (options == null) options = {};\n  if (options.autoClose == null) options.autoClose = true;\n  if (options.lazyEntries == null) options.lazyEntries = false;\n  if (callback == null) callback = defaultCallback;\n  if (typeof totalSize !== \"number\") throw new Error(\"expected totalSize parameter to be a number\");\n  if (totalSize > Number.MAX_SAFE_INTEGER) {\n    throw new Error(\"zip file too large. only file sizes up to 2^52 are supported due to JavaScript's Number type being an IEEE 754 double.\");\n  }\n\n  // the matching unref() call is in zipfile.close()\n  reader.ref();\n\n  // eocdr means End of Central Directory Record.\n  // search backwards for the eocdr signature.\n  // the last field of the eocdr is a variable-length comment.\n  // the comment size is encoded in a 2-byte field in the eocdr, which we can't find without trudging backwards through the comment to find it.\n  // as a consequence of this design decision, it's possible to have ambiguous zip file metadata if a coherent eocdr was in the comment.\n  // we search backwards for a eocdr signature, and hope that whoever made the zip file was smart enough to forbid the eocdr signature in the comment.\n  var eocdrWithoutCommentSize = 22;\n  var maxCommentSize = 0x10000; // 2-byte size\n  var bufferSize = Math.min(eocdrWithoutCommentSize + maxCommentSize, totalSize);\n  var buffer = new Buffer(bufferSize);\n  var bufferReadStart = totalSize - buffer.length;\n  readAndAssertNoEof(reader, buffer, 0, bufferSize, bufferReadStart, function(err) {\n    if (err) return callback(err);\n    for (var i = bufferSize - eocdrWithoutCommentSize; i >= 0; i -= 1) {\n      if (buffer.readUInt32LE(i) !== 0x06054b50) continue;\n      // found eocdr\n      var eocdrBuffer = buffer.slice(i);\n\n      // 0 - End of central directory signature = 0x06054b50\n      // 4 - Number of this disk\n      var diskNumber = eocdrBuffer.readUInt16LE(4);\n      if (diskNumber !== 0) return callback(new Error(\"multi-disk zip files are not supported: found disk number: \" + diskNumber));\n      // 6 - Disk where central directory starts\n      // 8 - Number of central directory records on this disk\n      // 10 - Total number of central directory records\n      var entryCount = eocdrBuffer.readUInt16LE(10);\n      // 12 - Size of central directory (bytes)\n      // 16 - Offset of start of central directory, relative to start of archive\n      var centralDirectoryOffset = eocdrBuffer.readUInt32LE(16);\n      // 20 - Comment length\n      var commentLength = eocdrBuffer.readUInt16LE(20);\n      var expectedCommentLength = eocdrBuffer.length - eocdrWithoutCommentSize;\n      if (commentLength !== expectedCommentLength) {\n        return callback(new Error(\"invalid comment length. expected: \" + expectedCommentLength + \". found: \" + commentLength));\n      }\n      // 22 - Comment\n      // the encoding is always cp437.\n      var comment = bufferToString(eocdrBuffer, 22, eocdrBuffer.length, false);\n\n      if (!(entryCount === 0xffff || centralDirectoryOffset === 0xffffffff)) {\n        return callback(null, new ZipFile(reader, centralDirectoryOffset, totalSize, entryCount, comment, options.autoClose, options.lazyEntries));\n      }\n\n      // ZIP64 format\n\n      // ZIP64 Zip64 end of central directory locator\n      var zip64EocdlBuffer = new Buffer(20);\n      var zip64EocdlOffset = bufferReadStart + i - zip64EocdlBuffer.length;\n      readAndAssertNoEof(reader, zip64EocdlBuffer, 0, zip64EocdlBuffer.length, zip64EocdlOffset, function(err) {\n        if (err) return callback(err);\n\n        // 0 - zip64 end of central dir locator signature = 0x07064b50\n        if (zip64EocdlBuffer.readUInt32LE(0) !== 0x07064b50) {\n          return callback(new Error(\"invalid ZIP64 End of Central Directory Locator signature\"));\n        }\n        // 4 - number of the disk with the start of the zip64 end of central directory\n        // 8 - relative offset of the zip64 end of central directory record\n        var zip64EocdrOffset = readUInt64LE(zip64EocdlBuffer, 8);\n        // 16 - total number of disks\n\n        // ZIP64 end of central directory record\n        var zip64EocdrBuffer = new Buffer(56);\n        readAndAssertNoEof(reader, zip64EocdrBuffer, 0, zip64EocdrBuffer.length, zip64EocdrOffset, function(err) {\n          if (err) return callback(err);\n\n          // 0 - zip64 end of central dir signature                           4 bytes  (0x06064b50)\n          if (zip64EocdrBuffer.readUInt32LE(0) !== 0x06064b50) return callback(new Error(\"invalid ZIP64 end of central directory record signature\"));\n          // 4 - size of zip64 end of central directory record                8 bytes\n          // 12 - version made by                                             2 bytes\n          // 14 - version needed to extract                                   2 bytes\n          // 16 - number of this disk                                         4 bytes\n          // 20 - number of the disk with the start of the central directory  4 bytes\n          // 24 - total number of entries in the central directory on this disk         8 bytes\n          // 32 - total number of entries in the central directory            8 bytes\n          entryCount = readUInt64LE(zip64EocdrBuffer, 32);\n          // 40 - size of the central directory                               8 bytes\n          // 48 - offset of start of central directory with respect to the starting disk number     8 bytes\n          centralDirectoryOffset = readUInt64LE(zip64EocdrBuffer, 48);\n          // 56 - zip64 extensible data sector                                (variable size)\n          return callback(null, new ZipFile(reader, centralDirectoryOffset, totalSize, entryCount, comment, options.autoClose, options.lazyEntries));\n        });\n      });\n      return;\n    }\n    callback(new Error(\"end of central directory record signature not found\"));\n  });\n}\n\nutil.inherits(ZipFile, EventEmitter);\nfunction ZipFile(reader, centralDirectoryOffset, fileSize, entryCount, comment, autoClose, lazyEntries) {\n  var self = this;\n  EventEmitter.call(self);\n  self.reader = reader;\n  // forward close events\n  self.reader.on(\"error\", function(err) {\n    // error closing the fd\n    emitError(self, err);\n  });\n  self.reader.once(\"close\", function() {\n    self.emit(\"close\");\n  });\n  self.readEntryCursor = centralDirectoryOffset;\n  self.fileSize = fileSize;\n  self.entryCount = entryCount;\n  self.comment = comment;\n  self.entriesRead = 0;\n  self.autoClose = !!autoClose;\n  self.lazyEntries = !!lazyEntries;\n  self.isOpen = true;\n  self.emittedError = false;\n\n  if (!self.lazyEntries) self.readEntry();\n}\nZipFile.prototype.close = function() {\n  if (!this.isOpen) return;\n  this.isOpen = false;\n  this.reader.unref();\n};\n\nfunction emitErrorAndAutoClose(self, err) {\n  if (self.autoClose) self.close();\n  emitError(self, err);\n}\nfunction emitError(self, err) {\n  if (self.emittedError) return;\n  self.emittedError = true;\n  self.emit(\"error\", err);\n}\n\nZipFile.prototype.readEntry = function() {\n  var self = this;\n  if (self.entryCount === self.entriesRead) {\n    // done with metadata\n    setImmediate(function() {\n      if (self.autoClose) self.close();\n      if (self.emittedError) return;\n      self.emit(\"end\");\n    });\n    return;\n  }\n  if (self.emittedError) return;\n  var buffer = new Buffer(46);\n  readAndAssertNoEof(self.reader, buffer, 0, buffer.length, self.readEntryCursor, function(err) {\n    if (err) return emitErrorAndAutoClose(self, err);\n    if (self.emittedError) return;\n    var entry = new Entry();\n    // 0 - Central directory file header signature\n    var signature = buffer.readUInt32LE(0);\n    if (signature !== 0x02014b50) return emitErrorAndAutoClose(self, new Error(\"invalid central directory file header signature: 0x\" + signature.toString(16)));\n    // 4 - Version made by\n    entry.versionMadeBy = buffer.readUInt16LE(4);\n    // 6 - Version needed to extract (minimum)\n    entry.versionNeededToExtract = buffer.readUInt16LE(6);\n    // 8 - General purpose bit flag\n    entry.generalPurposeBitFlag = buffer.readUInt16LE(8);\n    // 10 - Compression method\n    entry.compressionMethod = buffer.readUInt16LE(10);\n    // 12 - File last modification time\n    entry.lastModFileTime = buffer.readUInt16LE(12);\n    // 14 - File last modification date\n    entry.lastModFileDate = buffer.readUInt16LE(14);\n    // 16 - CRC-32\n    entry.crc32 = buffer.readUInt32LE(16);\n    // 20 - Compressed size\n    entry.compressedSize = buffer.readUInt32LE(20);\n    // 24 - Uncompressed size\n    entry.uncompressedSize = buffer.readUInt32LE(24);\n    // 28 - File name length (n)\n    entry.fileNameLength = buffer.readUInt16LE(28);\n    // 30 - Extra field length (m)\n    entry.extraFieldLength = buffer.readUInt16LE(30);\n    // 32 - File comment length (k)\n    entry.fileCommentLength = buffer.readUInt16LE(32);\n    // 34 - Disk number where file starts\n    // 36 - Internal file attributes\n    entry.internalFileAttributes = buffer.readUInt16LE(36);\n    // 38 - External file attributes\n    entry.externalFileAttributes = buffer.readUInt32LE(38);\n    // 42 - Relative offset of local file header\n    entry.relativeOffsetOfLocalHeader = buffer.readUInt32LE(42);\n\n    self.readEntryCursor += 46;\n\n    buffer = new Buffer(entry.fileNameLength + entry.extraFieldLength + entry.fileCommentLength);\n    readAndAssertNoEof(self.reader, buffer, 0, buffer.length, self.readEntryCursor, function(err) {\n      if (err) return emitErrorAndAutoClose(self, err);\n      if (self.emittedError) return;\n      // 46 - File name\n      var isUtf8 = entry.generalPurposeBitFlag & 0x800\n      try {\n        entry.fileName = bufferToString(buffer, 0, entry.fileNameLength, isUtf8);\n      } catch (e) {\n        return emitErrorAndAutoClose(self, e);\n      }\n\n      // 46+n - Extra field\n      var fileCommentStart = entry.fileNameLength + entry.extraFieldLength;\n      var extraFieldBuffer = buffer.slice(entry.fileNameLength, fileCommentStart);\n      entry.extraFields = [];\n      var i = 0;\n      while (i < extraFieldBuffer.length) {\n        var headerId = extraFieldBuffer.readUInt16LE(i + 0);\n        var dataSize = extraFieldBuffer.readUInt16LE(i + 2);\n        var dataStart = i + 4;\n        var dataEnd = dataStart + dataSize;\n        var dataBuffer = new Buffer(dataSize);\n        extraFieldBuffer.copy(dataBuffer, 0, dataStart, dataEnd);\n        entry.extraFields.push({\n          id: headerId,\n          data: dataBuffer,\n        });\n        i = dataEnd;\n      }\n\n      // 46+n+m - File comment\n      try {\n        entry.fileComment = bufferToString(buffer, fileCommentStart, fileCommentStart + entry.fileCommentLength, isUtf8);\n      } catch (e) {\n        return emitErrorAndAutoClose(self, e);\n      }\n\n      self.readEntryCursor += buffer.length;\n      self.entriesRead += 1;\n\n      if (entry.uncompressedSize            === 0xffffffff ||\n          entry.compressedSize              === 0xffffffff ||\n          entry.relativeOffsetOfLocalHeader === 0xffffffff) {\n        // ZIP64 format\n        // find the Zip64 Extended Information Extra Field\n        var zip64EiefBuffer = null;\n        for (var i = 0; i < entry.extraFields.length; i++) {\n          var extraField = entry.extraFields[i];\n          if (extraField.id === 0x0001) {\n            zip64EiefBuffer = extraField.data;\n            break;\n          }\n        }\n        if (zip64EiefBuffer == null) return emitErrorAndAutoClose(self, new Error(\"expected Zip64 Extended Information Extra Field\"));\n        var index = 0;\n        // 0 - Original Size          8 bytes\n        if (entry.uncompressedSize === 0xffffffff) {\n          if (index + 8 > zip64EiefBuffer.length) return emitErrorAndAutoClose(self, new Error(\"Zip64 Extended Information Extra Field does not include Original Size\"));\n          entry.uncompressedSize = readUInt64LE(zip64EiefBuffer, index);\n          index += 8;\n        }\n        // 8 - Compressed Size        8 bytes\n        if (entry.compressedSize === 0xffffffff) {\n          if (index + 8 > zip64EiefBuffer.length) return emitErrorAndAutoClose(self, new Error(\"Zip64 Extended Information Extra Field does not include Compressed Size\"));\n          entry.compressedSize = readUInt64LE(zip64EiefBuffer, index);\n          index += 8;\n        }\n        // 16 - Relative Header Offset 8 bytes\n        if (entry.relativeOffsetOfLocalHeader === 0xffffffff) {\n          if (index + 8 > zip64EiefBuffer.length) return emitErrorAndAutoClose(self, new Error(\"Zip64 Extended Information Extra Field does not include Relative Header Offset\"));\n          entry.relativeOffsetOfLocalHeader = readUInt64LE(zip64EiefBuffer, index);\n          index += 8;\n        }\n        // 24 - Disk Start Number      4 bytes\n      }\n\n      // validate file size\n      if (entry.compressionMethod === 0) {\n        if (entry.compressedSize !== entry.uncompressedSize) {\n          var msg = \"compressed/uncompressed size mismatch for stored file: \" + entry.compressedSize + \" != \" + entry.uncompressedSize;\n          return emitErrorAndAutoClose(self, new Error(msg));\n        }\n      }\n\n      // validate file name\n      if (entry.fileName.indexOf(\"\\\\\") !== -1) return emitErrorAndAutoClose(self, new Error(\"invalid characters in fileName: \" + entry.fileName));\n      if (/^[a-zA-Z]:/.test(entry.fileName) || /^\\//.test(entry.fileName)) return emitErrorAndAutoClose(self, new Error(\"absolute path: \" + entry.fileName));\n      if (entry.fileName.split(\"/\").indexOf(\"..\") !== -1) return emitErrorAndAutoClose(self, new Error(\"invalid relative path: \" + entry.fileName));\n      self.emit(\"entry\", entry);\n\n      if (!self.lazyEntries) self.readEntry();\n    });\n  });\n};\n\nZipFile.prototype.openReadStream = function(entry, callback) {\n  var self = this;\n  if (!self.isOpen) return callback(new Error(\"closed\"));\n  // make sure we don't lose the fd before we open the actual read stream\n  self.reader.ref();\n  var buffer = new Buffer(30);\n  readAndAssertNoEof(self.reader, buffer, 0, buffer.length, entry.relativeOffsetOfLocalHeader, function(err) {\n    try {\n      if (err) return callback(err);\n      // 0 - Local file header signature = 0x04034b50\n      var signature = buffer.readUInt32LE(0);\n      if (signature !== 0x04034b50) return callback(new Error(\"invalid local file header signature: 0x\" + signature.toString(16)));\n      // all this should be redundant\n      // 4 - Version needed to extract (minimum)\n      // 6 - General purpose bit flag\n      // 8 - Compression method\n      // 10 - File last modification time\n      // 12 - File last modification date\n      // 14 - CRC-32\n      // 18 - Compressed size\n      // 22 - Uncompressed size\n      // 26 - File name length (n)\n      var fileNameLength = buffer.readUInt16LE(26);\n      // 28 - Extra field length (m)\n      var extraFieldLength = buffer.readUInt16LE(28);\n      // 30 - File name\n      // 30+n - Extra field\n      var localFileHeaderEnd = entry.relativeOffsetOfLocalHeader + buffer.length + fileNameLength + extraFieldLength;\n      var compressed;\n      if (entry.compressionMethod === 0) {\n        // 0 - The file is stored (no compression)\n        compressed = false;\n      } else if (entry.compressionMethod === 8) {\n        // 8 - The file is Deflated\n        compressed = true;\n      } else {\n        return callback(new Error(\"unsupported compression method: \" + entry.compressionMethod));\n      }\n      var fileDataStart = localFileHeaderEnd;\n      var fileDataEnd = fileDataStart + entry.compressedSize;\n      if (entry.compressedSize !== 0) {\n        // bounds check now, because the read streams will probably not complain loud enough.\n        // since we're dealing with an unsigned offset plus an unsigned size,\n        // we only have 1 thing to check for.\n        if (fileDataEnd > self.fileSize) {\n          return callback(new Error(\"file data overflows file bounds: \" +\n              fileDataStart + \" + \" + entry.compressedSize + \" > \" + self.fileSize));\n        }\n      }\n      var readStream = self.reader.createReadStream({start: fileDataStart, end: fileDataEnd});\n      var endpointStream = readStream;\n      if (compressed) {\n        var destroyed = false;\n        var inflateFilter = zlib.createInflateRaw();\n        readStream.on(\"error\", function(err) {\n          // setImmediate here because errors can be emitted during the first call to pipe()\n          setImmediate(function() {\n            if (!destroyed) inflateFilter.emit(\"error\", err);\n          });\n        });\n\n        var checkerStream = new AssertByteCountStream(entry.uncompressedSize);\n        inflateFilter.on(\"error\", function(err) {\n          // forward zlib errors to the client-visible stream\n          setImmediate(function() {\n            if (!destroyed) checkerStream.emit(\"error\", err);\n          });\n        });\n        checkerStream.destroy = function() {\n          destroyed = true;\n          inflateFilter.unpipe(checkerStream);\n          readStream.unpipe(inflateFilter);\n          // TODO: the inflateFilter now causes a memory leak. see Issue #27.\n          readStream.destroy();\n        };\n        endpointStream = readStream.pipe(inflateFilter).pipe(checkerStream);\n      }\n      callback(null, endpointStream);\n    } finally {\n      self.reader.unref();\n    }\n  });\n};\n\nfunction Entry() {\n}\nEntry.prototype.getLastModDate = function() {\n  return dosDateTimeToDate(this.lastModFileDate, this.lastModFileTime);\n};\n\nfunction dosDateTimeToDate(date, time) {\n  var day = date & 0x1f; // 1-31\n  var month = (date >> 5 & 0xf) - 1; // 1-12, 0-11\n  var year = (date >> 9 & 0x7f) + 1980; // 0-128, 1980-2108\n\n  var millisecond = 0;\n  var second = (time & 0x1f) * 2; // 0-29, 0-58 (even numbers)\n  var minute = time >> 5 & 0x3f; // 0-59\n  var hour = time >> 11 & 0x1f; // 0-23\n\n  return new Date(year, month, day, hour, minute, second, millisecond);\n}\n\nfunction readAndAssertNoEof(reader, buffer, offset, length, position, callback) {\n  if (length === 0) {\n    // fs.read will throw an out-of-bounds error if you try to read 0 bytes from a 0 byte file\n    return setImmediate(function() { callback(null, new Buffer(0)); });\n  }\n  reader.read(buffer, offset, length, position, function(err, bytesRead) {\n    if (err) return callback(err);\n    if (bytesRead < length) return callback(new Error(\"unexpected EOF\"));\n    callback();\n  });\n}\n\nutil.inherits(AssertByteCountStream, Transform);\nfunction AssertByteCountStream(byteCount) {\n  Transform.call(this);\n  this.actualByteCount = 0;\n  this.expectedByteCount = byteCount;\n}\nAssertByteCountStream.prototype._transform = function(chunk, encoding, cb) {\n  this.actualByteCount += chunk.length;\n  if (this.actualByteCount > this.expectedByteCount) {\n    var msg = \"too many bytes in the stream. expected \" + this.expectedByteCount + \". got at least \" + this.actualByteCount;\n    return cb(new Error(msg));\n  }\n  cb(null, chunk);\n};\nAssertByteCountStream.prototype._flush = function(cb) {\n  if (this.actualByteCount < this.expectedByteCount) {\n    var msg = \"not enough bytes in the stream. expected \" + this.expectedByteCount + \". got only \" + this.actualByteCount;\n    return cb(new Error(msg));\n  }\n  cb();\n};\n\nutil.inherits(RandomAccessReader, EventEmitter);\nfunction RandomAccessReader() {\n  EventEmitter.call(this);\n  this.refCount = 0;\n}\nRandomAccessReader.prototype.ref = function() {\n  this.refCount += 1;\n};\nRandomAccessReader.prototype.unref = function() {\n  var self = this;\n  self.refCount -= 1;\n\n  if (self.refCount > 0) return;\n  if (self.refCount < 0) throw new Error(\"invalid unref\");\n\n  self.close(onCloseDone);\n\n  function onCloseDone(err) {\n    if (err) return self.emit('error', err);\n    self.emit('close');\n  }\n};\nRandomAccessReader.prototype.createReadStream = function(options) {\n  var start = options.start;\n  var end = options.end;\n  if (start === end) {\n    var emptyStream = new PassThrough();\n    setImmediate(function() {\n      emptyStream.end();\n    });\n    return emptyStream;\n  }\n  var stream = this._readStreamForRange(start, end);\n\n  var destroyed = false;\n  var refUnrefFilter = new RefUnrefFilter(this);\n  stream.on(\"error\", function(err) {\n    setImmediate(function() {\n      if (!destroyed) refUnrefFilter.emit(\"error\", err);\n    });\n  });\n  refUnrefFilter.destroy = function() {\n    stream.unpipe(refUnrefFilter);\n    refUnrefFilter.unref();\n    stream.destroy();\n  };\n\n  var byteCounter = new AssertByteCountStream(end - start);\n  refUnrefFilter.on(\"error\", function(err) {\n    setImmediate(function() {\n      if (!destroyed) byteCounter.emit(\"error\", err);\n    });\n  });\n  byteCounter.destroy = function() {\n    destroyed = true;\n    refUnrefFilter.unpipe(byteCounter);\n    refUnrefFilter.destroy();\n  };\n\n  return stream.pipe(refUnrefFilter).pipe(byteCounter);\n};\nRandomAccessReader.prototype._readStreamForRange = function(start, end) {\n  throw new Error(\"not implemented\");\n};\nRandomAccessReader.prototype.read = function(buffer, offset, length, position, callback) {\n  var readStream = this.createReadStream({start: position, end: position + length});\n  var writeStream = new Writable();\n  var written = 0;\n  writeStream._write = function(chunk, encoding, cb) {\n    chunk.copy(buffer, offset + written, 0, chunk.length);\n    written += chunk.length;\n    cb();\n  };\n  writeStream.on(\"finish\", callback);\n  readStream.on(\"error\", function(error) {\n    callback(error);\n  });\n  readStream.pipe(writeStream);\n};\nRandomAccessReader.prototype.close = function(callback) {\n  setImmediate(callback);\n};\n\nutil.inherits(RefUnrefFilter, PassThrough);\nfunction RefUnrefFilter(context) {\n  PassThrough.call(this);\n  this.context = context;\n  this.context.ref();\n  this.unreffedYet = false;\n}\nRefUnrefFilter.prototype._flush = function(cb) {\n  this.unref();\n  cb();\n};\nRefUnrefFilter.prototype.unref = function(cb) {\n  if (this.unreffedYet) return;\n  this.unreffedYet = true;\n  this.context.unref();\n};\n\nvar cp437 = '\\u0000 !\"#$%&\\'()*+,-./0123456789:;<=>?@ABCDEFGHIJKLMNOPQRSTUVWXYZ[\\\\]^_`abcdefghijklmnopqrstuvwxyz{|}~';\nfunction bufferToString(buffer, start, end, isUtf8) {\n  if (isUtf8) {\n    return buffer.toString(\"utf8\", start, end);\n  } else {\n    var result = \"\";\n    for (var i = start; i < end; i++) {\n      result += cp437[buffer[i]];\n    }\n    return result;\n  }\n}\n\nfunction readUInt64LE(buffer, offset) {\n  // there is no native function for this, because we can't actually store 64-bit integers precisely.\n  // after 53 bits, JavaScript's Number type (IEEE 754 double) can't store individual integers anymore.\n  // but since 53 bits is a whole lot more than 32 bits, we do our best anyway.\n  var lower32 = buffer.readUInt32LE(offset);\n  var upper32 = buffer.readUInt32LE(offset + 4);\n  // we can't use bitshifting here, because JavaScript bitshifting only works on 32-bit integers.\n  return upper32 * 0x100000000 + lower32;\n  // as long as we're bounds checking the result of this function against the total file size,\n  // we'll catch any overflow errors, because we already made sure the total file size was within reason.\n}\n\nfunction defaultCallback(err) {\n  if (err) throw err;\n}\n",
	"transpiled": true
}; item.content= context.Buffer.from(item.content,'binary'); } return item; })
	fileData.push(function(){ var item= cacheData[104]; if(!item){ item= cacheData[104]= {
	"stat": {
		"mtime": "2015-12-31T20:01:09.000Z",
		"mtimeMs": 1451592069000,
		"atime": "2019-05-18T07:17:58.934Z",
		"atimeMs": 1558163878934.4568,
		"isfile": true
	},
	"filename": "node_modules/yauzl/package.json",
	"content": "{\n  \"name\": \"yauzl\",\n  \"version\": \"2.4.1\",\n  \"description\": \"yet another unzip library for node\",\n  \"main\": \"index.js\",\n  \"scripts\": {\n    \"test\": \"node test/test.js\",\n    \"test-cov\": \"istanbul cover test/test.js\",\n    \"test-travis\": \"istanbul cover --report lcovonly test/test.js\"\n  },\n  \"repository\": {\n    \"type\": \"git\",\n    \"url\": \"https://github.com/thejoshwolfe/yauzl.git\"\n  },\n  \"keywords\": [\n    \"unzip\",\n    \"zip\",\n    \"stream\",\n    \"archive\",\n    \"file\"\n  ],\n  \"author\": \"Josh Wolfe <thejoshwolfe@gmail.com>\",\n  \"license\": \"MIT\",\n  \"bugs\": {\n    \"url\": \"https://github.com/thejoshwolfe/yauzl/issues\"\n  },\n  \"homepage\": \"https://github.com/thejoshwolfe/yauzl\",\n  \"dependencies\": {\n    \"fd-slicer\": \"~1.0.1\"\n  },\n  \"devDependencies\": {\n    \"bl\": \"~1.0.0\",\n    \"istanbul\": \"~0.3.4\",\n    \"pend\": \"~1.2.0\"\n  }\n}\n",
	"transpiled": true
}; item.content= context.Buffer.from(item.content,'binary'); } return item; })
	fileData.push(function(){ var item= cacheData[105]; if(!item){ item= cacheData[105]= {
	"stat": {
		"mtime": "2018-05-24T02:03:52.000Z",
		"mtimeMs": 1527127432000,
		"atime": "2019-05-18T07:17:58.534Z",
		"atimeMs": 1558163878534.45,
		"isfile": true
	},
	"filename": "package.json",
	"content": "{\n  \"name\": \"extract-zip\",\n  \"version\": \"1.6.7\",\n  \"description\": \"unzip a zip file into a directory using 100% javascript\",\n  \"main\": \"index.js\",\n  \"bin\": {\n    \"extract-zip\": \"cli.js\"\n  },\n  \"scripts\": {\n    \"test\": \"standard && node test/test.js\"\n  },\n  \"author\": \"max ogden\",\n  \"license\": \"BSD-2-Clause\",\n  \"repository\": \"maxogden/extract-zip\",\n  \"keywords\": [\n    \"unzip\",\n    \"zip\",\n    \"extract\"\n  ],\n  \"dependencies\": {\n    \"concat-stream\": \"1.6.2\",\n    \"debug\": \"2.6.9\",\n    \"mkdirp\": \"0.5.1\",\n    \"yauzl\": \"2.4.1\"\n  },\n  \"devDependencies\": {\n    \"rimraf\": \"^2.2.8\",\n    \"standard\": \"^5.2.2\",\n    \"tape\": \"^4.2.0\",\n    \"temp\": \"^0.8.3\"\n  },\n  \"directories\": {\n    \"test\": \"test\"\n  }\n}\n",
	"transpiled": true
}; item.content= context.Buffer.from(item.content,'binary'); } return item; })
	var filenames={
	"": 0,
	"cli.js": 1,
	"index.js": 2,
	"node_modules": 3,
	"node_modules/buffer-from": 4,
	"node_modules/buffer-from/index.js": 5,
	"node_modules/buffer-from/package.json": 6,
	"node_modules/concat-stream": 7,
	"node_modules/concat-stream/index.js": 8,
	"node_modules/concat-stream/package.json": 9,
	"node_modules/core-util-is": 10,
	"node_modules/core-util-is/float.patch": 11,
	"node_modules/core-util-is/lib": 12,
	"node_modules/core-util-is/lib/util.js": 13,
	"node_modules/core-util-is/package.json": 14,
	"node_modules/core-util-is/test.js": 15,
	"node_modules/debug": 16,
	"node_modules/debug/Makefile": 17,
	"node_modules/debug/component.json": 18,
	"node_modules/debug/karma.conf.js": 19,
	"node_modules/debug/node.js": 20,
	"node_modules/debug/package.json": 21,
	"node_modules/debug/src": 22,
	"node_modules/debug/src/browser.js": 23,
	"node_modules/debug/src/debug.js": 24,
	"node_modules/debug/src/index.js": 25,
	"node_modules/debug/src/inspector-log.js": 26,
	"node_modules/debug/src/node.js": 27,
	"node_modules/fd-slicer": 28,
	"node_modules/fd-slicer/index.js": 29,
	"node_modules/fd-slicer/package.json": 30,
	"node_modules/inherits": 31,
	"node_modules/inherits/inherits.js": 32,
	"node_modules/inherits/inherits_browser.js": 33,
	"node_modules/inherits/package.json": 34,
	"node_modules/isarray": 35,
	"node_modules/isarray/Makefile": 36,
	"node_modules/isarray/component.json": 37,
	"node_modules/isarray/index.js": 38,
	"node_modules/isarray/package.json": 39,
	"node_modules/isarray/test.js": 40,
	"node_modules/minimist": 41,
	"node_modules/minimist/index.js": 42,
	"node_modules/minimist/package.json": 43,
	"node_modules/minimist/readme.markdown": 44,
	"node_modules/mkdirp": 45,
	"node_modules/mkdirp/bin": 46,
	"node_modules/mkdirp/bin/cmd.js": 47,
	"node_modules/mkdirp/bin/usage.txt": 48,
	"node_modules/mkdirp/index.js": 49,
	"node_modules/mkdirp/package.json": 50,
	"node_modules/mkdirp/readme.markdown": 51,
	"node_modules/ms": 52,
	"node_modules/ms/index.js": 53,
	"node_modules/ms/package.json": 54,
	"node_modules/pend": 55,
	"node_modules/pend/index.js": 56,
	"node_modules/pend/package.json": 57,
	"node_modules/pend/test.js": 58,
	"node_modules/process-nextick-args": 59,
	"node_modules/process-nextick-args/index.js": 60,
	"node_modules/process-nextick-args/package.json": 61,
	"node_modules/readable-stream": 62,
	"node_modules/readable-stream/doc": 63,
	"node_modules/readable-stream/doc/wg-meetings": 64,
	"node_modules/readable-stream/duplex-browser.js": 65,
	"node_modules/readable-stream/duplex.js": 66,
	"node_modules/readable-stream/lib": 67,
	"node_modules/readable-stream/lib/_stream_duplex.js": 68,
	"node_modules/readable-stream/lib/_stream_passthrough.js": 69,
	"node_modules/readable-stream/lib/_stream_readable.js": 70,
	"node_modules/readable-stream/lib/_stream_transform.js": 71,
	"node_modules/readable-stream/lib/_stream_writable.js": 72,
	"node_modules/readable-stream/lib/internal": 73,
	"node_modules/readable-stream/lib/internal/streams": 74,
	"node_modules/readable-stream/lib/internal/streams/BufferList.js": 75,
	"node_modules/readable-stream/lib/internal/streams/destroy.js": 76,
	"node_modules/readable-stream/lib/internal/streams/stream-browser.js": 77,
	"node_modules/readable-stream/lib/internal/streams/stream.js": 78,
	"node_modules/readable-stream/package.json": 79,
	"node_modules/readable-stream/passthrough.js": 80,
	"node_modules/readable-stream/readable-browser.js": 81,
	"node_modules/readable-stream/readable.js": 82,
	"node_modules/readable-stream/transform.js": 83,
	"node_modules/readable-stream/writable-browser.js": 84,
	"node_modules/readable-stream/writable.js": 85,
	"node_modules/safe-buffer": 86,
	"node_modules/safe-buffer/index.d.ts": 87,
	"node_modules/safe-buffer/index.js": 88,
	"node_modules/safe-buffer/package.json": 89,
	"node_modules/string_decoder": 90,
	"node_modules/string_decoder/lib": 91,
	"node_modules/string_decoder/lib/string_decoder.js": 92,
	"node_modules/string_decoder/package.json": 93,
	"node_modules/typedarray": 94,
	"node_modules/typedarray/index.js": 95,
	"node_modules/typedarray/package.json": 96,
	"node_modules/typedarray/readme.markdown": 97,
	"node_modules/util-deprecate": 98,
	"node_modules/util-deprecate/browser.js": 99,
	"node_modules/util-deprecate/node.js": 100,
	"node_modules/util-deprecate/package.json": 101,
	"node_modules/yauzl": 102,
	"node_modules/yauzl/index.js": 103,
	"node_modules/yauzl/package.json": 104,
	"package.json": 105
}
		var mod1= function(KModule, exports){
			var i=0, main, pe, filecount, pjson
			for(var id in filenames){
				if(typeof module == "object"){
					
					if(id == "package.json"){
						pjson= fileData[i]()
						pjson= JSON.parse(pjson.content)
					}
			
				}
				KModule.addVirtualFile("extract-zip@1.6.7" + (id ? ("/"+id) : ""), fileData[i])
				i++
			}
			if(pjson){
				main= pjson.main
				if(!main){
					main= "index.js"
				}
				if(main.substring(0,2)=="./"){
					main= main.substring(2)
				}
				main= "extract-zip@1.6.7" + (main ? ("/" + main) : "")
			}
			if(main){
				return KModule.import("/virtual/" + main)
			}
			if(typeof module == "object"){
				return exports
			}
			return {}
		}

		var transpiledExtensions= {}


		/*
		if(typeof module == "object"){
			module.exports.__kawi= mod1
		}*/
		if(global.Buffer){
			context.Buffer= global.Buffer
		}

		if(typeof window == "object"){
			if(window.KModuleLoader){
				for(var id in transpiledExtensions){
					if(!window.KModuleLoader.extensions[id])
						window.KModuleLoader.extensions[id]= null
				}
				context.Buffer= global.___kmodule___basic.mod.buffer.Buffer
				context.module= window.KModuleLoader.generateModule()
				context.module.exports= mod1(window.KModuleLoader, context.module.exports)
				return mod1
			}
		}
		if(typeof KModule == "object"){
			for(var id in transpiledExtensions){
				if(!KModule.extensions[id])
					KModule.extensions[id]= null
			}
			module.exports= mod1(KModule, module.exports)
		}
		return mod1
		
})(typeof global == 'object' ? global : window, {})
// kawi converted. Preserve this line, Kawi transpiler will not reprocess if this line found